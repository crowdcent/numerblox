{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Generating predictions for Numerai on preprocessed data.\n",
    "output-file: model.html\n",
    "title: Model\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BaseModel` is an abstract base class that handles directory logic and naming conventions. All models should inherit from `BaseModel` and be sure to implement the `.predict` method.\n",
    "\n",
    "In general, models are loaded in from disk. However, if no model files are involved in your model you should pass an empty string (`\"\"`) as the `model_directory` argument.\n",
    "\n",
    "Note that a new prediction column will have the column name `prediction_{MODEL_NAME}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaseModel\n",
       "\n",
       ">      BaseModel (model_directory:str, model_name:str=None)\n",
       "\n",
       "Setup for model prediction on a Dataset.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaseModel\n",
       "\n",
       ">      BaseModel (model_directory:str, model_name:str=None)\n",
       "\n",
       "Setup for model prediction on a Dataset.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(BaseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. DirectoryModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DirectoryModel` assumes that you have a directory of models and you want to load + predict for all models with a certain `file_suffix` (for example, `.joblib`, `.cbm` or `.lgb`). This base class handles prediction logic for this situation.\n",
    "\n",
    "If you are thinking of implementing your own model and your use case involves reading multiple models from a directory, then you should inherit from `DirectoryModel` and be sure to implement `.load_models`. You then don't have to implement any prediction logic in the `.predict` method.\n",
    "\n",
    "When inheriting from `DirectoryModel` the only mandatory method implementation is for `.load_models`. It should instantiate all models and return them as a `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DirectoryModel\n",
       "\n",
       ">      DirectoryModel (model_directory:str, file_suffix:str,\n",
       ">                      model_name:str=None, feature_cols:list=None,\n",
       ">                      combine_preds=True)\n",
       "\n",
       "Base class implementation where predictions are averaged out from a directory of models. Walks through every file with given file_suffix in a directory.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param file_suffix: File format to load (For example, .joblib, .pkl, .cbm or .lgb) \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default. \n",
       "\n",
       ":param combine_preds: Whether to average predictions along column axis. Only relevant for multi target models. \n",
       "\n",
       "Convenient when you want to predict the main target by averaging a multi-target model."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DirectoryModel\n",
       "\n",
       ">      DirectoryModel (model_directory:str, file_suffix:str,\n",
       ">                      model_name:str=None, feature_cols:list=None,\n",
       ">                      combine_preds=True)\n",
       "\n",
       "Base class implementation where predictions are averaged out from a directory of models. Walks through every file with given file_suffix in a directory.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param file_suffix: File format to load (For example, .joblib, .pkl, .cbm or .lgb) \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default. \n",
       "\n",
       ":param combine_preds: Whether to average predictions along column axis. Only relevant for multi target models. \n",
       "\n",
       "Convenient when you want to predict the main target by averaging a multi-target model."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DirectoryModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single model formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementations for common Numerai model prediction situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. SingleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases you just want to load a single model file and create predictions for that model. `SingleModel` supports this.\n",
    "\n",
    "This class supports multiple model formats for easy use. All models should have a `.predict` method.\n",
    "Currently, `.joblib`, `.cbm`, `.pkl`, `.pickle` and `.h5` (keras) format are supported.\n",
    "\n",
    "**Things to keep in mind**\n",
    "- This model will use all available features in the `NumerFrame` and use them for prediction by default. Define `feature_cols` in `SingleModel` or implement a `FeatureSelectionPreProcessor` as part of your `ModelPipeline` if you are using a subset of features.\n",
    "- If you have XGBoost models we recommend saving them as `.joblib`.\n",
    "- The added prediction column will have the column name `prediction_{MODEL_NAME}` if 1 target is predicted.\n",
    "For multiple targets the new column names will be `prediction_{MODEL_NAME}_{i}` for each target number i (starting with 0).\n",
    "- We welcome the Numerai community to extend `SingleModel` for more file formats. See the Contributing section in `README.md` for more information on contributing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SingleModel\n",
       "\n",
       ">      SingleModel (model_file_path:str, model_name:str=None,\n",
       ">                   combine_preds=False, autoencoder_mlp=False,\n",
       ">                   feature_cols:list=None)\n",
       "\n",
       "Load single model from file and perform prediction logic.\n",
       "\n",
       ":param model_file_path: Full path to model file. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes. \n",
       "\n",
       ":param combine_preds: Whether to average predictions along column axis. Only relevant for multi target models.\n",
       "Convenient when you want to predict the main target by averaging a multi-target model. \n",
       "\n",
       ":param autoencoder_mlp: Whether your model is an autoencoder + MLP model.\n",
       "Will take the 3rd of tuple output in this case. Only relevant for NN models.\n",
       "More info on autoencoders:\n",
       "https://forum.numer.ai/t/autoencoder-and-multitask-mlp-on-new-dataset-from-kaggle-jane-street/4338 \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SingleModel\n",
       "\n",
       ">      SingleModel (model_file_path:str, model_name:str=None,\n",
       ">                   combine_preds=False, autoencoder_mlp=False,\n",
       ">                   feature_cols:list=None)\n",
       "\n",
       "Load single model from file and perform prediction logic.\n",
       "\n",
       ":param model_file_path: Full path to model file. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes. \n",
       "\n",
       ":param combine_preds: Whether to average predictions along column axis. Only relevant for multi target models.\n",
       "Convenient when you want to predict the main target by averaging a multi-target model. \n",
       "\n",
       ":param autoencoder_mlp: Whether your model is an autoencoder + MLP model.\n",
       "Will take the 3rd of tuple output in this case. Only relevant for NN models.\n",
       "More info on autoencoders:\n",
       "https://forum.numer.ai/t/autoencoder-and-multitask-mlp-on-new-dataset-from-kaggle-jane-street/4338 \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SingleModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_test\n",
      "id                               \n",
      "n559bd06a8861222         0.506948\n",
      "n9d39dea58c9e3cf         0.492578\n"
     ]
    }
   ],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "test_paths = [\"test_assets/joblib_v2_example_model.joblib\"]\n",
    "for path in test_paths:\n",
    "    model = SingleModel(path, model_name=\"test\")\n",
    "    print(model.predict(dataf).get_prediction_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'.joblib': <function joblib.numpy_pickle.load(filename, mmap_mode=None)>,\n '.cbm': <bound method CatBoost.load_model of <catboost.core.CatBoost object>>,\n '.pkl': <function _pickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=())>,\n '.pickle': <function _pickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=())>,\n '.h5': functools.partial(<function load_model>, compile=False)}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SingleModel(test_paths[0], model_name=\"test\")\n",
    "model.suffix_to_model_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. WandbKerasModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is for a specific case. Namely, if you are logging Keras model using [Weights & Biases](https://wandb.ai/site) and want to download the best model for a specific run. `WandbKerasModel` wraps `SingleModel` and only adds additional logic for downloading models from Weights & Biases.\n",
    "\n",
    "To authenticate your W&B account you are given several options:\n",
    "1. Run `wandb login` in terminal and follow instructions ([docs](https://docs.wandb.ai/ref/cli/wandb-login)).\n",
    "2. Configure [global environment variable](https://docs.wandb.ai/guides/track/advanced/environment-variables) `\"WANDB_API_KEY\"`.\n",
    "3. Run `wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME)` and\n",
    "pass API key from [https://wandb.ai/authorize](https://wandb.ai/authorize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### WandbKerasModel\n",
       "\n",
       ">      WandbKerasModel (run_path:str, file_name:str='model-best.h5',\n",
       ">                       combine_preds=False, autoencoder_mlp=False,\n",
       ">                       replace=False, feature_cols:list=None)\n",
       "\n",
       "Download best .h5 model from Weights & Biases (W&B) run in local directory and make predictions.\n",
       "More info on W&B: https://wandb.ai/site\n",
       "\n",
       ":param run_path: W&B path structured as entity/project/run_id.\n",
       "Can be copied from the Overview tab of a W&B run.\n",
       "For more info: https://docs.wandb.ai/ref/app/pages/run-page#overview-tab \n",
       "\n",
       ":param file_name: Name of .h5 file as saved in W&B run.\n",
       "'model-best.h5' by default.\n",
       "File name can be found under files tab of W&B run. \n",
       "\n",
       ":param combine_preds: Whether to average predictions along column axis. Convenient when you want to predict the main target by averaging a multi-target model. \n",
       "\n",
       ":param autoencoder_mlp: Whether your model is an autoencoder + MLP model.\n",
       "Will take the 3rd of tuple output in this case. Only relevant for NN models. \n",
       "\n",
       "More info on autoencoders:\n",
       "https://forum.numer.ai/t/autoencoder-and-multitask-mlp-on-new-dataset-from-kaggle-jane-street/4338 \n",
       "\n",
       ":param replace: Replace any model files saved under the same file name with downloaded W&B run model. WARNING: Setting to True may overwrite models in your local environment. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### WandbKerasModel\n",
       "\n",
       ">      WandbKerasModel (run_path:str, file_name:str='model-best.h5',\n",
       ">                       combine_preds=False, autoencoder_mlp=False,\n",
       ">                       replace=False, feature_cols:list=None)\n",
       "\n",
       "Download best .h5 model from Weights & Biases (W&B) run in local directory and make predictions.\n",
       "More info on W&B: https://wandb.ai/site\n",
       "\n",
       ":param run_path: W&B path structured as entity/project/run_id.\n",
       "Can be copied from the Overview tab of a W&B run.\n",
       "For more info: https://docs.wandb.ai/ref/app/pages/run-page#overview-tab \n",
       "\n",
       ":param file_name: Name of .h5 file as saved in W&B run.\n",
       "'model-best.h5' by default.\n",
       "File name can be found under files tab of W&B run. \n",
       "\n",
       ":param combine_preds: Whether to average predictions along column axis. Convenient when you want to predict the main target by averaging a multi-target model. \n",
       "\n",
       ":param autoencoder_mlp: Whether your model is an autoencoder + MLP model.\n",
       "Will take the 3rd of tuple output in this case. Only relevant for NN models. \n",
       "\n",
       "More info on autoencoders:\n",
       "https://forum.numer.ai/t/autoencoder-and-multitask-mlp-on-new-dataset-from-kaggle-jane-street/4338 \n",
       "\n",
       ":param replace: Replace any model files saved under the same file name with downloaded W&B run model. WARNING: Setting to True may overwrite models in your local environment. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(WandbKerasModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# run_path = \"user123/project/abcd1234\"\n",
    "# model = WandbKerasModel(run_path=run_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. CSVSub\n",
    "\n",
    "This model is a wrapper for if you want to add predictions from external CSVs in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ExternalCSVs\n",
       "\n",
       ">      ExternalCSVs (data_directory:str='external_submissions')\n",
       "\n",
       "Load external submissions and add to NumerFrame. \n",
       "\n",
       "All csv files in this directory will be added to NumerFrame.\n",
       "Make sure all external predictions are prepared and ready for submission. i.e. IDs lining up and one column named 'prediction'. \n",
       "\n",
       ":param data_directory: Directory path for retrieving external submission."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ExternalCSVs\n",
       "\n",
       ">      ExternalCSVs (data_directory:str='external_submissions')\n",
       "\n",
       "Load external submissions and add to NumerFrame. \n",
       "\n",
       "All csv files in this directory will be added to NumerFrame.\n",
       "Make sure all external predictions are prepared and ready for submission. i.e. IDs lining up and one column named 'prediction'. \n",
       "\n",
       ":param data_directory: Directory path for retrieving external submission."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ExternalCSVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, the `external_submissions` directory contains `test_predictions.csv` with values from feature `target_thomas_20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f7f74e9d38498f862b091543fd29bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "External submissions:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_test_predictions.csv</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  prediction_test_predictions.csv\nid                                               \nn559bd06a8861222                         0.333333\nn9d39dea58c9e3cf                         0.500000"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "external = ExternalCSVs(data_directory=\"test_assets/external_submissions\")\n",
    "new_dataf = external.predict(dataf)\n",
    "new_dataf.get_prediction_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "assert new_dataf['prediction_test_predictions.csv'].astype(np.float32).equals(new_dataf['target_thomas_20'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no submissions are found in the given `data_directory` you should recieve a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ WARNING: No csvs found in directory <span style=\"color: #008000; text-decoration-color: #008000\">'Some_nonexisting_directory_12354321'</span>. ⚠\n</pre>\n",
      "text/plain": "⚠ WARNING: No csvs found in directory \u001b[32m'Some_nonexisting_directory_12354321'\u001b[0m. ⚠\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ExternalCSVs(data_directory=\"Some_nonexisting_directory_12354321\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. NumerBay\n",
    "\n",
    "This model is a wrapper for if you want to add predictions from NumerBay purchases.\n",
    "\n",
    "Currently only Numerai Classic submissions are supported. Numerai Signals will be supported in a future version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NumerBayCSVs\n",
       "\n",
       ">      NumerBayCSVs (data_directory:str='numerbay_submissions',\n",
       ">                    numerbay_product_full_names:list=None,\n",
       ">                    numerbay_username:str=None, numerbay_password:str=None,\n",
       ">                    numerbay_key_path:str=None,\n",
       ">                    ticker_col:str='bloomberg_ticker')\n",
       "\n",
       "Load NumerBay submissions and add to NumerFrame. \n",
       "\n",
       "Make sure to provide correct NumerBay credentials and that your purchases have been confirmed and artifacts are available for download. \n",
       "\n",
       ":param data_directory: Directory path for caching submission. Files not already present in the directory will be downloaded from NumerBay.\n",
       ":param numerbay_product_full_names: List of product full names (in the format of [category]-[product name]) to download from NumerBay. E.g. ['numerai-predictions-numerbay']\n",
       ":param numerbay_username: NumerBay username\n",
       ":param numerbay_password: NumerBay password\n",
       ":param numerbay_key_path: NumerBay encryption key json file path (exported from the profile page)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NumerBayCSVs\n",
       "\n",
       ">      NumerBayCSVs (data_directory:str='numerbay_submissions',\n",
       ">                    numerbay_product_full_names:list=None,\n",
       ">                    numerbay_username:str=None, numerbay_password:str=None,\n",
       ">                    numerbay_key_path:str=None,\n",
       ">                    ticker_col:str='bloomberg_ticker')\n",
       "\n",
       "Load NumerBay submissions and add to NumerFrame. \n",
       "\n",
       "Make sure to provide correct NumerBay credentials and that your purchases have been confirmed and artifacts are available for download. \n",
       "\n",
       ":param data_directory: Directory path for caching submission. Files not already present in the directory will be downloaded from NumerBay.\n",
       ":param numerbay_product_full_names: List of product full names (in the format of [category]-[product name]) to download from NumerBay. E.g. ['numerai-predictions-numerbay']\n",
       ":param numerbay_username: NumerBay username\n",
       ":param numerbay_password: NumerBay password\n",
       ":param numerbay_key_path: NumerBay encryption key json file path (exported from the profile page)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(NumerBayCSVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# nb_model = NumerBayCSVs(data_directory='/app/notebooks/tmp',\n",
    "#                         numerbay_product_full_names=['numerai-predictions-someproduct'],\n",
    "#                         numerbay_username=\"myusername\",\n",
    "#                         numerbay_password=\"mypassword\",\n",
    "#                         numerbay_key_path=\"/app/notebooks/tmp/numerbay.json\")\n",
    "# preds = nb_model.predict(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading all models in directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Joblib directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models, like `scikit-learn`, can conveniently be saved as `.joblib` files. This class automatically loads all `.joblib` files in a given folder and generates (averaged out) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### JoblibModel\n",
       "\n",
       ">      JoblibModel (model_directory:str, model_name:str=None,\n",
       ">                   feature_cols:list=None)\n",
       "\n",
       "Load and predict for arbitrary models in directory saved as .joblib.\n",
       "\n",
       "All loaded models should have a .predict method and accept the features present in the data.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### JoblibModel\n",
       "\n",
       ">      JoblibModel (model_directory:str, model_name:str=None,\n",
       ">                   feature_cols:list=None)\n",
       "\n",
       "Load and predict for arbitrary models in directory saved as .joblib.\n",
       "\n",
       "All loaded models should have a .predict method and accept the features present in the data.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(JoblibModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd635295e0d8459aa1abafc3287dde1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "JoblibModel: 'Joblib_LGB' prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DirectoryModel</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1074</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">275598</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mDirectoryModel\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1074\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m275598\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_Joblib_LGB</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.506948</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.492578</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  prediction_Joblib_LGB\nid                                     \nn559bd06a8861222               0.506948\nn9d39dea58c9e3cf               0.492578"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\", metadata={\"version\": 2})\n",
    "model = JoblibModel(\"test_assets\", model_name=\"Joblib_LGB\")\n",
    "predictions = model.predict(dataf).get_prediction_data\n",
    "assert predictions['prediction_Joblib_LGB'].between(0, 1).all()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Catboost directory (.cbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model setup loads all `CatBoost` (`.cbm`) models present in a given directory and makes (averaged out) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### CatBoostModel\n",
       "\n",
       ">      CatBoostModel (model_directory:str, model_name:str=None,\n",
       ">                     feature_cols:list=None)\n",
       "\n",
       "Load and predict with all .cbm models (CatBoostRegressor) in directory.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### CatBoostModel\n",
       "\n",
       ">      CatBoostModel (model_directory:str, model_name:str=None,\n",
       ">                     feature_cols:list=None)\n",
       "\n",
       "Load and predict with all .cbm models (CatBoostRegressor) in directory.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CatBoostModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from numerblox.preprocessing import GroupStatsPreProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TargetSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">003134</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mTargetSelectionPreProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m314\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m003134\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8192208c80040e6a9ced0f191f4fc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "CatBoostModel: 'CB' prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/libs/data/model_dataset_compatibility.cpp:72: Feature feature_intelligence_mean is present in model but not in pool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m processed_dataf \u001b[38;5;241m=\u001b[39m TargetSelectionPreProcessor([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m])(dataf)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_assets\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_dataf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_prediction_data\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_CB\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m      7\u001b[0m predictions\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/numerblox/numerblox/preprocessing.py:57\u001b[0m, in \u001b[0;36mdisplay_processor_info.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     56\u001b[0m     tic \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m tic)\n\u001b[1;32m     59\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn [6], line 41\u001b[0m, in \u001b[0;36mDirectoryModel.predict\u001b[0;34m(self, dataf, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_cols \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_cols \u001b[38;5;28;01melse\u001b[39;00m dataf\u001b[38;5;241m.\u001b[39mfeature_cols\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m tqdm(models, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Check for if model output is a Pandas DataFrame\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(predictions, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/catboost/core.py:2596\u001b[0m, in \u001b[0;36mCatBoost.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, prediction_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRawFormulaVal\u001b[39m\u001b[38;5;124m'\u001b[39m, ntree_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ntree_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, thread_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;124;03m    Predict with data.\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;124;03m              with probability for every class for each object.\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/catboost/core.py:2544\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2541\u001b[0m data, data_is_single_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[0;32m-> 2544\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m data_is_single_object \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/catboost/core.py:1811\u001b[0m, in \u001b[0;36m_CatBoostBase._base_predict\u001b[0;34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_base_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type):\n\u001b[0;32m-> 1811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_catboost.pyx:4759\u001b[0m, in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4766\u001b[0m, in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/libs/data/model_dataset_compatibility.cpp:72: Feature feature_intelligence_mean is present in model but not in pool."
     ]
    }
   ],
   "source": [
    "# Example on NumerFrame\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\", {\"version\": 1})\n",
    "processed_dataf = GroupStatsPreProcessor()(dataf)\n",
    "model = CatBoostModel(\"test_assets\", model_name=\"CB\")\n",
    "predictions = model.predict(processed_dataf).get_prediction_data\n",
    "assert predictions['prediction_CB'].between(0, 1).all()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. LightGBM directory (.lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model setup loads all `LightGBM` (`.lgb`) models present in a given directory and makes (averaged out) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LGBMModel\n",
       "\n",
       ">      LGBMModel (model_directory:str, model_name:str=None,\n",
       ">                 feature_cols:list=None)\n",
       "\n",
       "Load and predict with all .lgb models (LightGBM) in directory.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LGBMModel\n",
       "\n",
       ">      LGBMModel (model_directory:str, model_name:str=None,\n",
       ">                 feature_cols:list=None)\n",
       "\n",
       "Load and predict with all .lgb models (LightGBM) in directory.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LGBMModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "model = LGBMModel(\"test_assets\", model_name=\"LGB\")\n",
    "predictions = model.predict(dataf).get_prediction_data\n",
    "assert predictions['prediction_LGB'].between(0, 1).all()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a baseline is always an important step for data science problems. This section introduces models that should only be used a baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. ConstantModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model simply outputs a constant of your choice. Convenient for setting classification baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ConstantModel\n",
       "\n",
       ">      ConstantModel (constant:float=0.5, model_name:str=None)\n",
       "\n",
       "WARNING: Only use this Model for testing purposes. \n",
       "\n",
       "Create constant prediction.\n",
       "\n",
       ":param constant: Value for constant prediction. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ConstantModel\n",
       "\n",
       ">      ConstantModel (constant:float=0.5, model_name:str=None)\n",
       "\n",
       "WARNING: Only use this Model for testing purposes. \n",
       "\n",
       "Create constant prediction.\n",
       "\n",
       ":param constant: Value for constant prediction. \n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ConstantModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "constant = 0.85\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "constant_model = ConstantModel(constant=constant)\n",
    "predictions = constant_model.predict(dataf).get_prediction_data\n",
    "assert (predictions.to_numpy() == constant).all()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. RandomModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model returns uniformly distributed predictions in range $[0...1)$. Solid naive baseline for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RandomModel\n",
       "\n",
       ">      RandomModel (model_name:str=None)\n",
       "\n",
       "WARNING: Only use this Model for testing purposes. \n",
       "\n",
       "Create uniformly distributed predictions.\n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RandomModel\n",
       "\n",
       ">      RandomModel (model_name:str=None)\n",
       "\n",
       "WARNING: Only use this Model for testing purposes. \n",
       "\n",
       "Create uniformly distributed predictions.\n",
       "\n",
       ":param model_name: Name that will be used to create column names and for display purposes."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(RandomModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "random_model = RandomModel()\n",
    "predictions = random_model.predict(dataf).get_prediction_data\n",
    "assert predictions['prediction_random'].between(0, 1).all()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Example (validation) predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Model performs downloading and adding of example predictions for Numerai Classic. Convenient when you are constructing a `ModelPipeline` and want to include example predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ExamplePredictionsModel\n",
       "\n",
       ">      ExamplePredictionsModel\n",
       ">                               (file_name:str='example_validation_predictions.p\n",
       ">                               arquet',\n",
       ">                               data_directory:str='example_predictions_model',\n",
       ">                               round_num:int=None)\n",
       "\n",
       "Load example predictions and add to NumerFrame. \n",
       "\n",
       ":param file_name: File to download from NumerAPI.\n",
       "'example_validation_predictions.parquet' by default. \n",
       "\n",
       ":param data_directory: Directory path to download example predictions to or directory where example data already exists. \n",
       "\n",
       ":param round_num: Optional round number. Downloads most recent round by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ExamplePredictionsModel\n",
       "\n",
       ">      ExamplePredictionsModel\n",
       ">                               (file_name:str='example_validation_predictions.p\n",
       ">                               arquet',\n",
       ">                               data_directory:str='example_predictions_model',\n",
       ">                               round_num:int=None)\n",
       "\n",
       "Load example predictions and add to NumerFrame. \n",
       "\n",
       ":param file_name: File to download from NumerAPI.\n",
       "'example_validation_predictions.parquet' by default. \n",
       "\n",
       ":param data_directory: Directory path to download example predictions to or directory where example data already exists. \n",
       "\n",
       ":param round_num: Optional round number. Downloads most recent round by default."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ExamplePredictionsModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| eval: false\n",
    "# Download validation data\n",
    "downloader = NumeraiClassicDownloader(\"example_predictions_model\")\n",
    "val_file = \"numerai_validation_data.parquet\"\n",
    "val_save_path = f\"{str(downloader.dir)}/{val_file}\"\n",
    "downloader.download_single_dataset(filename=val_file,\n",
    "                                   dest_path=val_save_path)\n",
    "\n",
    "# Load validation data and add example predictions\n",
    "dataf = create_numerframe(val_save_path)\n",
    "example_model = ExamplePredictionsModel()\n",
    "predictions = example_model.predict(dataf).get_prediction_data\n",
    "assert predictions['prediction_example'].between(0, 1).all()\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different ways to implement new models. Both have their own conveniences and use cases.\n",
    "\n",
    "**4.1.** Inherit from `BaseModel` (custom prediction logic).\n",
    "\n",
    "**4.2.** Inherit from `DirectoryModel` (make predictions for all models in directory with given file suffix. Prediction logic will already be implemented. Only implement model loading logic).\n",
    "\n",
    "**4.1. (From BaseModel)** works well when you have no or only a single file that you use for generating predictions.\n",
    "\n",
    "Examples:\n",
    "1. Loading a model is not relevant or your model is already loaded in memory.\n",
    "2. You would like predictions for one model loaded from disk.\n",
    "3. The object you are loading already aggregates multiple models and transformation steps (such as [scikit-learn FeatureUnion](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)).\n",
    "\n",
    "**4.2. (From DirectoryModel)** is convenient when you have a lot of similar models in a directory and want to generate predictions for all of them.\n",
    "\n",
    "Examples:\n",
    "1. You have multiple similar models saved through a cross validation process.\n",
    "2. You have a bagging strategy where a lot of models trained on slightly different data or with different initializations should are averaged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. From BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrary models can be instantiated and used for prediction generation by inheriting from `BaseModel`. Arbitrary logic (model loading, prediction, etc.) can be defined in `.predict` as long as the method takes a `NumerFrame` as input and outputs a `NumerFrame`.\n",
    "The model should be able to typecheck by adding the `@typeguard.typechecked` decorator at the top of the class.\n",
    "\n",
    "For clear console output we recommend adding the `@display_processor_info` decorator to the `.predict` method.\n",
    "\n",
    "If your model does not involve reading files from disk specify `model_directory=\"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AwesomeModel\n",
       "\n",
       ">      AwesomeModel (model_directory:str, model_name:str=None,\n",
       ">                    feature_cols:list=None)\n",
       "\n",
       "TEMPLATE - Predict with arbitrary prediction logic and model formats.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AwesomeModel\n",
       "\n",
       ">      AwesomeModel (model_directory:str, model_name:str=None,\n",
       ">                    feature_cols:list=None)\n",
       "\n",
       "TEMPLATE - Predict with arbitrary prediction logic and model formats.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(AwesomeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. From DirectoryModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to implement a setup similar to `JoblibModel` and `CatBoostModel`. Namely, load in all models of a certain type from a directory, predict for all and take the average. If this is your use case, inherit from `DirectoryModel` and be sure to implement the `.load_models` method.\n",
    "\n",
    "For a `DirectoryModel` you should specify a `file_suffix` (like `.joblib` or `.cbm`) which will be used to store all available models in `self.model_paths`.\n",
    "\n",
    "The `.predict` method will in this case already be implemented, but can be overridden if the prediction logic is more complex. For example, if you want to apply weighted averaging or a geometric mean for models within a given directory.\n",
    "\n",
    "\n",
    "Like with inheriting from `BaseModel`, This Model should also be able to typecheck by adding the `@typeguard.typechecked` decorator at the top of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AwesomeDirectoryModel\n",
       "\n",
       ">      AwesomeDirectoryModel (model_directory:str, model_name:str=None,\n",
       ">                             feature_cols:list=None)\n",
       "\n",
       "TEMPLATE - Load in all models of arbitrary file format and predict for all.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AwesomeDirectoryModel\n",
       "\n",
       ">      AwesomeDirectoryModel (model_directory:str, model_name:str=None,\n",
       ">                             feature_cols:list=None)\n",
       "\n",
       "TEMPLATE - Load in all models of arbitrary file format and predict for all.\n",
       "\n",
       ":param model_directory: Main directory from which to read in models. \n",
       "\n",
       ":param model_name: Name that will be used to define column names and for display purposes. \n",
       "\n",
       ":param feature_cols: optional list of features to use for prediction. Selects all feature columns (i.e. column names with prefix 'feature') by default."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(AwesomeDirectoryModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
