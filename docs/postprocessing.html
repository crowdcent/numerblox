---

title: Postprocessing


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/05_postprocessing.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_postprocessing.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="o">%</span><span class="k">load_ext</span> nb_black
<span class="o">%</span><span class="k">load_ext</span> lab_black
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="a5262dec-5cbf-40d8-b0ab-3ebe6bcb57ae"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#a5262dec-5cbf-40d8-b0ab-3ebe6bcb57ae');

            setTimeout(function() {
                var nbb_cell_id = 1;
                var nbb_unformatted_code = "%load_ext autoreload\n%autoreload 2\n%load_ext nb_black\n%load_ext lab_black";
                var nbb_formatted_code = "%load_ext autoreload\n%autoreload 2\n%load_ext nb_black\n%load_ext lab_black";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The postprocessing procedure is very similar to preprocessing.</p>
<p>The only difference between a postprocessing step and a preprocessing step is that preprocessing works on <code>feature_</code> columns while postprocessing manipulates <code>prediction_</code> columns.</p>
<p>Therefore, we also inherit from <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a> for postprocessing. The PostProcessor should take a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> as input and output a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> where either:</p>
<ol>
<li><code>prediction_</code> columns are manipulated or</li>
<li>A new prediction column is added with prefix <code>prediction_</code>.</li>
</ol>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Common-postprocessing-steps">1. Common postprocessing steps<a class="anchor-link" href="#1.-Common-postprocessing-steps"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.1.-Version-agnostic">1.1. Version agnostic<a class="anchor-link" href="#1.1.-Version-agnostic"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.1.1.-Ensembling">1.1.1. Ensembling<a class="anchor-link" href="#1.1.1.-Ensembling"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Multiple prediction results can be ensembled in multiple ways, but we provide the most common use cases here.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MeanEnsembler" class="doc_header"><code>class</code> <code>MeanEnsembler</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L21" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MeanEnsembler</code>(<strong><code>cols</code></strong>:<code>list</code>, <strong><code>final_col_name</code></strong>:<code>str</code>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>Take simple mean of multiple cols and store in new col.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="06be40db-a132-444f-a31d-7743c9d809a5"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#06be40db-a132-444f-a31d-7743c9d809a5');

            setTimeout(function() {
                var nbb_cell_id = 5;
                var nbb_unformatted_code = "#export\n@typechecked\nclass MeanEnsembler(BaseProcessor):\n    \"\"\" Take simple mean of multiple cols and store in new col. \"\"\"\n    def __init__(self, cols: list, final_col_name: str):\n        super(MeanEnsembler, self).__init__()\n        self.cols = cols\n        self.final_col_name = final_col_name\n        assert final_col_name.startswith(\"prediction\"), f\"final_col name should start with 'prediction'. Got {final_col_name}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        dataset.dataf.loc[:, self.final_col_name] = dataset.dataf.loc[:, self.cols].mean(axis=1)\n        rich_print(f\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\")\n        return Dataset(**dataset.__dict__)";
                var nbb_formatted_code = "# export\n@typechecked\nclass MeanEnsembler(BaseProcessor):\n    \"\"\"Take simple mean of multiple cols and store in new col.\"\"\"\n\n    def __init__(self, cols: list, final_col_name: str):\n        super(MeanEnsembler, self).__init__()\n        self.cols = cols\n        self.final_col_name = final_col_name\n        assert final_col_name.startswith(\n            \"prediction\"\n        ), f\"final_col name should start with 'prediction'. Got {final_col_name}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        dataset.dataf.loc[:, self.final_col_name] = dataset.dataf.loc[\n            :, self.cols\n        ].mean(axis=1)\n        rich_print(\n            f\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n        )\n        return Dataset(**dataset.__dict__)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.1.2.-Feature-Neutralization">1.1.2. Feature Neutralization<a class="anchor-link" href="#1.1.2.-Feature-Neutralization"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Classic feature neutralization (subtracting linear model from scores)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FeatureNeutralizer" class="doc_header"><code>class</code> <code>FeatureNeutralizer</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L37" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FeatureNeutralizer</code>(<strong><code>feature_names</code></strong>:<code>list</code>, <strong><code>pred_name</code></strong>:<code>str</code>=<em><code>'prediction'</code></em>, <strong><code>proportion</code></strong>=<em><code>0.5</code></em>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>Feature</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="9e0dd9bb-875f-426f-a37d-bf2ce06aa0da"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#9e0dd9bb-875f-426f-a37d-bf2ce06aa0da');

            setTimeout(function() {
                var nbb_cell_id = 6;
                var nbb_unformatted_code = "#export\n@typechecked\nclass FeatureNeutralizer(BaseProcessor):\n    \"\"\" Feature \"\"\"\n    def __init__(self, feature_names: list,\n                 pred_name: str = \"prediction\",\n                 proportion=0.5):\n        super(FeatureNeutralizer, self).__init__()\n        assert 0. <= proportion <= 1., f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n        self.proportion = proportion\n        self.feature_names = feature_names\n        self.pred_name = pred_name\n        self.new_col_name = f\"{self.pred_name}_neutralized_{self.proportion}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        neutralized_preds = dataset.dataf.groupby(\"era\")\\\n            .apply(lambda x: self.normalize_and_neutralize(x, [self.pred_name], self.feature_names))\n        dataset.dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(neutralized_preds)\n        rich_print(f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\")\n        rich_print(f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\")\n        return Dataset(**dataset.__dict__)\n\n    def _neutralize(self, df, columns, by):\n        scores = df[columns]\n        exposures = df[by].values\n        scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n        return scores / scores.std()\n\n    @staticmethod\n    def _normalize(dataf: pd.DataFrame):\n        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n        return sp.norm.ppf(normalized_ranks)\n\n    def normalize_and_neutralize(self, df, columns, by):\n        # Convert the scores to a normal distribution\n        df[columns] = self._normalize(df[columns])\n        df[columns] = self._neutralize(df, columns, by)\n        return df[columns]";
                var nbb_formatted_code = "# export\n@typechecked\nclass FeatureNeutralizer(BaseProcessor):\n    \"\"\"Feature\"\"\"\n\n    def __init__(\n        self, feature_names: list, pred_name: str = \"prediction\", proportion=0.5\n    ):\n        super(FeatureNeutralizer, self).__init__()\n        assert (\n            0.0 <= proportion <= 1.0\n        ), f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n        self.proportion = proportion\n        self.feature_names = feature_names\n        self.pred_name = pred_name\n        self.new_col_name = f\"{self.pred_name}_neutralized_{self.proportion}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        neutralized_preds = dataset.dataf.groupby(\"era\").apply(\n            lambda x: self.normalize_and_neutralize(\n                x, [self.pred_name], self.feature_names\n            )\n        )\n        dataset.dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\n            neutralized_preds\n        )\n        rich_print(\n            f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\"\n        )\n        rich_print(\n            f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\"\n        )\n        return Dataset(**dataset.__dict__)\n\n    def _neutralize(self, df, columns, by):\n        scores = df[columns]\n        exposures = df[by].values\n        scores = scores - self.proportion * exposures.dot(\n            np.linalg.pinv(exposures).dot(scores)\n        )\n        return scores / scores.std()\n\n    @staticmethod\n    def _normalize(dataf: pd.DataFrame):\n        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n        return sp.norm.ppf(normalized_ranks)\n\n    def normalize_and_neutralize(self, df, columns, by):\n        # Convert the scores to a normal distribution\n        df[columns] = self._normalize(df[columns])\n        df[columns] = self._neutralize(df, columns, by)\n        return df[columns]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;test_assets/mini_numerai_version_1_data.csv&quot;</span><span class="p">))</span>
<span class="n">test_dataset</span><span class="o">.</span><span class="n">dataf</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">dataf</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="02a42672-e847-4186-8c5a-fb88805c77f1"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#02a42672-e847-4186-8c5a-fb88805c77f1');

            setTimeout(function() {
                var nbb_cell_id = 7;
                var nbb_unformatted_code = "test_dataset = Dataset(pd.read_csv(\"test_assets/mini_numerai_version_1_data.csv\"))\ntest_dataset.dataf.loc[:, 'prediction'] = np.random.uniform(size=len(test_dataset.dataf))";
                var nbb_formatted_code = "test_dataset = Dataset(pd.read_csv(\"test_assets/mini_numerai_version_1_data.csv\"))\ntest_dataset.dataf.loc[:, \"prediction\"] = np.random.uniform(\n    size=len(test_dataset.dataf)\n)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ft</span> <span class="o">=</span> <span class="n">FeatureNeutralizer</span><span class="p">(</span><span class="n">feature_names</span><span class="o">=</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">feature_cols</span><span class="p">,</span> <span class="n">pred_name</span><span class="o">=</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="n">proportion</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">new_dataset</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">ðŸ¤– Neutralized <span style="color: #000080; text-decoration-color: #000080; font-weight: bold">'prediction'</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold"> with proportion </span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold">'0.8'</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold"> ðŸ¤–</span>
</pre>

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">New neutralized column = <span style="color: #008000; text-decoration-color: #008000; font-weight: bold">'prediction_neutralized_0.8'</span>.
</pre>

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">âœ… Finished step <span style="font-weight: bold">FeatureNeutralizer</span>. Output <span style="color: #808000; text-decoration-color: #808000">shape</span>=<span style="font-weight: bold">(</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">10</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">316</span><span style="font-weight: bold">)</span>. Time taken for step: 
<span style="color: #000080; text-decoration-color: #000080; font-weight: bold">0:00:00</span><span style="color: #000080; text-decoration-color: #000080">.</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold">043276</span>. âœ…
</pre>

</div>

</div>

<div class="output_area">




<div id="c6ec51e4-4c85-42bf-ab8b-29db1b5e908a"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#c6ec51e4-4c85-42bf-ab8b-29db1b5e908a');

            setTimeout(function() {
                var nbb_cell_id = 8;
                var nbb_unformatted_code = "ft = FeatureNeutralizer(feature_names=test_dataset.feature_cols, pred_name='prediction', proportion=0.8)\nnew_dataset = ft.transform(test_dataset);";
                var nbb_formatted_code = "ft = FeatureNeutralizer(\n    feature_names=test_dataset.feature_cols, pred_name=\"prediction\", proportion=0.8\n)\nnew_dataset = ft.transform(test_dataset)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="s2">&quot;prediction_neutralized_0.8&quot;</span> <span class="ow">in</span> <span class="n">new_dataset</span><span class="o">.</span><span class="n">prediction_cols</span>
<span class="k">assert</span> <span class="mf">0.</span> <span class="ow">in</span> <span class="n">new_dataset</span><span class="o">.</span><span class="n">get_prediction_data</span><span class="p">[</span><span class="s1">&#39;prediction_neutralized_0.8&#39;</span><span class="p">]</span>
<span class="k">assert</span> <span class="mf">1.</span> <span class="ow">in</span> <span class="n">new_dataset</span><span class="o">.</span><span class="n">get_prediction_data</span><span class="p">[</span><span class="s1">&#39;prediction_neutralized_0.8&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="9ca4a4bf-c397-42b0-aeaf-e1eb20b52bf3"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#9ca4a4bf-c397-42b0-aeaf-e1eb20b52bf3');

            setTimeout(function() {
                var nbb_cell_id = 9;
                var nbb_unformatted_code = "assert \"prediction_neutralized_0.8\" in new_dataset.prediction_cols\nassert 0. in new_dataset.get_prediction_data['prediction_neutralized_0.8']\nassert 1. in new_dataset.get_prediction_data['prediction_neutralized_0.8']";
                var nbb_formatted_code = "assert \"prediction_neutralized_0.8\" in new_dataset.prediction_cols\nassert 0.0 in new_dataset.get_prediction_data[\"prediction_neutralized_0.8\"]\nassert 1.0 in new_dataset.get_prediction_data[\"prediction_neutralized_0.8\"]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_dataset</span><span class="o">.</span><span class="n">prediction_cols</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;prediction&#39;, &#39;prediction_neutralized_0.8&#39;]</pre>
</div>

</div>

<div class="output_area">




<div id="ae86c82f-2caf-4ccf-a9c9-b0545dd7d9af"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#ae86c82f-2caf-4ccf-a9c9-b0545dd7d9af');

            setTimeout(function() {
                var nbb_cell_id = 10;
                var nbb_unformatted_code = "new_dataset.prediction_cols";
                var nbb_formatted_code = "new_dataset.prediction_cols";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_dataset</span><span class="o">.</span><span class="n">get_prediction_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prediction</th>
      <th>prediction_neutralized_0.8</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.895532</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.894037</td>
      <td>0.815053</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.170013</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.632977</td>
      <td>0.461802</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.392452</td>
      <td>0.184947</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.676905</td>
      <td>0.538198</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.682949</td>
      <td>0.617129</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.402920</td>
      <td>0.294970</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.845842</td>
      <td>0.705030</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.415415</td>
      <td>0.382871</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">




<div id="c06505b0-3ded-4d26-ad0c-f27ffa7183a5"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#c06505b0-3ded-4d26-ad0c-f27ffa7183a5');

            setTimeout(function() {
                var nbb_cell_id = 11;
                var nbb_unformatted_code = "new_dataset.get_prediction_data";
                var nbb_formatted_code = "new_dataset.get_prediction_data";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.1.3.-Feature-Penalization">1.1.3. Feature Penalization<a class="anchor-link" href="#1.1.3.-Feature-Penalization"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FeaturePenalizer" class="doc_header"><code>class</code> <code>FeaturePenalizer</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L77" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FeaturePenalizer</code>(<strong><code>model_list</code></strong>:<code>list</code>, <strong><code>max_exposure</code></strong>:<code>float</code>, <strong><code>risky_feature_names</code></strong>:<code>list</code>=<em><code>None</code></em>, <strong><code>pred_name</code></strong>:<code>str</code>=<em><code>'prediction'</code></em>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>Feature penalization with Tensorflow.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="0a677150-4393-4326-a730-f2867b40905d"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#0a677150-4393-4326-a730-f2867b40905d');

            setTimeout(function() {
                var nbb_cell_id = 12;
                var nbb_unformatted_code = "#export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\" Feature penalization with Tensorflow. \"\"\"\n    def __init__(self, model_list: list, max_exposure: float, risky_feature_names: list = None, pred_name: str = \"prediction\"):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert 0. <= max_exposure <= 1., f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = dataset.feature_cols if not self.risky_feature_names else self.risky_feature_names\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                            dataset.dataf,\n                            self.pred_name,\n                            neutralizers=risky_feature_names,\n                            max_exp=self.max_exposure,\n                        )\n            new_pred_col = f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(self, df: pd.DataFrame,\n                             column: str = \"prediction\",\n                             neutralizers: list = None,\n                             normalize=True,\n                             gaussianize=True,\n                             era_col=\"era\",\n                             max_exp: float = 0.1\n                             ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(scores, exposure_values,\n                                              max_exp, len(neutralizers), None)\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(np.concatenate(neutralized),\n                                   columns=[column], index=df.index)\n        return predictions\n\n    def reduce_exposure(self, prediction, features, max_exp, input_size=50, weights=None):\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Input(input_size),\n            tf.keras.experimental.LinearModel(use_bias=False),\n        ])\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:,None] - model(feats), model.get_weights()\n\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps)) +\n                                 tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps)))\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_formatted_code = "# export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\"Feature penalization with Tensorflow.\"\"\"\n\n    def __init__(\n        self,\n        model_list: list,\n        max_exposure: float,\n        risky_feature_names: list = None,\n        pred_name: str = \"prediction\",\n    ):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert (\n            0.0 <= max_exposure <= 1.0\n        ), f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = (\n            dataset.feature_cols\n            if not self.risky_feature_names\n            else self.risky_feature_names\n        )\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                dataset.dataf,\n                self.pred_name,\n                neutralizers=risky_feature_names,\n                max_exp=self.max_exposure,\n            )\n            new_pred_col = (\n                f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            )\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(\n        self,\n        df: pd.DataFrame,\n        column: str = \"prediction\",\n        neutralizers: list = None,\n        normalize=True,\n        gaussianize=True,\n        era_col=\"era\",\n        max_exp: float = 0.1,\n    ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(\n                scores, exposure_values, max_exp, len(neutralizers), None\n            )\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(\n            np.concatenate(neutralized), columns=[column], index=df.index\n        )\n        return predictions\n\n    def reduce_exposure(\n        self, prediction, features, max_exp, input_size=50, weights=None\n    ):\n        model = tf.keras.models.Sequential(\n            [\n                tf.keras.layers.Input(input_size),\n                tf.keras.experimental.LinearModel(use_bias=False),\n            ]\n        )\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:, None] - model(feats), model.get_weights()\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\n            )\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="9c81b651-3777-4547-a334-2ebcb7c83a69"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#9c81b651-3777-4547-a334-2ebcb7c83a69');

            setTimeout(function() {
                var nbb_cell_id = 12;
                var nbb_unformatted_code = "#export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\" Feature penalization with Tensorflow. \"\"\"\n    def __init__(self, model_list: list, max_exposure: float, risky_feature_names: list = None, pred_name: str = \"prediction\"):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert 0. <= max_exposure <= 1., f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = dataset.feature_cols if not self.risky_feature_names else self.risky_feature_names\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                            dataset.dataf,\n                            self.pred_name,\n                            neutralizers=risky_feature_names,\n                            max_exp=self.max_exposure,\n                        )\n            new_pred_col = f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(self, df: pd.DataFrame,\n                             column: str = \"prediction\",\n                             neutralizers: list = None,\n                             normalize=True,\n                             gaussianize=True,\n                             era_col=\"era\",\n                             max_exp: float = 0.1\n                             ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(scores, exposure_values,\n                                              max_exp, len(neutralizers), None)\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(np.concatenate(neutralized),\n                                   columns=[column], index=df.index)\n        return predictions\n\n    def reduce_exposure(self, prediction, features, max_exp, input_size=50, weights=None):\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Input(input_size),\n            tf.keras.experimental.LinearModel(use_bias=False),\n        ])\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:,None] - model(feats), model.get_weights()\n\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps)) +\n                                 tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps)))\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_formatted_code = "# export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\"Feature penalization with Tensorflow.\"\"\"\n\n    def __init__(\n        self,\n        model_list: list,\n        max_exposure: float,\n        risky_feature_names: list = None,\n        pred_name: str = \"prediction\",\n    ):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert (\n            0.0 <= max_exposure <= 1.0\n        ), f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = (\n            dataset.feature_cols\n            if not self.risky_feature_names\n            else self.risky_feature_names\n        )\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                dataset.dataf,\n                self.pred_name,\n                neutralizers=risky_feature_names,\n                max_exp=self.max_exposure,\n            )\n            new_pred_col = (\n                f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            )\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(\n        self,\n        df: pd.DataFrame,\n        column: str = \"prediction\",\n        neutralizers: list = None,\n        normalize=True,\n        gaussianize=True,\n        era_col=\"era\",\n        max_exp: float = 0.1,\n    ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(\n                scores, exposure_values, max_exp, len(neutralizers), None\n            )\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(\n            np.concatenate(neutralized), columns=[column], index=df.index\n        )\n        return predictions\n\n    def reduce_exposure(\n        self, prediction, features, max_exp, input_size=50, weights=None\n    ):\n        model = tf.keras.models.Sequential(\n            [\n                tf.keras.layers.Input(input_size),\n                tf.keras.experimental.LinearModel(use_bias=False),\n            ]\n        )\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:, None] - model(feats), model.get_weights()\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\n            )\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.2.-Version-1-specific">1.2. Version 1 specific<a class="anchor-link" href="#1.2.-Version-1-specific"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.3.-Version-2-specific">1.3. Version 2 specific<a class="anchor-link" href="#1.3.-Version-2-specific"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.4.-Signals-specific">1.4. Signals specific<a class="anchor-link" href="#1.4.-Signals-specific"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Custom-PostProcessors">2. Custom PostProcessors<a class="anchor-link" href="#2.-Custom-PostProcessors"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are an almost unlimited number of ways to postprocess data. We invite the Numerai community to develop Numerai Classic and Signals preprocessors for <code>numerai-blocks</code>.</p>
<p>A new PostProcessor should inherit from <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a> and implement a <code>transform</code> method. The <code>transform</code> method should take a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> as input and return a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> object as output. An example is given below.</p>
<p>We recommend adding <code>@typechecked</code> at the top of a new PostProcessor class to enforce types and provide useful debugging stacktraces.</p>
<p>To enable fancy logging output. Add the <code>@display_processor_info</code> decorator to the <code>transform</code> method.</p>
<p>Note that arbitrary metadata can be added or changed in the <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> class during a postprocessing step.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AwesomePostProcessor" class="doc_header"><code>class</code> <code>AwesomePostProcessor</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L182" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AwesomePostProcessor</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<ul>
<li>TEMPLATE -
Do some awesome postprocessing.</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="7ac84d82-6166-404b-8f8e-83f5f11554a5"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#7ac84d82-6166-404b-8f8e-83f5f11554a5');

            setTimeout(function() {
                var nbb_cell_id = 13;
                var nbb_unformatted_code = "#export\n@typechecked\nclass AwesomePostProcessor(BaseProcessor):\n    \"\"\"\n    - TEMPLATE -\n    Do some awesome postprocessing.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(AwesomePostProcessor, self).__init__()\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        # Do processing\n        ...\n        # Add new column for manipulated data (optional)\n        new_column_name = \"NEW_COLUMN_NAME\"\n        dataset.dataf.loc[:, f\"prediction_{new_column_name}\"] = ...\n        ...\n        # Parse all contents of Dataset to the next pipeline step\n        return Dataset(**dataset.__dict__)";
                var nbb_formatted_code = "# export\n@typechecked\nclass AwesomePostProcessor(BaseProcessor):\n    \"\"\"\n    - TEMPLATE -\n    Do some awesome postprocessing.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(AwesomePostProcessor, self).__init__()\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        # Do processing\n        ...\n        # Add new column for manipulated data (optional)\n        new_column_name = \"NEW_COLUMN_NAME\"\n        dataset.dataf.loc[:, f\"prediction_{new_column_name}\"] = ...\n        ...\n        # Parse all contents of Dataset to the next pipeline step\n        return Dataset(**dataset.__dict__)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
</div>
 

