---

title: Postprocessing


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/05_postprocessing.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_postprocessing.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="o">%</span><span class="k">load_ext</span> nb_black
<span class="o">%</span><span class="k">load_ext</span> lab_black
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="52263096-90e5-41e4-ad17-3a70b3c5a796"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#52263096-90e5-41e4-ad17-3a70b3c5a796');

            setTimeout(function() {
                var nbb_cell_id = 1;
                var nbb_unformatted_code = "%load_ext autoreload\n%autoreload 2\n%load_ext nb_black\n%load_ext lab_black";
                var nbb_formatted_code = "%load_ext autoreload\n%autoreload 2\n%load_ext nb_black\n%load_ext lab_black";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The postprocessing procedure is very similar to preprocessing.</p>
<p>The only difference between a postprocessing step and a preprocessing step is that preprocessing works on <code>feature_</code> columns while postprocessing manipulates <code>prediction_</code> columns.</p>
<p>Therefore, we also inherit from <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a> for postprocessing. The PostProcessor should take a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> as input and output a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> where either:</p>
<ol>
<li><code>prediction_</code> columns are manipulated or</li>
<li>A new prediction column is added with prefix <code>prediction_</code>.</li>
</ol>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Common-postprocessing-steps">1. Common postprocessing steps<a class="anchor-link" href="#1.-Common-postprocessing-steps"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.1.-Version-agnostic">1.1. Version agnostic<a class="anchor-link" href="#1.1.-Version-agnostic"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.1.1.-Ensembling">1.1.1. Ensembling<a class="anchor-link" href="#1.1.1.-Ensembling"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Multiple prediction results can be ensembled in multiple ways, but we provide the most common use cases here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Simple-Mean">Simple Mean<a class="anchor-link" href="#Simple-Mean"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MeanEnsembler" class="doc_header"><code>class</code> <code>MeanEnsembler</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L21" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MeanEnsembler</code>(<strong><code>cols</code></strong>:<code>list</code>, <strong><code>final_col_name</code></strong>:<code>str</code>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>Take simple mean of multiple cols and store in new col.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="3329861a-2efa-4cfb-b765-31efcd9f3b52"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#3329861a-2efa-4cfb-b765-31efcd9f3b52');

            setTimeout(function() {
                var nbb_cell_id = 5;
                var nbb_unformatted_code = "#export\n@typechecked\nclass MeanEnsembler(BaseProcessor):\n    \"\"\" Take simple mean of multiple cols and store in new col. \"\"\"\n    def __init__(self, cols: list, final_col_name: str):\n        super(MeanEnsembler, self).__init__()\n        self.cols = cols\n        self.final_col_name = final_col_name\n        assert final_col_name.startswith(\"prediction\"), f\"final_col name should start with 'prediction'. Got {final_col_name}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        dataset.dataf.loc[:, self.final_col_name] = dataset.dataf.loc[:, self.cols].mean(axis=1)\n        rich_print(f\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\")\n        return Dataset(**dataset.__dict__)";
                var nbb_formatted_code = "# export\n@typechecked\nclass MeanEnsembler(BaseProcessor):\n    \"\"\"Take simple mean of multiple cols and store in new col.\"\"\"\n\n    def __init__(self, cols: list, final_col_name: str):\n        super(MeanEnsembler, self).__init__()\n        self.cols = cols\n        self.final_col_name = final_col_name\n        assert final_col_name.startswith(\n            \"prediction\"\n        ), f\"final_col name should start with 'prediction'. Got {final_col_name}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        dataset.dataf.loc[:, self.final_col_name] = dataset.dataf.loc[\n            :, self.cols\n        ].mean(axis=1)\n        rich_print(\n            f\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n        )\n        return Dataset(**dataset.__dict__)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Donate's-formula">Donate's formula<a class="anchor-link" href="#Donate's-formula"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DonateWeightedEnsembler" class="doc_header"><code>class</code> <code>DonateWeightedEnsembler</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L37" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DonateWeightedEnsembler</code>(<strong><code>cols</code></strong>:<code>list</code>, <strong><code>final_col_name</code></strong>:<code>str</code>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>weighted average as per Donate et al.'s formula
<a href="https://doi.org/10.1016/j.neucom.2012.02.053">https://doi.org/10.1016/j.neucom.2012.02.053</a>
[0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold
Source: <a href="https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp">https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_features</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;prediction_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="s2">&quot;ABCDE&quot;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="n">test_features</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;era&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w_5_fold</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0625</span><span class="p">,</span> <span class="mf">0.0625</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">donate</span> <span class="o">=</span> <span class="n">DonateWeightedEnsembler</span><span class="p">(</span><span class="n">cols</span><span class="o">=</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">prediction_cols</span><span class="p">,</span> <span class="n">final_col_name</span><span class="o">=</span><span class="s1">&#39;prediction&#39;</span><span class="p">)</span>
<span class="n">ensembled</span> <span class="o">=</span> <span class="n">donate</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="o">.</span><span class="n">get_prediction_data</span>
<span class="k">assert</span> <span class="n">ensembled</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">w</span> <span class="o">*</span> <span class="n">elem</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">w_5_fold</span><span class="p">,</span> <span class="n">ensembled</span><span class="p">[</span><span class="n">test_features</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
<span class="n">ensembled</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">üç≤ Ensembled <span style="color: #000080; text-decoration-color: #000080">'['</span><span style="color: #000080; text-decoration-color: #000080">prediction_A', </span><span style="color: #000080; text-decoration-color: #000080">'prediction_B'</span><span style="color: #000080; text-decoration-color: #000080">, </span><span style="color: #000080; text-decoration-color: #000080">'prediction_C'</span><span style="color: #000080; text-decoration-color: #000080">, </span><span style="color: #000080; text-decoration-color: #000080">'prediction_D'</span><span style="color: #000080; text-decoration-color: #000080">, </span>
<span style="color: #000080; text-decoration-color: #000080">'prediction_E'</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold">]</span><span style="color: #000080; text-decoration-color: #000080">'</span><span style="color: #008000; text-decoration-color: #008000"> with </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">DonateWeightedEnsembler</span><span style="color: #008000; text-decoration-color: #008000"> and saved in </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">'</span><span style="font-weight: bold">prediction' üç≤</span>
</pre>

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">‚úÖ Finished step <span style="font-weight: bold">DonateWeightedEnsembler</span>. Output <span style="color: #808000; text-decoration-color: #808000">shape</span>=<span style="font-weight: bold">(</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">100</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span><span style="font-weight: bold">)</span>. Time taken for step: 
<span style="color: #000080; text-decoration-color: #000080; font-weight: bold">0:00:00</span><span style="color: #000080; text-decoration-color: #000080">.</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold">003895</span>. ‚úÖ
</pre>

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prediction_A</th>
      <th>prediction_B</th>
      <th>prediction_C</th>
      <th>prediction_D</th>
      <th>prediction_E</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.427880</td>
      <td>0.711636</td>
      <td>0.985088</td>
      <td>0.263601</td>
      <td>0.531591</td>
      <td>0.526052</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.303335</td>
      <td>0.062876</td>
      <td>0.179345</td>
      <td>0.127032</td>
      <td>0.029239</td>
      <td>0.091684</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.1.2.-Feature-Neutralization">1.1.2. Feature Neutralization<a class="anchor-link" href="#1.1.2.-Feature-Neutralization"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Classic feature neutralization (subtracting linear model from scores)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FeatureNeutralizer" class="doc_header"><code>class</code> <code>FeatureNeutralizer</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L68" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FeatureNeutralizer</code>(<strong><code>feature_names</code></strong>:<code>list</code>=<em><code>None</code></em>, <strong><code>pred_name</code></strong>:<code>str</code>=<em><code>'prediction'</code></em>, <strong><code>era_col</code></strong>:<code>str</code>=<em><code>'era'</code></em>, <strong><code>proportion</code></strong>:<code>float</code>=<em><code>0.5</code></em>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>Feature</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="d4b05b37-1934-4854-84a8-41447633916f"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#d4b05b37-1934-4854-84a8-41447633916f');

            setTimeout(function() {
                var nbb_cell_id = 6;
                var nbb_unformatted_code = "#export\n@typechecked\nclass FeatureNeutralizer(BaseProcessor):\n    \"\"\" Feature \"\"\"\n    def __init__(self, feature_names: list,\n                 pred_name: str = \"prediction\",\n                 proportion=0.5):\n        super(FeatureNeutralizer, self).__init__()\n        assert 0. <= proportion <= 1., f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n        self.proportion = proportion\n        self.feature_names = feature_names\n        self.pred_name = pred_name\n        self.new_col_name = f\"{self.pred_name}_neutralized_{self.proportion}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        neutralized_preds = dataset.dataf.groupby(\"era\")\\\n            .apply(lambda x: self.normalize_and_neutralize(x, [self.pred_name], self.feature_names))\n        dataset.dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(neutralized_preds)\n        rich_print(f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\")\n        rich_print(f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\")\n        return Dataset(**dataset.__dict__)\n\n    def _neutralize(self, df, columns, by):\n        scores = df[columns]\n        exposures = df[by].values\n        scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n        return scores / scores.std()\n\n    @staticmethod\n    def _normalize(dataf: pd.DataFrame):\n        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n        return sp.norm.ppf(normalized_ranks)\n\n    def normalize_and_neutralize(self, df, columns, by):\n        # Convert the scores to a normal distribution\n        df[columns] = self._normalize(df[columns])\n        df[columns] = self._neutralize(df, columns, by)\n        return df[columns]";
                var nbb_formatted_code = "# export\n@typechecked\nclass FeatureNeutralizer(BaseProcessor):\n    \"\"\"Feature\"\"\"\n\n    def __init__(\n        self, feature_names: list, pred_name: str = \"prediction\", proportion=0.5\n    ):\n        super(FeatureNeutralizer, self).__init__()\n        assert (\n            0.0 <= proportion <= 1.0\n        ), f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n        self.proportion = proportion\n        self.feature_names = feature_names\n        self.pred_name = pred_name\n        self.new_col_name = f\"{self.pred_name}_neutralized_{self.proportion}\"\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        neutralized_preds = dataset.dataf.groupby(\"era\").apply(\n            lambda x: self.normalize_and_neutralize(\n                x, [self.pred_name], self.feature_names\n            )\n        )\n        dataset.dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\n            neutralized_preds\n        )\n        rich_print(\n            f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\"\n        )\n        rich_print(\n            f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\"\n        )\n        return Dataset(**dataset.__dict__)\n\n    def _neutralize(self, df, columns, by):\n        scores = df[columns]\n        exposures = df[by].values\n        scores = scores - self.proportion * exposures.dot(\n            np.linalg.pinv(exposures).dot(scores)\n        )\n        return scores / scores.std()\n\n    @staticmethod\n    def _normalize(dataf: pd.DataFrame):\n        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n        return sp.norm.ppf(normalized_ranks)\n\n    def normalize_and_neutralize(self, df, columns, by):\n        # Convert the scores to a normal distribution\n        df[columns] = self._normalize(df[columns])\n        df[columns] = self._neutralize(df, columns, by)\n        return df[columns]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;test_assets/mini_numerai_version_1_data.csv&quot;</span><span class="p">))</span>
<span class="n">test_dataset</span><span class="o">.</span><span class="n">dataf</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">dataf</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="067906e9-f5bc-444f-9a3c-a76a9eb705fd"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#067906e9-f5bc-444f-9a3c-a76a9eb705fd');

            setTimeout(function() {
                var nbb_cell_id = 7;
                var nbb_unformatted_code = "test_dataset = Dataset(pd.read_csv(\"test_assets/mini_numerai_version_1_data.csv\"))\ntest_dataset.dataf.loc[:, 'prediction'] = np.random.uniform(size=len(test_dataset.dataf))";
                var nbb_formatted_code = "test_dataset = Dataset(pd.read_csv(\"test_assets/mini_numerai_version_1_data.csv\"))\ntest_dataset.dataf.loc[:, \"prediction\"] = np.random.uniform(\n    size=len(test_dataset.dataf)\n)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ft</span> <span class="o">=</span> <span class="n">FeatureNeutralizer</span><span class="p">(</span><span class="n">feature_names</span><span class="o">=</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">feature_cols</span><span class="p">,</span> <span class="n">pred_name</span><span class="o">=</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="n">proportion</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">new_dataset</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">ü§ñ Neutralized <span style="color: #000080; text-decoration-color: #000080; font-weight: bold">'prediction'</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold"> with proportion </span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold">'0.8'</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold"> ü§ñ</span>
</pre>

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">New neutralized column = <span style="color: #008000; text-decoration-color: #008000; font-weight: bold">'prediction_neutralized_0.8'</span>.
</pre>

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">‚úÖ Finished step <span style="font-weight: bold">FeatureNeutralizer</span>. Output <span style="color: #808000; text-decoration-color: #808000">shape</span>=<span style="font-weight: bold">(</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">10</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">316</span><span style="font-weight: bold">)</span>. Time taken for step: 
<span style="color: #000080; text-decoration-color: #000080; font-weight: bold">0:00:00</span><span style="color: #000080; text-decoration-color: #000080">.</span><span style="color: #000080; text-decoration-color: #000080; font-weight: bold">043276</span>. ‚úÖ
</pre>

</div>

</div>

<div class="output_area">




<div id="70fe72f0-8892-41fe-a287-e781eda2b849"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#70fe72f0-8892-41fe-a287-e781eda2b849');

            setTimeout(function() {
                var nbb_cell_id = 8;
                var nbb_unformatted_code = "ft = FeatureNeutralizer(feature_names=test_dataset.feature_cols, pred_name='prediction', proportion=0.8)\nnew_dataset = ft.transform(test_dataset);";
                var nbb_formatted_code = "ft = FeatureNeutralizer(\n    feature_names=test_dataset.feature_cols, pred_name=\"prediction\", proportion=0.8\n)\nnew_dataset = ft.transform(test_dataset)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="s2">&quot;prediction_neutralized_0.8&quot;</span> <span class="ow">in</span> <span class="n">new_dataset</span><span class="o">.</span><span class="n">prediction_cols</span>
<span class="k">assert</span> <span class="mf">0.</span> <span class="ow">in</span> <span class="n">new_dataset</span><span class="o">.</span><span class="n">get_prediction_data</span><span class="p">[</span><span class="s1">&#39;prediction_neutralized_0.8&#39;</span><span class="p">]</span>
<span class="k">assert</span> <span class="mf">1.</span> <span class="ow">in</span> <span class="n">new_dataset</span><span class="o">.</span><span class="n">get_prediction_data</span><span class="p">[</span><span class="s1">&#39;prediction_neutralized_0.8&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="cbd510c9-278f-41b6-94bb-5ed149fb9372"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#cbd510c9-278f-41b6-94bb-5ed149fb9372');

            setTimeout(function() {
                var nbb_cell_id = 9;
                var nbb_unformatted_code = "assert \"prediction_neutralized_0.8\" in new_dataset.prediction_cols\nassert 0. in new_dataset.get_prediction_data['prediction_neutralized_0.8']\nassert 1. in new_dataset.get_prediction_data['prediction_neutralized_0.8']";
                var nbb_formatted_code = "assert \"prediction_neutralized_0.8\" in new_dataset.prediction_cols\nassert 0.0 in new_dataset.get_prediction_data[\"prediction_neutralized_0.8\"]\nassert 1.0 in new_dataset.get_prediction_data[\"prediction_neutralized_0.8\"]";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_dataset</span><span class="o">.</span><span class="n">prediction_cols</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;prediction&#39;, &#39;prediction_neutralized_0.8&#39;]</pre>
</div>

</div>

<div class="output_area">




<div id="66aa44e2-b7e2-40fc-9917-db773cbbd45c"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#66aa44e2-b7e2-40fc-9917-db773cbbd45c');

            setTimeout(function() {
                var nbb_cell_id = 10;
                var nbb_unformatted_code = "new_dataset.prediction_cols";
                var nbb_formatted_code = "new_dataset.prediction_cols";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_dataset</span><span class="o">.</span><span class="n">get_prediction_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prediction</th>
      <th>prediction_neutralized_0.8</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.895532</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.894037</td>
      <td>0.815053</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.170013</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.632977</td>
      <td>0.461802</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.392452</td>
      <td>0.184947</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.676905</td>
      <td>0.538198</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.682949</td>
      <td>0.617129</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.402920</td>
      <td>0.294970</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.845842</td>
      <td>0.705030</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.415415</td>
      <td>0.382871</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">




<div id="3486ba4b-4469-4180-b331-050b99cf9be2"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#3486ba4b-4469-4180-b331-050b99cf9be2');

            setTimeout(function() {
                var nbb_cell_id = 11;
                var nbb_unformatted_code = "new_dataset.get_prediction_data";
                var nbb_formatted_code = "new_dataset.get_prediction_data";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.1.3.-Feature-Penalization">1.1.3. Feature Penalization<a class="anchor-link" href="#1.1.3.-Feature-Penalization"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FeaturePenalizer" class="doc_header"><code>class</code> <code>FeaturePenalizer</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L112" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FeaturePenalizer</code>(<strong><code>model_list</code></strong>:<code>list</code>, <strong><code>max_exposure</code></strong>:<code>float</code>, <strong><code>risky_feature_names</code></strong>:<code>list</code>=<em><code>None</code></em>, <strong><code>pred_name</code></strong>:<code>str</code>=<em><code>'prediction'</code></em>, <strong><code>era_col</code></strong>:<code>str</code>=<em><code>'era'</code></em>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<p>Feature penalization with Tensorflow.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="b68feebb-4f4e-4abd-8ee6-10e95eaf4a9d"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#b68feebb-4f4e-4abd-8ee6-10e95eaf4a9d');

            setTimeout(function() {
                var nbb_cell_id = 12;
                var nbb_unformatted_code = "#export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\" Feature penalization with Tensorflow. \"\"\"\n    def __init__(self, model_list: list, max_exposure: float, risky_feature_names: list = None, pred_name: str = \"prediction\"):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert 0. <= max_exposure <= 1., f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = dataset.feature_cols if not self.risky_feature_names else self.risky_feature_names\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                            dataset.dataf,\n                            self.pred_name,\n                            neutralizers=risky_feature_names,\n                            max_exp=self.max_exposure,\n                        )\n            new_pred_col = f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(self, df: pd.DataFrame,\n                             column: str = \"prediction\",\n                             neutralizers: list = None,\n                             normalize=True,\n                             gaussianize=True,\n                             era_col=\"era\",\n                             max_exp: float = 0.1\n                             ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(scores, exposure_values,\n                                              max_exp, len(neutralizers), None)\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(np.concatenate(neutralized),\n                                   columns=[column], index=df.index)\n        return predictions\n\n    def reduce_exposure(self, prediction, features, max_exp, input_size=50, weights=None):\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Input(input_size),\n            tf.keras.experimental.LinearModel(use_bias=False),\n        ])\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:,None] - model(feats), model.get_weights()\n\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps)) +\n                                 tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps)))\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_formatted_code = "# export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\"Feature penalization with Tensorflow.\"\"\"\n\n    def __init__(\n        self,\n        model_list: list,\n        max_exposure: float,\n        risky_feature_names: list = None,\n        pred_name: str = \"prediction\",\n    ):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert (\n            0.0 <= max_exposure <= 1.0\n        ), f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = (\n            dataset.feature_cols\n            if not self.risky_feature_names\n            else self.risky_feature_names\n        )\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                dataset.dataf,\n                self.pred_name,\n                neutralizers=risky_feature_names,\n                max_exp=self.max_exposure,\n            )\n            new_pred_col = (\n                f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            )\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(\n        self,\n        df: pd.DataFrame,\n        column: str = \"prediction\",\n        neutralizers: list = None,\n        normalize=True,\n        gaussianize=True,\n        era_col=\"era\",\n        max_exp: float = 0.1,\n    ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(\n                scores, exposure_values, max_exp, len(neutralizers), None\n            )\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(\n            np.concatenate(neutralized), columns=[column], index=df.index\n        )\n        return predictions\n\n    def reduce_exposure(\n        self, prediction, features, max_exp, input_size=50, weights=None\n    ):\n        model = tf.keras.models.Sequential(\n            [\n                tf.keras.layers.Input(input_size),\n                tf.keras.experimental.LinearModel(use_bias=False),\n            ]\n        )\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:, None] - model(feats), model.get_weights()\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\n            )\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="ba6d58da-b30d-42a9-94ae-3ff5adb975d5"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#ba6d58da-b30d-42a9-94ae-3ff5adb975d5');

            setTimeout(function() {
                var nbb_cell_id = 12;
                var nbb_unformatted_code = "#export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\" Feature penalization with Tensorflow. \"\"\"\n    def __init__(self, model_list: list, max_exposure: float, risky_feature_names: list = None, pred_name: str = \"prediction\"):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert 0. <= max_exposure <= 1., f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = dataset.feature_cols if not self.risky_feature_names else self.risky_feature_names\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                            dataset.dataf,\n                            self.pred_name,\n                            neutralizers=risky_feature_names,\n                            max_exp=self.max_exposure,\n                        )\n            new_pred_col = f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(self, df: pd.DataFrame,\n                             column: str = \"prediction\",\n                             neutralizers: list = None,\n                             normalize=True,\n                             gaussianize=True,\n                             era_col=\"era\",\n                             max_exp: float = 0.1\n                             ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(scores, exposure_values,\n                                              max_exp, len(neutralizers), None)\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(np.concatenate(neutralized),\n                                   columns=[column], index=df.index)\n        return predictions\n\n    def reduce_exposure(self, prediction, features, max_exp, input_size=50, weights=None):\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Input(input_size),\n            tf.keras.experimental.LinearModel(use_bias=False),\n        ])\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:,None] - model(feats), model.get_weights()\n\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps)) +\n                                 tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps)))\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_formatted_code = "# export\n@typechecked\nclass FeaturePenalizer(BaseProcessor):\n    \"\"\"Feature penalization with Tensorflow.\"\"\"\n\n    def __init__(\n        self,\n        model_list: list,\n        max_exposure: float,\n        risky_feature_names: list = None,\n        pred_name: str = \"prediction\",\n    ):\n        super(FeaturePenalizer, self).__init__()\n        self.model_list = model_list\n        assert (\n            0.0 <= max_exposure <= 1.0\n        ), f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n        self.max_exposure = max_exposure\n        self.risky_feature_names = risky_feature_names\n        self.pred_name = pred_name\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        risky_feature_names = (\n            dataset.feature_cols\n            if not self.risky_feature_names\n            else self.risky_feature_names\n        )\n        for model_name in self.model_list:\n            penalized_data = self.reduce_all_exposures(\n                dataset.dataf,\n                self.pred_name,\n                neutralizers=risky_feature_names,\n                max_exp=self.max_exposure,\n            )\n            new_pred_col = (\n                f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n            )\n            dataset.dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n        return Dataset(**dataset.__dict__)\n\n    def reduce_all_exposures(\n        self,\n        df: pd.DataFrame,\n        column: str = \"prediction\",\n        neutralizers: list = None,\n        normalize=True,\n        gaussianize=True,\n        era_col=\"era\",\n        max_exp: float = 0.1,\n    ):\n        if neutralizers is None:\n            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n        neutralized = []\n\n        for era in tqdm(df[era_col].unique()):\n            df_era = df[df[era_col] == era]\n            scores = df_era[[column]].values\n            exposure_values = df_era[neutralizers].values\n\n            if normalize:\n                scores2 = []\n                for x in scores.T:\n                    x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n                    if gaussianize:\n                        x = scipy.stats.norm.ppf(x)\n                    scores2.append(x)\n                scores = np.array(scores2)[0]\n\n            scores, weights = self.reduce_exposure(\n                scores, exposure_values, max_exp, len(neutralizers), None\n            )\n\n            scores /= tf.math.reduce_std(scores)\n            scores -= tf.reduce_min(scores)\n            scores /= tf.reduce_max(scores)\n            neutralized.append(scores.numpy())\n\n        predictions = pd.DataFrame(\n            np.concatenate(neutralized), columns=[column], index=df.index\n        )\n        return predictions\n\n    def reduce_exposure(\n        self, prediction, features, max_exp, input_size=50, weights=None\n    ):\n        model = tf.keras.models.Sequential(\n            [\n                tf.keras.layers.Input(input_size),\n                tf.keras.experimental.LinearModel(use_bias=False),\n            ]\n        )\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n        if weights is None:\n            optimizer = tf.keras.optimizers.Adamax()\n            start_exp = self.__exposures(feats, pred[:, None])\n            target_exps = tf.clip_by_value(start_exp, -max_exp, max_exp)\n            self._train_loop(model, optimizer, feats, pred, target_exps)\n        else:\n            model.set_weights(weights)\n        return pred[:, None] - model(feats), model.get_weights()\n\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n        for i in range(1000000):\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            if loss < 1e-7:\n                break\n\n    @tf.function(experimental_relax_shapes=True)\n    def __train_loop_body(self, model, feats, pred, target_exps):\n        with tf.GradientTape() as tape:\n            exps = self.exposures(feats, pred[:, None] - model(feats, training=True))\n            loss = tf.reduce_sum(\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\n            )\n        return loss, tape.gradient(loss, model.trainable_variables)\n\n    @staticmethod\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n    def __exposures(x, y):\n        x = x - tf.math.reduce_mean(x, axis=0)\n        x = x / tf.norm(x, axis=0)\n        y = y - tf.math.reduce_mean(y, axis=0)\n        y = y / tf.norm(y, axis=0)\n        return tf.matmul(x, y, transpose_a=True)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.2.-Version-1-specific">1.2. Version 1 specific<a class="anchor-link" href="#1.2.-Version-1-specific"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.3.-Version-2-specific">1.3. Version 2 specific<a class="anchor-link" href="#1.3.-Version-2-specific"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.4.-Signals-specific">1.4. Signals specific<a class="anchor-link" href="#1.4.-Signals-specific"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Custom-PostProcessors">2. Custom PostProcessors<a class="anchor-link" href="#2.-Custom-PostProcessors"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are an almost unlimited number of ways to postprocess data. We invite the Numerai community to develop Numerai Classic and Signals preprocessors for <code>numerai-blocks</code>.</p>
<p>A new PostProcessor should inherit from <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a> and implement a <code>transform</code> method. The <code>transform</code> method should take a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> as input and return a <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> object as output. An example is given below.</p>
<p>We recommend adding <code>@typechecked</code> at the top of a new PostProcessor class to enforce types and provide useful debugging stacktraces.</p>
<p>To enable fancy logging output. Add the <code>@display_processor_info</code> decorator to the <code>transform</code> method.</p>
<p>Note that arbitrary metadata can be added or changed in the <a href="/numerai_blocks/dataset.html#Dataset"><code>Dataset</code></a> class during a postprocessing step.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AwesomePostProcessor" class="doc_header"><code>class</code> <code>AwesomePostProcessor</code><a href="https://github.com/crowdcent/numerai_blocks/tree/main/numerai_blocks/postprocessing.py#L216" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AwesomePostProcessor</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/numerai_blocks/preprocessing.html#BaseProcessor"><code>BaseProcessor</code></a></p>
</blockquote>
<ul>
<li>TEMPLATE -
Do some awesome postprocessing.</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">




<div id="58fc9cfd-283d-4eae-8db7-5fbfdf61bf7e"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#58fc9cfd-283d-4eae-8db7-5fbfdf61bf7e');

            setTimeout(function() {
                var nbb_cell_id = 13;
                var nbb_unformatted_code = "#export\n@typechecked\nclass AwesomePostProcessor(BaseProcessor):\n    \"\"\"\n    - TEMPLATE -\n    Do some awesome postprocessing.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(AwesomePostProcessor, self).__init__()\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        # Do processing\n        ...\n        # Add new column for manipulated data (optional)\n        new_column_name = \"NEW_COLUMN_NAME\"\n        dataset.dataf.loc[:, f\"prediction_{new_column_name}\"] = ...\n        ...\n        # Parse all contents of Dataset to the next pipeline step\n        return Dataset(**dataset.__dict__)";
                var nbb_formatted_code = "# export\n@typechecked\nclass AwesomePostProcessor(BaseProcessor):\n    \"\"\"\n    - TEMPLATE -\n    Do some awesome postprocessing.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(AwesomePostProcessor, self).__init__()\n\n    @display_processor_info\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n        # Do processing\n        ...\n        # Add new column for manipulated data (optional)\n        new_column_name = \"NEW_COLUMN_NAME\"\n        dataset.dataf.loc[:, f\"prediction_{new_column_name}\"] = ...\n        ...\n        # Parse all contents of Dataset to the next pipeline step\n        return Dataset(**dataset.__dict__)";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            
</script>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
</div>
 

