{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp submission\";\n                var nbb_formatted_code = \"# default_exp submission\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "> Uploading predictions to Numerai.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Functionality in this section allows you to easily and reliably submit predictions for Numerai Classic and Numerai Signals.\n",
    "\n",
    "The two objects are called:\n",
    "1. `NumeraiClassicSubmitter`\n",
    "2. `NumeraiSignalsSubmitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev import show_doc\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev import show_doc\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev import show_doc\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# export\\nimport os\\nimport uuid\\nimport numpy as np\\nimport pandas as pd\\nfrom typing import Union\\nfrom copy import deepcopy\\nfrom random import choices\\nfrom tqdm.auto import tqdm\\nfrom datetime import datetime\\nfrom abc import abstractmethod\\nfrom typeguard import typechecked\\nfrom string import ascii_uppercase\\nfrom rich import print as rich_print\\nfrom numerapi import NumerAPI, SignalsAPI\\nfrom dateutil.relativedelta import relativedelta, FR\\n\\nfrom numerblox.download import BaseIO\\nfrom numerblox.key import Key\";\n                var nbb_formatted_code = \"# export\\nimport os\\nimport uuid\\nimport numpy as np\\nimport pandas as pd\\nfrom typing import Union\\nfrom copy import deepcopy\\nfrom random import choices\\nfrom tqdm.auto import tqdm\\nfrom datetime import datetime\\nfrom abc import abstractmethod\\nfrom typeguard import typechecked\\nfrom string import ascii_uppercase\\nfrom rich import print as rich_print\\nfrom numerapi import NumerAPI, SignalsAPI\\nfrom dateutil.relativedelta import relativedelta, FR\\n\\nfrom numerblox.download import BaseIO\\nfrom numerblox.key import Key\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from copy import deepcopy\n",
    "from random import choices\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from abc import abstractmethod\n",
    "from typeguard import typechecked\n",
    "from string import ascii_uppercase\n",
    "from rich import print as rich_print\n",
    "from numerapi import NumerAPI, SignalsAPI\n",
    "from dateutil.relativedelta import relativedelta, FR\n",
    "\n",
    "from numerblox.download import BaseIO\n",
    "from numerblox.key import Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. BaseSubmitter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`BaseSubmitter` handles all submission logic common to Numerai Classic and Numerai Signals. Under the hood directory logic is handled by `BaseIO`.\n",
    "Each submittor should inherit from `BaseSubmitter` and implement the `.save_csv` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass BaseSubmitter(BaseIO):\\n    \\\"\\\"\\\"\\n    Basic functionality for submitting to Numerai. \\\\n\\n    Uses numerapi under the hood.\\n    More info: https://numerapi.readthedocs.io/ \\\\n\\n\\n    | :param directory_path: Directory to store and read submissions from. \\\\n\\n    | :param api: NumerAPI or SignalsAPI\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str, api: Union[NumerAPI, SignalsAPI]):\\n        super().__init__(directory_path)\\n        self.api = api\\n\\n    @abstractmethod\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        For Numerai Classic: Save index column + 'cols' (targets) to CSV.\\n        For Numerai Signals: Save ticker, friday_date, data_type and signal columns to CSV.\\n        \\\"\\\"\\\"\\n        ...\\n\\n    def upload_predictions(self, file_name: str, model_name: str, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        Upload CSV file to Numerai for given model name.\\n        :param file_name: File name/path relative to directory_path.\\n        :param model_name: Lowercase raw model name (For example, 'integration_test').\\n        \\\"\\\"\\\"\\n        full_path = str(self.dir / file_name)\\n        model_id = self._get_model_id(model_name=model_name)\\n        api_type = str(self.api.__class__.__name__)\\n        rich_print(\\n            f\\\":airplane: {api_type}: Uploading predictions from '{full_path}' for model [bold blue]'{model_name}'[/bold blue] (model_id='{model_id}') :airplane:\\\"\\n        )\\n        self.api.upload_predictions(\\n            file_path=full_path, model_id=model_id, *args, **kwargs\\n        )\\n        rich_print(\\n            f\\\":thumbs_up: {api_type} submission of '{full_path}' for [bold blue]{model_name}[/bold blue] is successful! :thumbs_up:\\\"\\n        )\\n\\n    def full_submission(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        model_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        Save DataFrame to csv and upload predictions through API.\\n        *args, **kwargs are passed to numerapi API.\\n        \\\"\\\"\\\"\\n        self.save_csv(dataf=dataf, file_name=file_name, cols=cols)\\n        self.upload_predictions(\\n            file_name=file_name, model_name=model_name, *args, **kwargs\\n        )\\n\\n    def combine_csvs(self, csv_paths: list,\\n                     aux_cols: list,\\n                     era_col: str = None,\\n                     pred_col: str = 'prediction') -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Read in csv files and combine all predictions with a rank mean.\\n        Multi-target predictions will be averaged out.\\n        :param csv_paths: List of full paths to .csv prediction files.\\n        :param aux_cols: ['id'] for Numerai Classic and\\n        For example ['ticker', 'last_friday', 'data_type'] for Numerai Signals.\\n        All aux_cols will be stored as index.\\n        :param era_col: Column indicating era ('era' or 'last_friday').\\n        Will be used for Grouping the rank mean if given. Skip groupby if no era_col provided.\\n        :param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals.\\n        \\\"\\\"\\\"\\n        all_datafs = [pd.read_csv(path, index_col=aux_cols) for path in tqdm(csv_paths)]\\n        final_dataf = pd.concat(all_datafs, axis=\\\"columns\\\")\\n        # Remove issue of duplicate columns\\n        numeric_cols = final_dataf.select_dtypes(include=np.number).columns\\n        final_dataf.rename({k: str(v) for k, v in zip(numeric_cols, range(len(numeric_cols)))},\\n                           axis=1,\\n                           inplace=True)\\n        # Combine all numeric columns with rank mean\\n        num_dataf = final_dataf.select_dtypes(include=np.number)\\n        num_dataf = num_dataf.groupby(era_col) if era_col else num_dataf\\n        final_dataf[pred_col] = num_dataf.rank(pct=True, method=\\\"first\\\").mean(axis=1)\\n        return final_dataf[[pred_col]]\\n\\n    def _get_model_id(self, model_name: str) -> str:\\n        \\\"\\\"\\\"\\n        Get ID needed for prediction uploading.\\n        :param model_name: Raw lowercase model name\\n        of Numerai model that you have access to.\\n        \\\"\\\"\\\"\\n        return self.get_model_mapping[model_name]\\n\\n    @property\\n    def get_model_mapping(self) -> dict:\\n        \\\"\\\"\\\"Mapping between raw model names and model IDs.\\\"\\\"\\\"\\n        return self.api.get_models()\\n\\n    def _check_value_range(self, dataf: pd.DataFrame, cols: Union[str, list]):\\n        \\\"\\\"\\\" Check if all predictions are in range (0...1). \\\"\\\"\\\"\\n        cols = [cols] if isinstance(cols, str) else cols\\n        for col in cols:\\n            if not dataf[col].between(0, 1).all():\\n                min_val, max_val = dataf[col].min(), dataf[col].max()\\n                raise ValueError(\\n                    f\\\"Values must be between 0 and 1. \\\\\\nFound min value of '{min_val}' and max value of '{max_val}' for column '{col}'.\\\"\\n                )\\n\\n    def __call__(\\n            self,\\n            dataf: pd.DataFrame,\\n            file_name: str,\\n            model_name: str,\\n            cols: Union[str, list],\\n            *args,\\n            **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        The most common use case will be to create a CSV and submit it immediately after that.\\n        full_submission handles this.\\n        \\\"\\\"\\\"\\n        self.full_submission(\\n            dataf=dataf,\\n            file_name=file_name,\\n            model_name=model_name,\\n            cols=cols,\\n            *args,\\n            **kwargs,\\n        )\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass BaseSubmitter(BaseIO):\\n    \\\"\\\"\\\"\\n    Basic functionality for submitting to Numerai. \\\\n\\n    Uses numerapi under the hood.\\n    More info: https://numerapi.readthedocs.io/ \\\\n\\n\\n    | :param directory_path: Directory to store and read submissions from. \\\\n\\n    | :param api: NumerAPI or SignalsAPI\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, api: Union[NumerAPI, SignalsAPI]):\\n        super().__init__(directory_path)\\n        self.api = api\\n\\n    @abstractmethod\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        For Numerai Classic: Save index column + 'cols' (targets) to CSV.\\n        For Numerai Signals: Save ticker, friday_date, data_type and signal columns to CSV.\\n        \\\"\\\"\\\"\\n        ...\\n\\n    def upload_predictions(self, file_name: str, model_name: str, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        Upload CSV file to Numerai for given model name.\\n        :param file_name: File name/path relative to directory_path.\\n        :param model_name: Lowercase raw model name (For example, 'integration_test').\\n        \\\"\\\"\\\"\\n        full_path = str(self.dir / file_name)\\n        model_id = self._get_model_id(model_name=model_name)\\n        api_type = str(self.api.__class__.__name__)\\n        rich_print(\\n            f\\\":airplane: {api_type}: Uploading predictions from '{full_path}' for model [bold blue]'{model_name}'[/bold blue] (model_id='{model_id}') :airplane:\\\"\\n        )\\n        self.api.upload_predictions(\\n            file_path=full_path, model_id=model_id, *args, **kwargs\\n        )\\n        rich_print(\\n            f\\\":thumbs_up: {api_type} submission of '{full_path}' for [bold blue]{model_name}[/bold blue] is successful! :thumbs_up:\\\"\\n        )\\n\\n    def full_submission(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        model_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        Save DataFrame to csv and upload predictions through API.\\n        *args, **kwargs are passed to numerapi API.\\n        \\\"\\\"\\\"\\n        self.save_csv(dataf=dataf, file_name=file_name, cols=cols)\\n        self.upload_predictions(\\n            file_name=file_name, model_name=model_name, *args, **kwargs\\n        )\\n\\n    def combine_csvs(\\n        self,\\n        csv_paths: list,\\n        aux_cols: list,\\n        era_col: str = None,\\n        pred_col: str = \\\"prediction\\\",\\n    ) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Read in csv files and combine all predictions with a rank mean.\\n        Multi-target predictions will be averaged out.\\n        :param csv_paths: List of full paths to .csv prediction files.\\n        :param aux_cols: ['id'] for Numerai Classic and\\n        For example ['ticker', 'last_friday', 'data_type'] for Numerai Signals.\\n        All aux_cols will be stored as index.\\n        :param era_col: Column indicating era ('era' or 'last_friday').\\n        Will be used for Grouping the rank mean if given. Skip groupby if no era_col provided.\\n        :param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals.\\n        \\\"\\\"\\\"\\n        all_datafs = [pd.read_csv(path, index_col=aux_cols) for path in tqdm(csv_paths)]\\n        final_dataf = pd.concat(all_datafs, axis=\\\"columns\\\")\\n        # Remove issue of duplicate columns\\n        numeric_cols = final_dataf.select_dtypes(include=np.number).columns\\n        final_dataf.rename(\\n            {k: str(v) for k, v in zip(numeric_cols, range(len(numeric_cols)))},\\n            axis=1,\\n            inplace=True,\\n        )\\n        # Combine all numeric columns with rank mean\\n        num_dataf = final_dataf.select_dtypes(include=np.number)\\n        num_dataf = num_dataf.groupby(era_col) if era_col else num_dataf\\n        final_dataf[pred_col] = num_dataf.rank(pct=True, method=\\\"first\\\").mean(axis=1)\\n        return final_dataf[[pred_col]]\\n\\n    def _get_model_id(self, model_name: str) -> str:\\n        \\\"\\\"\\\"\\n        Get ID needed for prediction uploading.\\n        :param model_name: Raw lowercase model name\\n        of Numerai model that you have access to.\\n        \\\"\\\"\\\"\\n        return self.get_model_mapping[model_name]\\n\\n    @property\\n    def get_model_mapping(self) -> dict:\\n        \\\"\\\"\\\"Mapping between raw model names and model IDs.\\\"\\\"\\\"\\n        return self.api.get_models()\\n\\n    def _check_value_range(self, dataf: pd.DataFrame, cols: Union[str, list]):\\n        \\\"\\\"\\\"Check if all predictions are in range (0...1).\\\"\\\"\\\"\\n        cols = [cols] if isinstance(cols, str) else cols\\n        for col in cols:\\n            if not dataf[col].between(0, 1).all():\\n                min_val, max_val = dataf[col].min(), dataf[col].max()\\n                raise ValueError(\\n                    f\\\"Values must be between 0 and 1. \\\\\\nFound min value of '{min_val}' and max value of '{max_val}' for column '{col}'.\\\"\\n                )\\n\\n    def __call__(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        model_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        The most common use case will be to create a CSV and submit it immediately after that.\\n        full_submission handles this.\\n        \\\"\\\"\\\"\\n        self.full_submission(\\n            dataf=dataf,\\n            file_name=file_name,\\n            model_name=model_name,\\n            cols=cols,\\n            *args,\\n            **kwargs,\\n        )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class BaseSubmitter(BaseIO):\n",
    "    \"\"\"\n",
    "    Basic functionality for submitting to Numerai. \\n\n",
    "    Uses numerapi under the hood.\n",
    "    More info: https://numerapi.readthedocs.io/ \\n\n",
    "\n",
    "    | :param directory_path: Directory to store and read submissions from. \\n\n",
    "    | :param api: NumerAPI or SignalsAPI\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str, api: Union[NumerAPI, SignalsAPI]):\n",
    "        super().__init__(directory_path)\n",
    "        self.api = api\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_csv(\n",
    "        self,\n",
    "        dataf: pd.DataFrame,\n",
    "        file_name: str,\n",
    "        cols: Union[str, list],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        For Numerai Classic: Save index column + 'cols' (targets) to CSV.\n",
    "        For Numerai Signals: Save ticker, friday_date, data_type and signal columns to CSV.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def upload_predictions(self, file_name: str, model_name: str, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Upload CSV file to Numerai for given model name.\n",
    "        :param file_name: File name/path relative to directory_path.\n",
    "        :param model_name: Lowercase raw model name (For example, 'integration_test').\n",
    "        \"\"\"\n",
    "        full_path = str(self.dir / file_name)\n",
    "        model_id = self._get_model_id(model_name=model_name)\n",
    "        api_type = str(self.api.__class__.__name__)\n",
    "        rich_print(\n",
    "            f\":airplane: {api_type}: Uploading predictions from '{full_path}' for model [bold blue]'{model_name}'[/bold blue] (model_id='{model_id}') :airplane:\"\n",
    "        )\n",
    "        self.api.upload_predictions(\n",
    "            file_path=full_path, model_id=model_id, *args, **kwargs\n",
    "        )\n",
    "        rich_print(\n",
    "            f\":thumbs_up: {api_type} submission of '{full_path}' for [bold blue]{model_name}[/bold blue] is successful! :thumbs_up:\"\n",
    "        )\n",
    "\n",
    "    def full_submission(\n",
    "        self,\n",
    "        dataf: pd.DataFrame,\n",
    "        file_name: str,\n",
    "        model_name: str,\n",
    "        cols: Union[str, list],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save DataFrame to csv and upload predictions through API.\n",
    "        *args, **kwargs are passed to numerapi API.\n",
    "        \"\"\"\n",
    "        self.save_csv(dataf=dataf, file_name=file_name, cols=cols)\n",
    "        self.upload_predictions(\n",
    "            file_name=file_name, model_name=model_name, *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def combine_csvs(self, csv_paths: list,\n",
    "                     aux_cols: list,\n",
    "                     era_col: str = None,\n",
    "                     pred_col: str = 'prediction') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Read in csv files and combine all predictions with a rank mean.\n",
    "        Multi-target predictions will be averaged out.\n",
    "        :param csv_paths: List of full paths to .csv prediction files.\n",
    "        :param aux_cols: ['id'] for Numerai Classic and\n",
    "        For example ['ticker', 'last_friday', 'data_type'] for Numerai Signals.\n",
    "        All aux_cols will be stored as index.\n",
    "        :param era_col: Column indicating era ('era' or 'last_friday').\n",
    "        Will be used for Grouping the rank mean if given. Skip groupby if no era_col provided.\n",
    "        :param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals.\n",
    "        \"\"\"\n",
    "        all_datafs = [pd.read_csv(path, index_col=aux_cols) for path in tqdm(csv_paths)]\n",
    "        final_dataf = pd.concat(all_datafs, axis=\"columns\")\n",
    "        # Remove issue of duplicate columns\n",
    "        numeric_cols = final_dataf.select_dtypes(include=np.number).columns\n",
    "        final_dataf.rename({k: str(v) for k, v in zip(numeric_cols, range(len(numeric_cols)))},\n",
    "                           axis=1,\n",
    "                           inplace=True)\n",
    "        # Combine all numeric columns with rank mean\n",
    "        num_dataf = final_dataf.select_dtypes(include=np.number)\n",
    "        num_dataf = num_dataf.groupby(era_col) if era_col else num_dataf\n",
    "        final_dataf[pred_col] = num_dataf.rank(pct=True, method=\"first\").mean(axis=1)\n",
    "        return final_dataf[[pred_col]]\n",
    "\n",
    "    def _get_model_id(self, model_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Get ID needed for prediction uploading.\n",
    "        :param model_name: Raw lowercase model name\n",
    "        of Numerai model that you have access to.\n",
    "        \"\"\"\n",
    "        return self.get_model_mapping[model_name]\n",
    "\n",
    "    @property\n",
    "    def get_model_mapping(self) -> dict:\n",
    "        \"\"\"Mapping between raw model names and model IDs.\"\"\"\n",
    "        return self.api.get_models()\n",
    "\n",
    "    def _check_value_range(self, dataf: pd.DataFrame, cols: Union[str, list]):\n",
    "        \"\"\" Check if all predictions are in range (0...1). \"\"\"\n",
    "        cols = [cols] if isinstance(cols, str) else cols\n",
    "        for col in cols:\n",
    "            if not dataf[col].between(0, 1).all():\n",
    "                min_val, max_val = dataf[col].min(), dataf[col].max()\n",
    "                raise ValueError(\n",
    "                    f\"Values must be between 0 and 1. \\\n",
    "Found min value of '{min_val}' and max value of '{max_val}' for column '{col}'.\"\n",
    "                )\n",
    "\n",
    "    def __call__(\n",
    "            self,\n",
    "            dataf: pd.DataFrame,\n",
    "            file_name: str,\n",
    "            model_name: str,\n",
    "            cols: Union[str, list],\n",
    "            *args,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The most common use case will be to create a CSV and submit it immediately after that.\n",
    "        full_submission handles this.\n",
    "        \"\"\"\n",
    "        self.full_submission(\n",
    "            dataf=dataf,\n",
    "            file_name=file_name,\n",
    "            model_name=model_name,\n",
    "            cols=cols,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For Numerai Classic submissions. Uses [NumerAPI](https://numerapi.readthedocs.io/en/latest/_modules/numerapi/numerapi.html) under the hood.\n",
    "\n",
    "Note that using submitters requires a `Key` object."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass NumeraiClassicSubmitter(BaseSubmitter):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Classic.\\n\\n    | :param directory_path: Base directory to save and read prediction files from. \\\\n\\n    | :param key: Key object containing valid credentials for Numerai Classic. \\\\n\\n    | *args, **kwargs will be passed to NumerAPI initialization.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = NumerAPI(public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs)\\n        super().__init__(\\n            directory_path=directory_path, api=api\\n        )\\n\\n    def save_csv(\\n            self,\\n            dataf: pd.DataFrame,\\n            file_name: str,\\n            cols: str = \\\"prediction\\\",\\n            *args,\\n            **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n        1. id (as index column)\\n        2. cols (for example, 'prediction_mymodel').\\n        :param file_name: .csv file path.\\n        :param cols: Prediction column name.\\n        For example, 'prediction' or 'prediction_mymodel'.\\n        \\\"\\\"\\\"\\n        sub_dataf = deepcopy(dataf)\\n        self._check_value_range(dataf=sub_dataf, cols=cols)\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        sub_dataf.loc[:, 'prediction'] = sub_dataf[cols]\\n        sub_dataf.loc[:, 'prediction'].to_csv(full_path, *args, **kwargs)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass NumeraiClassicSubmitter(BaseSubmitter):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Classic.\\n\\n    | :param directory_path: Base directory to save and read prediction files from. \\\\n\\n    | :param key: Key object containing valid credentials for Numerai Classic. \\\\n\\n    | *args, **kwargs will be passed to NumerAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = NumerAPI(public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs)\\n        super().__init__(directory_path=directory_path, api=api)\\n\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: str = \\\"prediction\\\",\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n        1. id (as index column)\\n        2. cols (for example, 'prediction_mymodel').\\n        :param file_name: .csv file path.\\n        :param cols: Prediction column name.\\n        For example, 'prediction' or 'prediction_mymodel'.\\n        \\\"\\\"\\\"\\n        sub_dataf = deepcopy(dataf)\\n        self._check_value_range(dataf=sub_dataf, cols=cols)\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        sub_dataf.loc[:, \\\"prediction\\\"] = sub_dataf[cols]\\n        sub_dataf.loc[:, \\\"prediction\\\"].to_csv(full_path, *args, **kwargs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class NumeraiClassicSubmitter(BaseSubmitter):\n",
    "    \"\"\"\n",
    "    Submit for Numerai Classic.\n",
    "\n",
    "    | :param directory_path: Base directory to save and read prediction files from. \\n\n",
    "    | :param key: Key object containing valid credentials for Numerai Classic. \\n\n",
    "    | *args, **kwargs will be passed to NumerAPI initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\n",
    "        api = NumerAPI(public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs)\n",
    "        super().__init__(\n",
    "            directory_path=directory_path, api=api\n",
    "        )\n",
    "\n",
    "    def save_csv(\n",
    "            self,\n",
    "            dataf: pd.DataFrame,\n",
    "            file_name: str,\n",
    "            cols: str = \"prediction\",\n",
    "            *args,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param dataf: DataFrame which should have at least the following columns:\n",
    "        1. id (as index column)\n",
    "        2. cols (for example, 'prediction_mymodel').\n",
    "        :param file_name: .csv file path.\n",
    "        :param cols: Prediction column name.\n",
    "        For example, 'prediction' or 'prediction_mymodel'.\n",
    "        \"\"\"\n",
    "        sub_dataf = deepcopy(dataf)\n",
    "        self._check_value_range(dataf=sub_dataf, cols=cols)\n",
    "\n",
    "        full_path = str(self.dir / file_name)\n",
    "        rich_print(\n",
    "            f\":page_facing_up: Saving predictions CSV to '{full_path}'. :page_facing_up:\"\n",
    "        )\n",
    "        sub_dataf.loc[:, 'prediction'] = sub_dataf[cols]\n",
    "        sub_dataf.loc[:, 'prediction'].to_csv(full_path, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage 1: NumeraiClassicSubmitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ðŸ”‘ Numerai Auth key initialized with pub_id = \u001B[32m'UFVCTElDX0lE'\u001B[0m ðŸ”‘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”‘ Numerai Auth key initialized with pub_id = <span style=\"color: #008000; text-decoration-color: #008000\">'UFVCTElDX0lE'</span> ðŸ”‘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_sub\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_sub</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                      prediction\nid                                              \nbf49fd90-91cd-4232-b06e-bcda608f20ef    0.848623\n58634fe7-e200-4ce3-9431-338c2df71de8    0.472443",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bf49fd90-91cd-4232-b06e-bcda608f20ef</th>\n      <td>0.848623</td>\n    </tr>\n    <tr>\n      <th>58634fe7-e200-4ce3-9431-338c2df71de8</th>\n      <td>0.472443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# example 1\\n# Initialization (Random credentials)\\ntest_dir = \\\"test_sub\\\"\\nclassic_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nnum_sub = NumeraiClassicSubmitter(directory_path=test_dir, key=classic_key)\\nassert num_sub.dir.is_dir()\\n\\n# Create random dataframe\\nn_rows = 100\\ntargets = \\\"prediction\\\"\\ntest_dataf = pd.DataFrame(np.random.uniform(size=n_rows), columns=[targets])\\ntest_dataf[\\\"id\\\"] = [uuid.uuid4() for _ in range(n_rows)]\\ntest_dataf = test_dataf.set_index(\\\"id\\\")\\ntest_dataf.head(2)\";\n                var nbb_formatted_code = \"# example 1\\n# Initialization (Random credentials)\\ntest_dir = \\\"test_sub\\\"\\nclassic_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nnum_sub = NumeraiClassicSubmitter(directory_path=test_dir, key=classic_key)\\nassert num_sub.dir.is_dir()\\n\\n# Create random dataframe\\nn_rows = 100\\ntargets = \\\"prediction\\\"\\ntest_dataf = pd.DataFrame(np.random.uniform(size=n_rows), columns=[targets])\\ntest_dataf[\\\"id\\\"] = [uuid.uuid4() for _ in range(n_rows)]\\ntest_dataf = test_dataf.set_index(\\\"id\\\")\\ntest_dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example 1\n",
    "# Initialization (Random credentials)\n",
    "test_dir = \"test_sub\"\n",
    "classic_key = Key(pub_id=\"UFVCTElDX0lE\", secret_key=\"U1VQRVJfU0VDUkVUX0tFWQ==\")\n",
    "num_sub = NumeraiClassicSubmitter(directory_path=test_dir, key=classic_key)\n",
    "assert num_sub.dir.is_dir()\n",
    "\n",
    "# Create random dataframe\n",
    "n_rows = 100\n",
    "targets = \"prediction\"\n",
    "test_dataf = pd.DataFrame(np.random.uniform(size=n_rows), columns=[targets])\n",
    "test_dataf[\"id\"] = [uuid.uuid4() for _ in range(n_rows)]\n",
    "test_dataf = test_dataf.set_index(\"id\")\n",
    "test_dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "CSVs can be saved with `.save_csv`. `NumeraiClassicSubmitter` will automatically provide checks to make sure that data is saved correctly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 18:15:12,995 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-03-09 18:15:12,999 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": "ðŸ“„ Saving predictions CSV to \u001B[32m'test_sub/test.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub/test.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "ðŸ“„ Saving predictions CSV to \u001B[32m'test_sub/test2.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub/test2.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                     id  prediction\n0  bf49fd90-91cd-4232-b06e-bcda608f20ef    0.848623\n1  58634fe7-e200-4ce3-9431-338c2df71de8    0.472443",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bf49fd90-91cd-4232-b06e-bcda608f20ef</td>\n      <td>0.848623</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>58634fe7-e200-4ce3-9431-338c2df71de8</td>\n      <td>0.472443</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"file_name = \\\"test.csv\\\"\\nnum_sub.save_csv(dataf=test_dataf, file_name=file_name, cols=targets)\\nnum_sub.save_csv(dataf=test_dataf, file_name=\\\"test2.csv\\\", cols=targets)\\npd.read_csv(f\\\"{test_dir}/{file_name}\\\").head(2)\";\n                var nbb_formatted_code = \"file_name = \\\"test.csv\\\"\\nnum_sub.save_csv(dataf=test_dataf, file_name=file_name, cols=targets)\\nnum_sub.save_csv(dataf=test_dataf, file_name=\\\"test2.csv\\\", cols=targets)\\npd.read_csv(f\\\"{test_dir}/{file_name}\\\").head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = \"test.csv\"\n",
    "num_sub.save_csv(dataf=test_dataf, file_name=file_name, cols=targets)\n",
    "num_sub.save_csv(dataf=test_dataf, file_name=\"test2.csv\", cols=targets)\n",
    "pd.read_csv(f\"{test_dir}/{file_name}\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`NumeraiClassicSubmitter` also gives you the option to combine multiple predictions csvs that you already created. Prediction will be standardized by default."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<h4 id=\"BaseSubmitter.combine_csvs\" class=\"doc_header\"><code>BaseSubmitter.combine_csvs</code><a href=\"__main__.py#L68\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>BaseSubmitter.combine_csvs</code>(**`csv_paths`**:`list`, **`aux_cols`**:`list`, **`era_col`**:`str`=*`None`*, **`pred_col`**:`str`=*`'prediction'`*)\n\nRead in csv files and combine all predictions with a rank mean.\nMulti-target predictions will be averaged out.\n:param csv_paths: List of full paths to .csv prediction files.\n:param aux_cols: ['id'] for Numerai Classic and\nFor example ['ticker', 'last_friday', 'data_type'] for Numerai Signals.\nAll aux_cols will be stored as index.\n:param era_col: Column indicating era ('era' or 'last_friday').\nWill be used for Grouping the rank mean if given. Skip groupby if no era_col provided.\n:param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"#hide_input\\nshow_doc(NumeraiClassicSubmitter.combine_csvs)\";\n                var nbb_formatted_code = \"# hide_input\\nshow_doc(NumeraiClassicSubmitter.combine_csvs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "show_doc(NumeraiClassicSubmitter.combine_csvs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a68ba4b3f2943698a6ff8d867f4d92b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                      prediction\nid                                              \nbf49fd90-91cd-4232-b06e-bcda608f20ef        0.80\n58634fe7-e200-4ce3-9431-338c2df71de8        0.48",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bf49fd90-91cd-4232-b06e-bcda608f20ef</th>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>58634fe7-e200-4ce3-9431-338c2df71de8</th>\n      <td>0.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"combined = num_sub.combine_csvs([\\\"test_sub/test.csv\\\", \\\"test_sub/test2.csv\\\"], aux_cols=['id'])\\nassert combined.columns == ['prediction']\\ncombined.head(2)\";\n                var nbb_formatted_code = \"combined = num_sub.combine_csvs(\\n    [\\\"test_sub/test.csv\\\", \\\"test_sub/test2.csv\\\"], aux_cols=[\\\"id\\\"]\\n)\\nassert combined.columns == [\\\"prediction\\\"]\\ncombined.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = num_sub.combine_csvs([\"test_sub/test.csv\", \"test_sub/test2.csv\"], aux_cols=['id'])\n",
    "assert combined.columns == ['prediction']\n",
    "combined.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# hide\\ndef test_signal_validity(\\n        submittor: NumeraiClassicSubmitter, dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\" Test value range of prediction. \\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(dataf)\\n        invalid_signal.iloc[0][\\\"prediction\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=\\\"prediction\\\",\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\nassert test_signal_validity(num_sub, test_dataf)\";\n                var nbb_formatted_code = \"# hide\\ndef test_signal_validity(submittor: NumeraiClassicSubmitter, dataf: pd.DataFrame):\\n    \\\"\\\"\\\"Test value range of prediction.\\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(dataf)\\n        invalid_signal.iloc[0][\\\"prediction\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=\\\"prediction\\\",\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\n\\nassert test_signal_validity(num_sub, test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "def test_signal_validity(\n",
    "        submitter: NumeraiClassicSubmitter, dataf: pd.DataFrame\n",
    "):\n",
    "    \"\"\" Test value range of prediction. \"\"\"\n",
    "    try:\n",
    "        invalid_signal = deepcopy(dataf)\n",
    "        invalid_signal.iloc[0][\"prediction\"] += 10\n",
    "        submitter.save_csv(\n",
    "            invalid_signal,\n",
    "            file_name=\"should_not_save.csv\",\n",
    "            cols=\"prediction\",\n",
    "        )\n",
    "    except ValueError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "assert test_signal_validity(num_sub, test_dataf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uncomment to save CSV and upload predictions in one go."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"# Full submission\\n# num_sub.full_submission(dataf=test_dataf, file_name='test.csv', cols=targets, model_name=\\\"test\\\")\";\n                var nbb_formatted_code = \"# Full submission\\n# num_sub.full_submission(dataf=test_dataf, file_name='test.csv', cols=targets, model_name=\\\"test\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full submission\n",
    "# num_sub.full_submission(dataf=test_dataf, file_name='test.csv', cols=targets, model_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After a successful submission, contents can be removed to keep a clean environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "âš  \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicSubmitter\u001B[0m\u001B[32m'\u001B[0m âš \nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âš  <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicSubmitter</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> âš \nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"num_sub.remove_base_directory()\\nassert not os.path.exists(test_dir)\";\n                var nbb_formatted_code = \"num_sub.remove_base_directory()\\nassert not os.path.exists(test_dir)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_sub.remove_base_directory()\n",
    "assert not os.path.exists(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numerai Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numerai Signals submissions. Uses [SignalsAPI](https://numerapi.readthedocs.io/en/latest/_modules/numerapi/signalsapi.html) under the hood."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass NumeraiSignalsSubmitter(BaseSubmitter):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Signals.\\n\\n    | :param directory_path: Base directory to save and read prediction files from. \\\\n\\n    | :param key: Key object containing valid credentials for Numerai Signals. \\\\n\\n    | *args, **kwargs will be passed to SignalsAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = SignalsAPI(\\n            public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs\\n        )\\n        super().__init__(\\n            directory_path=directory_path, api=api\\n        )\\n        self.supported_ticker_formats = [\\n            \\\"cusip\\\",\\n            \\\"sedol\\\",\\n            \\\"ticker\\\",\\n            \\\"numerai_ticker\\\",\\n            \\\"bloomberg_ticker\\\",\\n        ]\\n\\n    def save_csv(\\n        self, dataf: pd.DataFrame, file_name: str, cols: list = None, *args, **kwargs\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n         1. One of supported ticker formats (cusip, sedol, ticker, numerai_ticker or bloomberg_ticker)\\n         2. signal (Values between 0 and 1 (exclusive))\\n         Additional columns for if you include validation data (optional):\\n         3. friday_date (YYYYMMDD format date indication)\\n         4. data_type ('val' and 'live' partitions)\\n\\n         :param file_name: .csv file path.\\n         :param cols: All cols that should be passed to CSV. Defaults to 2 standard columns.\\n          ('bloomberg_ticker', 'signal')\\n        \\\"\\\"\\\"\\n        if not cols:\\n            cols = [\\\"bloomberg_ticker\\\", \\\"signal\\\"]\\n\\n        self._check_ticker_format(cols=cols)\\n        self._check_value_range(dataf=dataf, cols=\\\"signal\\\")\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving Signals predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        dataf.loc[:, cols].reset_index(drop=True).to_csv(\\n            full_path, index=False, *args, **kwargs\\n        )\\n\\n    def _check_ticker_format(self, cols: list):\\n        \\\"\\\"\\\" Check for valid ticker format. \\\"\\\"\\\"\\n        valid_tickers = set(cols).intersection(set(self.supported_ticker_formats))\\n        if not valid_tickers:\\n            raise NotImplementedError(\\n                f\\\"No supported ticker format in {cols}). \\\\\\nSupported: '{self.supported_ticker_formats}'\\\"\\n            )\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass NumeraiSignalsSubmitter(BaseSubmitter):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Signals.\\n\\n    | :param directory_path: Base directory to save and read prediction files from. \\\\n\\n    | :param key: Key object containing valid credentials for Numerai Signals. \\\\n\\n    | *args, **kwargs will be passed to SignalsAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = SignalsAPI(\\n            public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs\\n        )\\n        super().__init__(directory_path=directory_path, api=api)\\n        self.supported_ticker_formats = [\\n            \\\"cusip\\\",\\n            \\\"sedol\\\",\\n            \\\"ticker\\\",\\n            \\\"numerai_ticker\\\",\\n            \\\"bloomberg_ticker\\\",\\n        ]\\n\\n    def save_csv(\\n        self, dataf: pd.DataFrame, file_name: str, cols: list = None, *args, **kwargs\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n         1. One of supported ticker formats (cusip, sedol, ticker, numerai_ticker or bloomberg_ticker)\\n         2. signal (Values between 0 and 1 (exclusive))\\n         Additional columns for if you include validation data (optional):\\n         3. friday_date (YYYYMMDD format date indication)\\n         4. data_type ('val' and 'live' partitions)\\n\\n         :param file_name: .csv file path.\\n         :param cols: All cols that should be passed to CSV. Defaults to 2 standard columns.\\n          ('bloomberg_ticker', 'signal')\\n        \\\"\\\"\\\"\\n        if not cols:\\n            cols = [\\\"bloomberg_ticker\\\", \\\"signal\\\"]\\n\\n        self._check_ticker_format(cols=cols)\\n        self._check_value_range(dataf=dataf, cols=\\\"signal\\\")\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving Signals predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        dataf.loc[:, cols].reset_index(drop=True).to_csv(\\n            full_path, index=False, *args, **kwargs\\n        )\\n\\n    def _check_ticker_format(self, cols: list):\\n        \\\"\\\"\\\"Check for valid ticker format.\\\"\\\"\\\"\\n        valid_tickers = set(cols).intersection(set(self.supported_ticker_formats))\\n        if not valid_tickers:\\n            raise NotImplementedError(\\n                f\\\"No supported ticker format in {cols}). \\\\\\nSupported: '{self.supported_ticker_formats}'\\\"\\n            )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class NumeraiSignalsSubmitter(BaseSubmitter):\n",
    "    \"\"\"\n",
    "    Submit for Numerai Signals.\n",
    "\n",
    "    | :param directory_path: Base directory to save and read prediction files from. \\n\n",
    "    | :param key: Key object containing valid credentials for Numerai Signals. \\n\n",
    "    | *args, **kwargs will be passed to SignalsAPI initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\n",
    "        api = SignalsAPI(\n",
    "            public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs\n",
    "        )\n",
    "        super().__init__(\n",
    "            directory_path=directory_path, api=api\n",
    "        )\n",
    "        self.supported_ticker_formats = [\n",
    "            \"cusip\",\n",
    "            \"sedol\",\n",
    "            \"ticker\",\n",
    "            \"numerai_ticker\",\n",
    "            \"bloomberg_ticker\",\n",
    "        ]\n",
    "\n",
    "    def save_csv(\n",
    "        self, dataf: pd.DataFrame, file_name: str, cols: list = None, *args, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param dataf: DataFrame which should have at least the following columns:\n",
    "         1. One of supported ticker formats (cusip, sedol, ticker, numerai_ticker or bloomberg_ticker)\n",
    "         2. signal (Values between 0 and 1 (exclusive))\n",
    "         Additional columns for if you include validation data (optional):\n",
    "         3. friday_date (YYYYMMDD format date indication)\n",
    "         4. data_type ('val' and 'live' partitions)\n",
    "\n",
    "         :param file_name: .csv file path.\n",
    "         :param cols: All cols that should be passed to CSV. Defaults to 2 standard columns.\n",
    "          ('bloomberg_ticker', 'signal')\n",
    "        \"\"\"\n",
    "        if not cols:\n",
    "            cols = [\"bloomberg_ticker\", \"signal\"]\n",
    "\n",
    "        self._check_ticker_format(cols=cols)\n",
    "        self._check_value_range(dataf=dataf, cols=\"signal\")\n",
    "\n",
    "        full_path = str(self.dir / file_name)\n",
    "        rich_print(\n",
    "            f\":page_facing_up: Saving Signals predictions CSV to '{full_path}'. :page_facing_up:\"\n",
    "        )\n",
    "        dataf.loc[:, cols].reset_index(drop=True).to_csv(\n",
    "            full_path, index=False, *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def _check_ticker_format(self, cols: list):\n",
    "        \"\"\" Check for valid ticker format. \"\"\"\n",
    "        valid_tickers = set(cols).intersection(set(self.supported_ticker_formats))\n",
    "        if not valid_tickers:\n",
    "            raise NotImplementedError(\n",
    "                f\"No supported ticker format in {cols}). \\\n",
    "Supported: '{self.supported_ticker_formats}'\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage 2: NumeraiSignalsSubmitter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialization (Random credentials)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ðŸ”‘ Numerai Auth key initialized with pub_id = \u001B[32m'UFVCTElDX0lE'\u001B[0m ðŸ”‘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”‘ Numerai Auth key initialized with pub_id = <span style=\"color: #008000; text-decoration-color: #008000\">'UFVCTElDX0lE'</span> ðŸ”‘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_sub_signals\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_sub_signals</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"test_dir_signals = \\\"test_sub_signals\\\"\\nsignals_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nsignals_sub = NumeraiSignalsSubmitter(directory_path=test_dir_signals, key=signals_key)\\nassert signals_sub.dir.is_dir()\";\n                var nbb_formatted_code = \"test_dir_signals = \\\"test_sub_signals\\\"\\nsignals_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nsignals_sub = NumeraiSignalsSubmitter(directory_path=test_dir_signals, key=signals_key)\\nassert signals_sub.dir.is_dir()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dir_signals = \"test_sub_signals\"\n",
    "signals_key = Key(pub_id=\"UFVCTElDX0lE\", secret_key=\"U1VQRVJfU0VDUkVUX0tFWQ==\")\n",
    "signals_sub = NumeraiSignalsSubmitter(directory_path=test_dir_signals, key=signals_key)\n",
    "assert signals_sub.dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     signal ticker last_friday data_type\n0  0.893796   JRHX    20220304      live\n1  0.492890   LWMF    20220304      live",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>signal</th>\n      <th>ticker</th>\n      <th>last_friday</th>\n      <th>data_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.893796</td>\n      <td>JRHX</td>\n      <td>20220304</td>\n      <td>live</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.492890</td>\n      <td>LWMF</td>\n      <td>20220304</td>\n      <td>live</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"def create_random_signals_dataf(n_rows=5000):\\n    signals_test_dataf = pd.DataFrame(\\n        np.random.uniform(size=(n_rows, 1)), columns=[\\\"signal\\\"]\\n    )\\n    signals_test_dataf[\\\"ticker\\\"] = [\\n        \\\"\\\".join(choices(ascii_uppercase, k=4)) for _ in range(n_rows)\\n    ]\\n    last_friday = str((datetime.now() + relativedelta(weekday=FR(-1))).date()).replace(\\\"-\\\", \\\"\\\")\\n    signals_test_dataf['last_friday'] = last_friday\\n    signals_test_dataf['data_type'] = 'live'\\n    return signals_test_dataf\\n\\nsignals_test_dataf = create_random_signals_dataf()\\nsignals_test_dataf.head(2)\";\n                var nbb_formatted_code = \"def create_random_signals_dataf(n_rows=5000):\\n    signals_test_dataf = pd.DataFrame(\\n        np.random.uniform(size=(n_rows, 1)), columns=[\\\"signal\\\"]\\n    )\\n    signals_test_dataf[\\\"ticker\\\"] = [\\n        \\\"\\\".join(choices(ascii_uppercase, k=4)) for _ in range(n_rows)\\n    ]\\n    last_friday = str((datetime.now() + relativedelta(weekday=FR(-1))).date()).replace(\\n        \\\"-\\\", \\\"\\\"\\n    )\\n    signals_test_dataf[\\\"last_friday\\\"] = last_friday\\n    signals_test_dataf[\\\"data_type\\\"] = \\\"live\\\"\\n    return signals_test_dataf\\n\\n\\nsignals_test_dataf = create_random_signals_dataf()\\nsignals_test_dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_random_signals_dataf(n_rows=5000):\n",
    "    signals_test_dataf = pd.DataFrame(\n",
    "        np.random.uniform(size=(n_rows, 1)), columns=[\"signal\"]\n",
    "    )\n",
    "    signals_test_dataf[\"ticker\"] = [\n",
    "        \"\".join(choices(ascii_uppercase, k=4)) for _ in range(n_rows)\n",
    "    ]\n",
    "    last_friday = str((datetime.now() + relativedelta(weekday=FR(-1))).date()).replace(\"-\", \"\")\n",
    "    signals_test_dataf['last_friday'] = last_friday\n",
    "    signals_test_dataf['data_type'] = 'live'\n",
    "    return signals_test_dataf\n",
    "\n",
    "signals_test_dataf = create_random_signals_dataf()\n",
    "signals_test_dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ðŸ“„ Saving Signals predictions CSV to \u001B[32m'test_sub_signals/signals_test.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving Signals predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub_signals/signals_test.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "ðŸ“„ Saving Signals predictions CSV to \u001B[32m'test_sub_signals/signals_test2.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving Signals predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub_signals/signals_test2.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     signal ticker data_type  last_friday\n0  0.893796   JRHX      live     20220304\n1  0.492890   LWMF      live     20220304",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>signal</th>\n      <th>ticker</th>\n      <th>data_type</th>\n      <th>last_friday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.893796</td>\n      <td>JRHX</td>\n      <td>live</td>\n      <td>20220304</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.492890</td>\n      <td>LWMF</td>\n      <td>live</td>\n      <td>20220304</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"# hide\\nsignals_cols = [\\\"signal\\\", \\\"ticker\\\", \\\"data_type\\\", \\\"last_friday\\\"]\\nfile_name = \\\"signals_test.csv\\\"\\nsignals_sub.save_csv(dataf=signals_test_dataf, file_name=file_name, cols=signals_cols)\\nsignals_sub.save_csv(dataf=signals_test_dataf, file_name=\\\"signals_test2.csv\\\", cols=signals_cols)\\npd.read_csv(f\\\"{test_dir_signals}/{file_name}\\\").head(2)\";\n                var nbb_formatted_code = \"# hide\\nsignals_cols = [\\\"signal\\\", \\\"ticker\\\", \\\"data_type\\\", \\\"last_friday\\\"]\\nfile_name = \\\"signals_test.csv\\\"\\nsignals_sub.save_csv(dataf=signals_test_dataf, file_name=file_name, cols=signals_cols)\\nsignals_sub.save_csv(\\n    dataf=signals_test_dataf, file_name=\\\"signals_test2.csv\\\", cols=signals_cols\\n)\\npd.read_csv(f\\\"{test_dir_signals}/{file_name}\\\").head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "signals_cols = [\"signal\", \"ticker\", \"data_type\", \"last_friday\"]\n",
    "file_name = \"signals_test.csv\"\n",
    "signals_sub.save_csv(dataf=signals_test_dataf, file_name=file_name, cols=signals_cols)\n",
    "signals_sub.save_csv(dataf=signals_test_dataf, file_name=\"signals_test2.csv\", cols=signals_cols)\n",
    "pd.read_csv(f\"{test_dir_signals}/{file_name}\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51c4241f4fc94137883669cb306b6d70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                              signal\nticker last_friday data_type        \nJRHX   20220304    live       0.8950\nLWMF   20220304    live       0.4926",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>signal</th>\n    </tr>\n    <tr>\n      <th>ticker</th>\n      <th>last_friday</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>JRHX</th>\n      <th>20220304</th>\n      <th>live</th>\n      <td>0.8950</td>\n    </tr>\n    <tr>\n      <th>LWMF</th>\n      <th>20220304</th>\n      <th>live</th>\n      <td>0.4926</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"# hide\\ncombined_signals = signals_sub.combine_csvs(csv_paths=[\\\"test_sub_signals/signals_test.csv\\\",\\n                                               \\\"test_sub_signals/signals_test2.csv\\\"],\\n                                    aux_cols=['ticker', 'last_friday', 'data_type'],\\n                                    era_col='last_friday',\\n                                    pred_col='signal')\\nassert combined_signals.columns == ['signal']\\ncombined_signals.head(2)\";\n                var nbb_formatted_code = \"# hide\\ncombined_signals = signals_sub.combine_csvs(\\n    csv_paths=[\\n        \\\"test_sub_signals/signals_test.csv\\\",\\n        \\\"test_sub_signals/signals_test2.csv\\\",\\n    ],\\n    aux_cols=[\\\"ticker\\\", \\\"last_friday\\\", \\\"data_type\\\"],\\n    era_col=\\\"last_friday\\\",\\n    pred_col=\\\"signal\\\",\\n)\\nassert combined_signals.columns == [\\\"signal\\\"]\\ncombined_signals.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "combined_signals = signals_sub.combine_csvs(csv_paths=[\"test_sub_signals/signals_test.csv\",\n",
    "                                               \"test_sub_signals/signals_test2.csv\"],\n",
    "                                    aux_cols=['ticker', 'last_friday', 'data_type'],\n",
    "                                    era_col='last_friday',\n",
    "                                    pred_col='signal')\n",
    "assert combined_signals.columns == ['signal']\n",
    "combined_signals.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Signals CSV should fail if there is no valid ticker column or if `signal` has values outside the range $[0...1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"def test_signal_validity(\\n    submittor: NumeraiSignalsSubmitter, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\" Test value range of signal. \\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(signals_dataf)\\n        invalid_signal.loc[0, \\\"signal\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_signal.columns),\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\n\\ndef test_ticker_validity(\\n    submittor: NumeraiSignalsSubmitter, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\" Test safeguard if ticker column is not valid. \\\"\\\"\\\"\\n    try:\\n        invalid_ticker = deepcopy(signals_dataf)\\n        invalid_ticker = invalid_ticker.rename(\\n            {\\\"ticker\\\": \\\"not_a_valid_ticker_format\\\"}, axis=1\\n        )\\n        submittor.save_csv(\\n            invalid_ticker,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_ticker.columns),\\n        )\\n    except NotImplementedError:\\n        return True\\n    return False\\n\\nassert test_signal_validity(signals_sub, signals_test_dataf)\\nassert test_ticker_validity(signals_sub, signals_test_dataf)\";\n                var nbb_formatted_code = \"def test_signal_validity(\\n    submittor: NumeraiSignalsSubmitter, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\"Test value range of signal.\\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(signals_dataf)\\n        invalid_signal.loc[0, \\\"signal\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_signal.columns),\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\n\\ndef test_ticker_validity(\\n    submittor: NumeraiSignalsSubmitter, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\"Test safeguard if ticker column is not valid.\\\"\\\"\\\"\\n    try:\\n        invalid_ticker = deepcopy(signals_dataf)\\n        invalid_ticker = invalid_ticker.rename(\\n            {\\\"ticker\\\": \\\"not_a_valid_ticker_format\\\"}, axis=1\\n        )\\n        submittor.save_csv(\\n            invalid_ticker,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_ticker.columns),\\n        )\\n    except NotImplementedError:\\n        return True\\n    return False\\n\\n\\nassert test_signal_validity(signals_sub, signals_test_dataf)\\nassert test_ticker_validity(signals_sub, signals_test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_signal_validity(\n",
    "    submitter: NumeraiSignalsSubmitter, signals_dataf: pd.DataFrame\n",
    "):\n",
    "    \"\"\" Test value range of signal. \"\"\"\n",
    "    try:\n",
    "        invalid_signal = deepcopy(signals_dataf)\n",
    "        invalid_signal.loc[0, \"signal\"] += 10\n",
    "        submitter.save_csv(\n",
    "            invalid_signal,\n",
    "            file_name=\"should_not_save.csv\",\n",
    "            cols=list(invalid_signal.columns),\n",
    "        )\n",
    "    except ValueError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def test_ticker_validity(\n",
    "    submitter: NumeraiSignalsSubmitter, signals_dataf: pd.DataFrame\n",
    "):\n",
    "    \"\"\" Test safeguard if ticker column is not valid. \"\"\"\n",
    "    try:\n",
    "        invalid_ticker = deepcopy(signals_dataf)\n",
    "        invalid_ticker = invalid_ticker.rename(\n",
    "            {\"ticker\": \"not_a_valid_ticker_format\"}, axis=1\n",
    "        )\n",
    "        submitter.save_csv(\n",
    "            invalid_ticker,\n",
    "            file_name=\"should_not_save.csv\",\n",
    "            cols=list(invalid_ticker.columns),\n",
    "        )\n",
    "    except NotImplementedError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "assert test_signal_validity(signals_sub, signals_test_dataf)\n",
    "assert test_ticker_validity(signals_sub, signals_test_dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uncomment to save CSV and upload predictions in one go."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"# Full submission Signals\\n# signals_sub.full_submission(dataf=signals_test_dataf, file_name='signals_test.csv', cols=signals_cols, model_name=\\\"test\\\")\";\n                var nbb_formatted_code = \"# Full submission Signals\\n# signals_sub.full_submission(dataf=signals_test_dataf, file_name='signals_test.csv', cols=signals_cols, model_name=\\\"test\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full Signals submission\n",
    "# signals_sub.full_submission(dataf=signals_test_dataf, file_name='signals_test.csv', cols=signals_cols, model_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After a successful submission, contents can be removed to keep a clean environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "âš  \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiSignalsSubmitter\u001B[0m\u001B[32m'\u001B[0m âš \nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub_signals'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âš  <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiSignalsSubmitter</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> âš \nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub_signals'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"signals_sub.remove_base_directory()\\nassert not os.path.exists(test_dir_signals)\";\n                var nbb_formatted_code = \"signals_sub.remove_base_directory()\\nassert not os.path.exists(test_dir_signals)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signals_sub.remove_base_directory()\n",
    "assert not os.path.exists(test_dir_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_misc.ipynb.\n",
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}