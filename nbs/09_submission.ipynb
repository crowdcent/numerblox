{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp submission\";\n                var nbb_formatted_code = \"# default_exp submission\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "These objects allow you to easily and reliably submit predictions for Numerai Classic and Numerai Signals.\n",
    "\n",
    "The main objects are:\n",
    "1. `NumeraiClassicSubmittor`\n",
    "2. `NumeraiSignalsSubmittor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# export\\nimport os\\nimport uuid\\nimport numpy as np\\nimport pandas as pd\\nfrom typing import Union\\nfrom copy import deepcopy\\nfrom random import choices\\nfrom tqdm.auto import tqdm\\nfrom datetime import datetime\\nfrom abc import abstractmethod\\nfrom typeguard import typechecked\\nfrom string import ascii_uppercase\\nfrom rich import print as rich_print\\nfrom numerapi import NumerAPI, SignalsAPI\\nfrom dateutil.relativedelta import relativedelta, FR\\n\\nfrom numerai_blocks.download import BaseIO\\nfrom numerai_blocks.key import Key\";\n                var nbb_formatted_code = \"# export\\nimport os\\nimport uuid\\nimport numpy as np\\nimport pandas as pd\\nfrom typing import Union\\nfrom copy import deepcopy\\nfrom random import choices\\nfrom tqdm.auto import tqdm\\nfrom datetime import datetime\\nfrom abc import abstractmethod\\nfrom typeguard import typechecked\\nfrom string import ascii_uppercase\\nfrom rich import print as rich_print\\nfrom numerapi import NumerAPI, SignalsAPI\\nfrom dateutil.relativedelta import relativedelta, FR\\n\\nfrom numerai_blocks.download import BaseIO\\nfrom numerai_blocks.key import Key\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from copy import deepcopy\n",
    "from random import choices\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from abc import abstractmethod\n",
    "from typeguard import typechecked\n",
    "from string import ascii_uppercase\n",
    "from rich import print as rich_print\n",
    "from numerapi import NumerAPI, SignalsAPI\n",
    "from dateutil.relativedelta import relativedelta, FR\n",
    "\n",
    "from numerai_blocks.download import BaseIO\n",
    "from numerai_blocks.key import Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BaseSubmittor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`BaseSubmittor` handles all submission logic common to Numerai Classic and Numerai Signals. Under the hood directory logic is handled by `BaseIO`.\n",
    "Each submittor should inherit from `BaseSubmittor` and implement the `.save_csv` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass BaseSubmittor(BaseIO):\\n    def __init__(self, directory_path: str, api: Union[NumerAPI, SignalsAPI]):\\n        super().__init__(directory_path)\\n        self.api = api\\n\\n    @abstractmethod\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        For Numerai Classic: Save index column + 'cols' (targets) to CSV.\\n        For Numerai Signals: Save ticker, friday_date, data_type and signal columns to CSV.\\n        \\\"\\\"\\\"\\n        ...\\n\\n    def upload_predictions(self, file_name: str, model_name: str, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        Upload CSV file to Numerai for given model name.\\n        :param file_name: File name/path relative to directory_path.\\n        :param model_name: Lowercase raw model name (For example, 'integration_test').\\n        \\\"\\\"\\\"\\n        full_path = str(self.dir / file_name)\\n        model_id = self._get_model_id(model_name=model_name)\\n        api_type = str(self.api.__class__.__name__)\\n        rich_print(\\n            f\\\":airplane: {api_type}: Uploading predictions from '{full_path}' for model [bold blue]'{model_name}'[/bold blue] (model_id='{model_id}') :airplane:\\\"\\n        )\\n        self.api.upload_predictions(\\n            file_path=full_path, model_id=model_id, *args, **kwargs\\n        )\\n        rich_print(\\n            f\\\":thumbs_up: {api_type} submission of '{full_path}' for [bold blue]{model_name}[/bold blue] is successful! :thumbs_up:\\\"\\n        )\\n\\n    def full_submission(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        model_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        Save DataFrame to csv and upload predictions through API.\\n        *args, **kwargs are passed to numerapi API.\\n        \\\"\\\"\\\"\\n        self.save_csv(dataf=dataf, file_name=file_name, cols=cols)\\n        self.upload_predictions(\\n            file_name=file_name, model_name=model_name, *args, **kwargs\\n        )\\n\\n    def combine_csvs(self, csv_paths: list,\\n                     aux_cols: list,\\n                     era_col: str = None,\\n                     pred_col: str = 'prediction') -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Read in csv files and combine all predictions with a rank mean.\\n        Multi-target predictions will be averaged out.\\n        :param csv_paths: List of full paths to .csv prediction files.\\n        :param aux_cols: ['id'] for Numerai Classic and [ticker column] for Numerai Signals.\\n        :param era_col: Column indicating era ('era' or 'last_friday').\\n        Will be used for ranked mean if given. Groupby will be skipped by default.\\n        :param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals.\\n        \\\"\\\"\\\"\\n        all_datafs = [pd.read_csv(path, index_col=aux_cols) for path in tqdm(csv_paths)]\\n        final_dataf = pd.concat(all_datafs, axis=\\\"columns\\\")\\n        # Remove issue of duplicate columns\\n        numeric_cols = final_dataf.select_dtypes(include=np.number).columns\\n        final_dataf.rename({k: str(v) for k, v in zip(numeric_cols, range(len(numeric_cols)))},\\n                           axis=1,\\n                           inplace=True)\\n        # Combine all numeric columns with rank mean\\n        num_dataf = final_dataf.select_dtypes(include=np.number)\\n        num_dataf = num_dataf.groupby(era_col) if era_col else final_dataf\\n        final_dataf[pred_col] = num_dataf.rank(pct=True, method=\\\"first\\\").mean(axis=1)\\n        return final_dataf[[pred_col]]\\n\\n    def _get_model_id(self, model_name: str) -> str:\\n        \\\"\\\"\\\"\\n        Get ID needed for prediction uploading.\\n        :param model_name: Raw lowercase model name\\n        of model that you have access to.\\n        \\\"\\\"\\\"\\n        return self.get_model_mapping[model_name]\\n\\n    @property\\n    def get_model_mapping(self) -> dict:\\n        \\\"\\\"\\\"Mapping between raw model names and model IDs.\\\"\\\"\\\"\\n        return self.api.get_models()\\n\\n    def _check_value_range(self, dataf: pd.DataFrame, cols: Union[str, list]):\\n        \\\"\\\"\\\" Check if all predictions are in range (0...1). \\\"\\\"\\\"\\n        cols = [cols] if isinstance(cols, str) else cols\\n        for col in cols:\\n            if not dataf[col].between(0, 1).all():\\n                min_val, max_val = dataf[col].min(), dataf[col].max()\\n                raise ValueError(\\n                    f\\\"Values in 'signal' must be between 0 and 1 (exclusive). \\\\\\nFound min value of '{min_val}' and max value of '{max_val}' for column '{col}'.\\\"\\n                )\\n\\n    def __call__(\\n            self,\\n            dataf: pd.DataFrame,\\n            file_name: str,\\n            model_name: str,\\n            cols: Union[str, list],\\n            *args,\\n            **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        The most common use case will be to create a CSV and submit it immediately after that.\\n        full_submission handles this.\\n        \\\"\\\"\\\"\\n        self.full_submission(\\n            dataf=dataf,\\n            file_name=file_name,\\n            model_name=model_name,\\n            cols=cols,\\n            *args,\\n            **kwargs,\\n        )\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass BaseSubmittor(BaseIO):\\n    def __init__(self, directory_path: str, api: Union[NumerAPI, SignalsAPI]):\\n        super().__init__(directory_path)\\n        self.api = api\\n\\n    @abstractmethod\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        For Numerai Classic: Save index column + 'cols' (targets) to CSV.\\n        For Numerai Signals: Save ticker, friday_date, data_type and signal columns to CSV.\\n        \\\"\\\"\\\"\\n        ...\\n\\n    def upload_predictions(self, file_name: str, model_name: str, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        Upload CSV file to Numerai for given model name.\\n        :param file_name: File name/path relative to directory_path.\\n        :param model_name: Lowercase raw model name (For example, 'integration_test').\\n        \\\"\\\"\\\"\\n        full_path = str(self.dir / file_name)\\n        model_id = self._get_model_id(model_name=model_name)\\n        api_type = str(self.api.__class__.__name__)\\n        rich_print(\\n            f\\\":airplane: {api_type}: Uploading predictions from '{full_path}' for model [bold blue]'{model_name}'[/bold blue] (model_id='{model_id}') :airplane:\\\"\\n        )\\n        self.api.upload_predictions(\\n            file_path=full_path, model_id=model_id, *args, **kwargs\\n        )\\n        rich_print(\\n            f\\\":thumbs_up: {api_type} submission of '{full_path}' for [bold blue]{model_name}[/bold blue] is successful! :thumbs_up:\\\"\\n        )\\n\\n    def full_submission(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        model_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        Save DataFrame to csv and upload predictions through API.\\n        *args, **kwargs are passed to numerapi API.\\n        \\\"\\\"\\\"\\n        self.save_csv(dataf=dataf, file_name=file_name, cols=cols)\\n        self.upload_predictions(\\n            file_name=file_name, model_name=model_name, *args, **kwargs\\n        )\\n\\n    def combine_csvs(\\n        self,\\n        csv_paths: list,\\n        aux_cols: list,\\n        era_col: str = None,\\n        pred_col: str = \\\"prediction\\\",\\n    ) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Read in csv files and combine all predictions with a rank mean.\\n        Multi-target predictions will be averaged out.\\n        :param csv_paths: List of full paths to .csv prediction files.\\n        :param aux_cols: ['id'] for Numerai Classic and [ticker column] for Numerai Signals.\\n        :param era_col: Column indicating era ('era' or 'last_friday').\\n        Will be used for ranked mean if given. Groupby will be skipped by default.\\n        :param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals.\\n        \\\"\\\"\\\"\\n        all_datafs = [pd.read_csv(path, index_col=aux_cols) for path in tqdm(csv_paths)]\\n        final_dataf = pd.concat(all_datafs, axis=\\\"columns\\\")\\n        # Remove issue of duplicate columns\\n        numeric_cols = final_dataf.select_dtypes(include=np.number).columns\\n        final_dataf.rename(\\n            {k: str(v) for k, v in zip(numeric_cols, range(len(numeric_cols)))},\\n            axis=1,\\n            inplace=True,\\n        )\\n        # Combine all numeric columns with rank mean\\n        num_dataf = final_dataf.select_dtypes(include=np.number)\\n        num_dataf = num_dataf.groupby(era_col) if era_col else final_dataf\\n        final_dataf[pred_col] = num_dataf.rank(pct=True, method=\\\"first\\\").mean(axis=1)\\n        return final_dataf[[pred_col]]\\n\\n    def _get_model_id(self, model_name: str) -> str:\\n        \\\"\\\"\\\"\\n        Get ID needed for prediction uploading.\\n        :param model_name: Raw lowercase model name\\n        of model that you have access to.\\n        \\\"\\\"\\\"\\n        return self.get_model_mapping[model_name]\\n\\n    @property\\n    def get_model_mapping(self) -> dict:\\n        \\\"\\\"\\\"Mapping between raw model names and model IDs.\\\"\\\"\\\"\\n        return self.api.get_models()\\n\\n    def _check_value_range(self, dataf: pd.DataFrame, cols: Union[str, list]):\\n        \\\"\\\"\\\"Check if all predictions are in range (0...1).\\\"\\\"\\\"\\n        cols = [cols] if isinstance(cols, str) else cols\\n        for col in cols:\\n            if not dataf[col].between(0, 1).all():\\n                min_val, max_val = dataf[col].min(), dataf[col].max()\\n                raise ValueError(\\n                    f\\\"Values in 'signal' must be between 0 and 1 (exclusive). \\\\\\nFound min value of '{min_val}' and max value of '{max_val}' for column '{col}'.\\\"\\n                )\\n\\n    def __call__(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        model_name: str,\\n        cols: Union[str, list],\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        The most common use case will be to create a CSV and submit it immediately after that.\\n        full_submission handles this.\\n        \\\"\\\"\\\"\\n        self.full_submission(\\n            dataf=dataf,\\n            file_name=file_name,\\n            model_name=model_name,\\n            cols=cols,\\n            *args,\\n            **kwargs,\\n        )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class BaseSubmittor(BaseIO):\n",
    "    def __init__(self, directory_path: str, api: Union[NumerAPI, SignalsAPI]):\n",
    "        super().__init__(directory_path)\n",
    "        self.api = api\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_csv(\n",
    "        self,\n",
    "        dataf: pd.DataFrame,\n",
    "        file_name: str,\n",
    "        cols: Union[str, list],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        For Numerai Classic: Save index column + 'cols' (targets) to CSV.\n",
    "        For Numerai Signals: Save ticker, friday_date, data_type and signal columns to CSV.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def upload_predictions(self, file_name: str, model_name: str, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Upload CSV file to Numerai for given model name.\n",
    "        :param file_name: File name/path relative to directory_path.\n",
    "        :param model_name: Lowercase raw model name (For example, 'integration_test').\n",
    "        \"\"\"\n",
    "        full_path = str(self.dir / file_name)\n",
    "        model_id = self._get_model_id(model_name=model_name)\n",
    "        api_type = str(self.api.__class__.__name__)\n",
    "        rich_print(\n",
    "            f\":airplane: {api_type}: Uploading predictions from '{full_path}' for model [bold blue]'{model_name}'[/bold blue] (model_id='{model_id}') :airplane:\"\n",
    "        )\n",
    "        self.api.upload_predictions(\n",
    "            file_path=full_path, model_id=model_id, *args, **kwargs\n",
    "        )\n",
    "        rich_print(\n",
    "            f\":thumbs_up: {api_type} submission of '{full_path}' for [bold blue]{model_name}[/bold blue] is successful! :thumbs_up:\"\n",
    "        )\n",
    "\n",
    "    def full_submission(\n",
    "        self,\n",
    "        dataf: pd.DataFrame,\n",
    "        file_name: str,\n",
    "        model_name: str,\n",
    "        cols: Union[str, list],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save DataFrame to csv and upload predictions through API.\n",
    "        *args, **kwargs are passed to numerapi API.\n",
    "        \"\"\"\n",
    "        self.save_csv(dataf=dataf, file_name=file_name, cols=cols)\n",
    "        self.upload_predictions(\n",
    "            file_name=file_name, model_name=model_name, *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def combine_csvs(self, csv_paths: list,\n",
    "                     aux_cols: list,\n",
    "                     era_col: str = None,\n",
    "                     pred_col: str = 'prediction') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Read in csv files and combine all predictions with a rank mean.\n",
    "        Multi-target predictions will be averaged out.\n",
    "        :param csv_paths: List of full paths to .csv prediction files.\n",
    "        :param aux_cols: ['id'] for Numerai Classic and\n",
    "        For example ['ticker', 'last_friday', 'data_type'] for Numerai Signals.\n",
    "        :param era_col: Column indicating era ('era' or 'last_friday').\n",
    "        Will be used for Grouping the rank mean if given. Skip groupby if no era_col provided.\n",
    "        :param pred_col: 'prediction' for Numerai Classic and 'signal' for Numerai Signals.\n",
    "        \"\"\"\n",
    "        all_datafs = [pd.read_csv(path, index_col=aux_cols) for path in tqdm(csv_paths)]\n",
    "        final_dataf = pd.concat(all_datafs, axis=\"columns\")\n",
    "        # Remove issue of duplicate columns\n",
    "        numeric_cols = final_dataf.select_dtypes(include=np.number).columns\n",
    "        final_dataf.rename({k: str(v) for k, v in zip(numeric_cols, range(len(numeric_cols)))},\n",
    "                           axis=1,\n",
    "                           inplace=True)\n",
    "        # Combine all numeric columns with rank mean\n",
    "        num_dataf = final_dataf.select_dtypes(include=np.number)\n",
    "        num_dataf = num_dataf.groupby(era_col) if era_col else final_dataf\n",
    "        final_dataf[pred_col] = num_dataf.rank(pct=True, method=\"first\").mean(axis=1)\n",
    "        return final_dataf[[pred_col]]\n",
    "\n",
    "    def _get_model_id(self, model_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Get ID needed for prediction uploading.\n",
    "        :param model_name: Raw lowercase model name\n",
    "        of Numerai model that you have access to.\n",
    "        \"\"\"\n",
    "        return self.get_model_mapping[model_name]\n",
    "\n",
    "    @property\n",
    "    def get_model_mapping(self) -> dict:\n",
    "        \"\"\"Mapping between raw model names and model IDs.\"\"\"\n",
    "        return self.api.get_models()\n",
    "\n",
    "    def _check_value_range(self, dataf: pd.DataFrame, cols: Union[str, list]):\n",
    "        \"\"\" Check if all predictions are in range (0...1). \"\"\"\n",
    "        cols = [cols] if isinstance(cols, str) else cols\n",
    "        for col in cols:\n",
    "            if not dataf[col].between(0, 1).all():\n",
    "                min_val, max_val = dataf[col].min(), dataf[col].max()\n",
    "                raise ValueError(\n",
    "                    f\"Values in 'signal' must be between 0 and 1 (exclusive). \\\n",
    "Found min value of '{min_val}' and max value of '{max_val}' for column '{col}'.\"\n",
    "                )\n",
    "\n",
    "    def __call__(\n",
    "            self,\n",
    "            dataf: pd.DataFrame,\n",
    "            file_name: str,\n",
    "            model_name: str,\n",
    "            cols: Union[str, list],\n",
    "            *args,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The most common use case will be to create a CSV and submit it immediately after that.\n",
    "        full_submission handles this.\n",
    "        \"\"\"\n",
    "        self.full_submission(\n",
    "            dataf=dataf,\n",
    "            file_name=file_name,\n",
    "            model_name=model_name,\n",
    "            cols=cols,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For Numerai Classic submissions. Uses [NumerAPI](https://numerapi.readthedocs.io/en/latest/_modules/numerapi/numerapi.html) under the hood.\n",
    "\n",
    "Note that using submittors requires a `Key` object. For more information about this, see section 8."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass NumeraiClassicSubmittor(BaseSubmittor):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Classic.\\n    :param directory_path: Base directory to save and read prediction files from.\\n    :param key: Key object (numerai-blocks.key.Key) containing valid credentials for Numerai Classic.\\n    *args, **kwargs will be passed to NumerAPI initialization.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = NumerAPI(public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs)\\n        super().__init__(\\n            directory_path=directory_path, api=api\\n        )\\n\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: Union[str, list] = \\\"prediction\\\",\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n        1. id (as index column)\\n        2. cols (for example, 'prediction', ['prediction'] or [ALL_NUMERAI_TARGETS]).\\n        :param file_name: .csv file path .\\n        :param cols: All prediction columns.\\n        For example, 'prediction', ['prediction'] or [ALL_NUMERAI_TARGETS].\\n        \\\"\\\"\\\"\\n        self._check_value_range(dataf=dataf, cols=cols)\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        dataf.loc[:, cols].to_csv(full_path, *args, **kwargs)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass NumeraiClassicSubmittor(BaseSubmittor):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Classic.\\n    :param directory_path: Base directory to save and read prediction files from.\\n    :param key: Key object (numerai-blocks.key.Key) containing valid credentials for Numerai Classic.\\n    *args, **kwargs will be passed to NumerAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = NumerAPI(public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs)\\n        super().__init__(directory_path=directory_path, api=api)\\n\\n    def save_csv(\\n        self,\\n        dataf: pd.DataFrame,\\n        file_name: str,\\n        cols: Union[str, list] = \\\"prediction\\\",\\n        *args,\\n        **kwargs,\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n        1. id (as index column)\\n        2. cols (for example, 'prediction', ['prediction'] or [ALL_NUMERAI_TARGETS]).\\n        :param file_name: .csv file path .\\n        :param cols: All prediction columns.\\n        For example, 'prediction', ['prediction'] or [ALL_NUMERAI_TARGETS].\\n        \\\"\\\"\\\"\\n        self._check_value_range(dataf=dataf, cols=cols)\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        dataf.loc[:, cols].to_csv(full_path, *args, **kwargs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class NumeraiClassicSubmittor(BaseSubmittor):\n",
    "    \"\"\"\n",
    "    Submit for Numerai Classic.\n",
    "    :param directory_path: Base directory to save and read prediction files from.\n",
    "    :param key: Key object (numerai-blocks.key.Key) containing valid credentials for Numerai Classic.\n",
    "    *args, **kwargs will be passed to NumerAPI initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\n",
    "        api = NumerAPI(public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs)\n",
    "        super().__init__(\n",
    "            directory_path=directory_path, api=api\n",
    "        )\n",
    "\n",
    "    def save_csv(\n",
    "        self,\n",
    "        dataf: pd.DataFrame,\n",
    "        file_name: str,\n",
    "        cols: Union[str, list] = \"prediction\",\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param dataf: DataFrame which should have at least the following columns:\n",
    "        1. id (as index column)\n",
    "        2. cols (for example, 'prediction', ['prediction'] or [ALL_NUMERAI_TARGETS]).\n",
    "        :param file_name: .csv file path .\n",
    "        :param cols: All prediction columns.\n",
    "        For example, 'prediction', ['prediction'] or [ALL_NUMERAI_TARGETS].\n",
    "        \"\"\"\n",
    "        self._check_value_range(dataf=dataf, cols=cols)\n",
    "\n",
    "        full_path = str(self.dir / file_name)\n",
    "        rich_print(\n",
    "            f\":page_facing_up: Saving predictions CSV to '{full_path}'. :page_facing_up:\"\n",
    "        )\n",
    "        dataf.loc[:, cols].to_csv(full_path, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumeraiClassicSubmittor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ðŸ”‘ Numerai Auth key initialized with pub_id = \u001B[32m'UFVCTElDX0lE'\u001B[0m ðŸ”‘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”‘ Numerai Auth key initialized with pub_id = <span style=\"color: #008000; text-decoration-color: #008000\">'UFVCTElDX0lE'</span> ðŸ”‘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_sub\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_sub</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                      prediction_0  prediction_1  \\\nid                                                                 \n16a05375-2b6f-4246-be6a-5a6b506199c8      0.966805      0.445274   \nbf4ec661-0391-42c4-9535-dc79dcdc8663      0.395945      0.115366   \n\n                                      prediction_2  prediction_3  \\\nid                                                                 \n16a05375-2b6f-4246-be6a-5a6b506199c8      0.113626      0.872420   \nbf4ec661-0391-42c4-9535-dc79dcdc8663      0.121587      0.664771   \n\n                                      prediction_4  prediction_5  \\\nid                                                                 \n16a05375-2b6f-4246-be6a-5a6b506199c8      0.871790      0.326325   \nbf4ec661-0391-42c4-9535-dc79dcdc8663      0.889804      0.200167   \n\n                                      prediction_6  prediction_7  \\\nid                                                                 \n16a05375-2b6f-4246-be6a-5a6b506199c8      0.354165      0.631607   \nbf4ec661-0391-42c4-9535-dc79dcdc8663      0.455613      0.860832   \n\n                                      prediction_8  prediction_9  \\\nid                                                                 \n16a05375-2b6f-4246-be6a-5a6b506199c8      0.824616      0.057961   \nbf4ec661-0391-42c4-9535-dc79dcdc8663      0.700849      0.979715   \n\n                                      prediction_10  prediction_11  \\\nid                                                                   \n16a05375-2b6f-4246-be6a-5a6b506199c8       0.970455       0.448550   \nbf4ec661-0391-42c4-9535-dc79dcdc8663       0.616883       0.919233   \n\n                                      prediction_12  prediction_13  \\\nid                                                                   \n16a05375-2b6f-4246-be6a-5a6b506199c8       0.632162       0.263125   \nbf4ec661-0391-42c4-9535-dc79dcdc8663       0.206422       0.168764   \n\n                                      prediction_14  prediction_15  \\\nid                                                                   \n16a05375-2b6f-4246-be6a-5a6b506199c8       0.869591       0.586021   \nbf4ec661-0391-42c4-9535-dc79dcdc8663       0.325130       0.874233   \n\n                                      prediction_16  prediction_17  \\\nid                                                                   \n16a05375-2b6f-4246-be6a-5a6b506199c8       0.539623       0.852208   \nbf4ec661-0391-42c4-9535-dc79dcdc8663       0.508022       0.115025   \n\n                                      prediction_18  prediction_19  \nid                                                                  \n16a05375-2b6f-4246-be6a-5a6b506199c8       0.589349       0.302066  \nbf4ec661-0391-42c4-9535-dc79dcdc8663       0.831241       0.743218  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_0</th>\n      <th>prediction_1</th>\n      <th>prediction_2</th>\n      <th>prediction_3</th>\n      <th>prediction_4</th>\n      <th>prediction_5</th>\n      <th>prediction_6</th>\n      <th>prediction_7</th>\n      <th>prediction_8</th>\n      <th>prediction_9</th>\n      <th>prediction_10</th>\n      <th>prediction_11</th>\n      <th>prediction_12</th>\n      <th>prediction_13</th>\n      <th>prediction_14</th>\n      <th>prediction_15</th>\n      <th>prediction_16</th>\n      <th>prediction_17</th>\n      <th>prediction_18</th>\n      <th>prediction_19</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16a05375-2b6f-4246-be6a-5a6b506199c8</th>\n      <td>0.966805</td>\n      <td>0.445274</td>\n      <td>0.113626</td>\n      <td>0.872420</td>\n      <td>0.871790</td>\n      <td>0.326325</td>\n      <td>0.354165</td>\n      <td>0.631607</td>\n      <td>0.824616</td>\n      <td>0.057961</td>\n      <td>0.970455</td>\n      <td>0.448550</td>\n      <td>0.632162</td>\n      <td>0.263125</td>\n      <td>0.869591</td>\n      <td>0.586021</td>\n      <td>0.539623</td>\n      <td>0.852208</td>\n      <td>0.589349</td>\n      <td>0.302066</td>\n    </tr>\n    <tr>\n      <th>bf4ec661-0391-42c4-9535-dc79dcdc8663</th>\n      <td>0.395945</td>\n      <td>0.115366</td>\n      <td>0.121587</td>\n      <td>0.664771</td>\n      <td>0.889804</td>\n      <td>0.200167</td>\n      <td>0.455613</td>\n      <td>0.860832</td>\n      <td>0.700849</td>\n      <td>0.979715</td>\n      <td>0.616883</td>\n      <td>0.919233</td>\n      <td>0.206422</td>\n      <td>0.168764</td>\n      <td>0.325130</td>\n      <td>0.874233</td>\n      <td>0.508022</td>\n      <td>0.115025</td>\n      <td>0.831241</td>\n      <td>0.743218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# Initialization (Random credentials)\\ntest_dir = \\\"test_sub\\\"\\nclassic_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nnum_sub = NumeraiClassicSubmittor(directory_path=test_dir, key=classic_key)\\nassert num_sub.dir.is_dir()\\n\\n# Create random dataframe\\nn_rows, n_columns = 100, 20\\ntargets = [f\\\"prediction_{i}\\\" for i in range(n_columns)]\\ntest_dataf = pd.DataFrame(np.random.uniform(size=(n_rows, n_columns)), columns=targets)\\ntest_dataf[\\\"id\\\"] = [uuid.uuid4() for _ in range(n_rows)]\\ntest_dataf = test_dataf.set_index(\\\"id\\\")\\ntest_dataf.head(2)\";\n                var nbb_formatted_code = \"# Initialization (Random credentials)\\ntest_dir = \\\"test_sub\\\"\\nclassic_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nnum_sub = NumeraiClassicSubmittor(directory_path=test_dir, key=classic_key)\\nassert num_sub.dir.is_dir()\\n\\n# Create random dataframe\\nn_rows, n_columns = 100, 20\\ntargets = [f\\\"prediction_{i}\\\" for i in range(n_columns)]\\ntest_dataf = pd.DataFrame(np.random.uniform(size=(n_rows, n_columns)), columns=targets)\\ntest_dataf[\\\"id\\\"] = [uuid.uuid4() for _ in range(n_rows)]\\ntest_dataf = test_dataf.set_index(\\\"id\\\")\\ntest_dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization (Random credentials)\n",
    "test_dir = \"test_sub\"\n",
    "classic_key = Key(pub_id=\"UFVCTElDX0lE\", secret_key=\"U1VQRVJfU0VDUkVUX0tFWQ==\")\n",
    "num_sub = NumeraiClassicSubmittor(directory_path=test_dir, key=classic_key)\n",
    "assert num_sub.dir.is_dir()\n",
    "\n",
    "# Create random dataframe\n",
    "n_rows, n_columns = 100, 20\n",
    "targets = [f\"prediction_{i}\" for i in range(n_columns)]\n",
    "test_dataf = pd.DataFrame(np.random.uniform(size=(n_rows, n_columns)), columns=targets)\n",
    "test_dataf[\"id\"] = [uuid.uuid4() for _ in range(n_rows)]\n",
    "test_dataf = test_dataf.set_index(\"id\")\n",
    "test_dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 14:17:29,672 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-02-21 14:17:29,673 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": "ðŸ“„ Saving predictions CSV to \u001B[32m'test_sub/test.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub/test.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "ðŸ“„ Saving predictions CSV to \u001B[32m'test_sub/test2.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub/test2.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                     id  prediction_0  prediction_1  \\\n0  16a05375-2b6f-4246-be6a-5a6b506199c8      0.966805      0.445274   \n1  bf4ec661-0391-42c4-9535-dc79dcdc8663      0.395945      0.115366   \n\n   prediction_2  prediction_3  prediction_4  prediction_5  prediction_6  \\\n0      0.113626      0.872420      0.871790      0.326325      0.354165   \n1      0.121587      0.664771      0.889804      0.200167      0.455613   \n\n   prediction_7  prediction_8  ...  prediction_10  prediction_11  \\\n0      0.631607      0.824616  ...       0.970455       0.448550   \n1      0.860832      0.700849  ...       0.616883       0.919233   \n\n   prediction_12  prediction_13  prediction_14  prediction_15  prediction_16  \\\n0       0.632162       0.263125       0.869591       0.586021       0.539623   \n1       0.206422       0.168764       0.325130       0.874233       0.508022   \n\n   prediction_17  prediction_18  prediction_19  \n0       0.852208       0.589349       0.302066  \n1       0.115025       0.831241       0.743218  \n\n[2 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction_0</th>\n      <th>prediction_1</th>\n      <th>prediction_2</th>\n      <th>prediction_3</th>\n      <th>prediction_4</th>\n      <th>prediction_5</th>\n      <th>prediction_6</th>\n      <th>prediction_7</th>\n      <th>prediction_8</th>\n      <th>...</th>\n      <th>prediction_10</th>\n      <th>prediction_11</th>\n      <th>prediction_12</th>\n      <th>prediction_13</th>\n      <th>prediction_14</th>\n      <th>prediction_15</th>\n      <th>prediction_16</th>\n      <th>prediction_17</th>\n      <th>prediction_18</th>\n      <th>prediction_19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16a05375-2b6f-4246-be6a-5a6b506199c8</td>\n      <td>0.966805</td>\n      <td>0.445274</td>\n      <td>0.113626</td>\n      <td>0.872420</td>\n      <td>0.871790</td>\n      <td>0.326325</td>\n      <td>0.354165</td>\n      <td>0.631607</td>\n      <td>0.824616</td>\n      <td>...</td>\n      <td>0.970455</td>\n      <td>0.448550</td>\n      <td>0.632162</td>\n      <td>0.263125</td>\n      <td>0.869591</td>\n      <td>0.586021</td>\n      <td>0.539623</td>\n      <td>0.852208</td>\n      <td>0.589349</td>\n      <td>0.302066</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bf4ec661-0391-42c4-9535-dc79dcdc8663</td>\n      <td>0.395945</td>\n      <td>0.115366</td>\n      <td>0.121587</td>\n      <td>0.664771</td>\n      <td>0.889804</td>\n      <td>0.200167</td>\n      <td>0.455613</td>\n      <td>0.860832</td>\n      <td>0.700849</td>\n      <td>...</td>\n      <td>0.616883</td>\n      <td>0.919233</td>\n      <td>0.206422</td>\n      <td>0.168764</td>\n      <td>0.325130</td>\n      <td>0.874233</td>\n      <td>0.508022</td>\n      <td>0.115025</td>\n      <td>0.831241</td>\n      <td>0.743218</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 21 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"file_name = \\\"test.csv\\\"\\nnum_sub.save_csv(dataf=test_dataf, file_name=file_name, cols=targets)\\nnum_sub.save_csv(dataf=test_dataf, file_name=\\\"test2.csv\\\", cols=targets)\\npd.read_csv(f\\\"{test_dir}/{file_name}\\\").head(2)\";\n                var nbb_formatted_code = \"file_name = \\\"test.csv\\\"\\nnum_sub.save_csv(dataf=test_dataf, file_name=file_name, cols=targets)\\nnum_sub.save_csv(dataf=test_dataf, file_name=\\\"test2.csv\\\", cols=targets)\\npd.read_csv(f\\\"{test_dir}/{file_name}\\\").head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = \"test.csv\"\n",
    "num_sub.save_csv(dataf=test_dataf, file_name=file_name, cols=targets)\n",
    "num_sub.save_csv(dataf=test_dataf, file_name=\"test2.csv\", cols=targets)\n",
    "pd.read_csv(f\"{test_dir}/{file_name}\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04c60fee18014dd49aec2c084950518c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                      prediction\nid                                              \n16a05375-2b6f-4246-be6a-5a6b506199c8      0.5690\nbf4ec661-0391-42c4-9535-dc79dcdc8663      0.5275",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16a05375-2b6f-4246-be6a-5a6b506199c8</th>\n      <td>0.5690</td>\n    </tr>\n    <tr>\n      <th>bf4ec661-0391-42c4-9535-dc79dcdc8663</th>\n      <td>0.5275</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"combined = num_sub.combine_csvs([\\\"test_sub/test.csv\\\", \\\"test_sub/test2.csv\\\"], aux_cols=['id'])\\nassert combined.columns == ['prediction']\\ncombined.head(2)\";\n                var nbb_formatted_code = \"combined = num_sub.combine_csvs(\\n    [\\\"test_sub/test.csv\\\", \\\"test_sub/test2.csv\\\"], aux_cols=[\\\"id\\\"]\\n)\\nassert combined.columns == [\\\"prediction\\\"]\\ncombined.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = num_sub.combine_csvs([\"test_sub/test.csv\", \"test_sub/test2.csv\"], aux_cols=['id'])\n",
    "assert combined.columns == ['prediction']\n",
    "combined.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"def test_signal_validity(\\n        submittor: NumeraiClassicSubmittor, dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\" Test value range of prediction. \\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(dataf)\\n        invalid_signal.iloc[0][\\\"prediction_0\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_signal.columns),\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\nassert test_signal_validity(num_sub, test_dataf)\";\n                var nbb_formatted_code = \"def test_signal_validity(submittor: NumeraiClassicSubmittor, dataf: pd.DataFrame):\\n    \\\"\\\"\\\"Test value range of prediction.\\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(dataf)\\n        invalid_signal.iloc[0][\\\"prediction_0\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_signal.columns),\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\n\\nassert test_signal_validity(num_sub, test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_signal_validity(\n",
    "        submittor: NumeraiClassicSubmittor, dataf: pd.DataFrame\n",
    "):\n",
    "    \"\"\" Test value range of prediction. \"\"\"\n",
    "    try:\n",
    "        invalid_signal = deepcopy(dataf)\n",
    "        invalid_signal.iloc[0][\"prediction_0\"] += 10\n",
    "        submittor.save_csv(\n",
    "            invalid_signal,\n",
    "            file_name=\"should_not_save.csv\",\n",
    "            cols=list(invalid_signal.columns),\n",
    "        )\n",
    "    except ValueError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "assert test_signal_validity(num_sub, test_dataf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# Uncomment to save CSV and upload predictions\\n# num_sub.full_submission(dataf=test_dataf, file_name='test.csv', cols=targets, model_name=\\\"test\\\")\";\n                var nbb_formatted_code = \"# Uncomment to save CSV and upload predictions\\n# num_sub.full_submission(dataf=test_dataf, file_name='test.csv', cols=targets, model_name=\\\"test\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment to save CSV and upload predictions\n",
    "# num_sub.full_submission(dataf=test_dataf, file_name='test.csv', cols=targets, model_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "âš  \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicSubmittor\u001B[0m\u001B[32m'\u001B[0m âš \nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âš  <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicSubmittor</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> âš \nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"# Remove contents after submitting is successful\\nnum_sub.remove_base_directory()\\nassert not os.path.exists(test_dir)\";\n                var nbb_formatted_code = \"# Remove contents after submitting is successful\\nnum_sub.remove_base_directory()\\nassert not os.path.exists(test_dir)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove contents after submitting is successful\n",
    "num_sub.remove_base_directory()\n",
    "assert not os.path.exists(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numerai Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For Numerai Signals submissions. Uses [SignalsAPI](https://numerapi.readthedocs.io/en/latest/_modules/numerapi/signalsapi.html) under the hood."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass NumeraiSignalsSubmittor(BaseSubmittor):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Signals\\n    :param directory_path: Base directory to save and read prediction files from.\\n    :param key: Key object (numerai-blocks.key.Key) containing valid credentials for Numerai Signals.\\n    *args, **kwargs will be passed to SignalsAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = SignalsAPI(\\n            public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs\\n        )\\n        super().__init__(\\n            directory_path=directory_path, api=api\\n        )\\n        self.supported_ticker_formats = [\\n            \\\"cusip\\\",\\n            \\\"sedol\\\",\\n            \\\"ticker\\\",\\n            \\\"numerai_ticker\\\",\\n            \\\"bloomberg_ticker\\\",\\n        ]\\n\\n    def save_csv(\\n        self, dataf: pd.DataFrame, file_name: str, cols: list = None, *args, **kwargs\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n         1. One of supported ticker formats (cusip, sedol, ticker, numerai_ticker or bloomberg_ticker)\\n         2. signal (Values between 0 and 1 (exclusive))\\n         Additional columns for if you include validation data (optional):\\n         3. friday_date (YYYYMMDD format date indication)\\n         4. data_type ('val' and 'live' partitions)\\n\\n         :param file_name: .csv file path.\\n         :param cols: All cols that should be passed to CSV. Defaults to 2 standard columns.\\n          ('bloomberg_ticker', 'signal')\\n        \\\"\\\"\\\"\\n        if not cols:\\n            cols = [\\\"bloomberg_ticker\\\", \\\"signal\\\"]\\n\\n        self._check_ticker_format(cols=cols)\\n        self._check_value_range(dataf=dataf, cols=\\\"signal\\\")\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving Signals predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        dataf.loc[:, cols].reset_index(drop=True).to_csv(\\n            full_path, index=False, *args, **kwargs\\n        )\\n\\n    def _check_ticker_format(self, cols: list):\\n        \\\"\\\"\\\" Check for valid ticker format. \\\"\\\"\\\"\\n        valid_tickers = set(cols).intersection(set(self.supported_ticker_formats))\\n        if not valid_tickers:\\n            raise NotImplementedError(\\n                f\\\"No supported ticker format in {cols}). \\\\\\nSupported: '{self.supported_ticker_formats}'\\\"\\n            )\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass NumeraiSignalsSubmittor(BaseSubmittor):\\n    \\\"\\\"\\\"\\n    Submit for Numerai Signals\\n    :param directory_path: Base directory to save and read prediction files from.\\n    :param key: Key object (numerai-blocks.key.Key) containing valid credentials for Numerai Signals.\\n    *args, **kwargs will be passed to SignalsAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\\n        api = SignalsAPI(\\n            public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs\\n        )\\n        super().__init__(directory_path=directory_path, api=api)\\n        self.supported_ticker_formats = [\\n            \\\"cusip\\\",\\n            \\\"sedol\\\",\\n            \\\"ticker\\\",\\n            \\\"numerai_ticker\\\",\\n            \\\"bloomberg_ticker\\\",\\n        ]\\n\\n    def save_csv(\\n        self, dataf: pd.DataFrame, file_name: str, cols: list = None, *args, **kwargs\\n    ):\\n        \\\"\\\"\\\"\\n        :param dataf: DataFrame which should have at least the following columns:\\n         1. One of supported ticker formats (cusip, sedol, ticker, numerai_ticker or bloomberg_ticker)\\n         2. signal (Values between 0 and 1 (exclusive))\\n         Additional columns for if you include validation data (optional):\\n         3. friday_date (YYYYMMDD format date indication)\\n         4. data_type ('val' and 'live' partitions)\\n\\n         :param file_name: .csv file path.\\n         :param cols: All cols that should be passed to CSV. Defaults to 2 standard columns.\\n          ('bloomberg_ticker', 'signal')\\n        \\\"\\\"\\\"\\n        if not cols:\\n            cols = [\\\"bloomberg_ticker\\\", \\\"signal\\\"]\\n\\n        self._check_ticker_format(cols=cols)\\n        self._check_value_range(dataf=dataf, cols=\\\"signal\\\")\\n\\n        full_path = str(self.dir / file_name)\\n        rich_print(\\n            f\\\":page_facing_up: Saving Signals predictions CSV to '{full_path}'. :page_facing_up:\\\"\\n        )\\n        dataf.loc[:, cols].reset_index(drop=True).to_csv(\\n            full_path, index=False, *args, **kwargs\\n        )\\n\\n    def _check_ticker_format(self, cols: list):\\n        \\\"\\\"\\\"Check for valid ticker format.\\\"\\\"\\\"\\n        valid_tickers = set(cols).intersection(set(self.supported_ticker_formats))\\n        if not valid_tickers:\\n            raise NotImplementedError(\\n                f\\\"No supported ticker format in {cols}). \\\\\\nSupported: '{self.supported_ticker_formats}'\\\"\\n            )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class NumeraiSignalsSubmittor(BaseSubmittor):\n",
    "    \"\"\"\n",
    "    Submit for Numerai Signals\n",
    "    :param directory_path: Base directory to save and read prediction files from.\n",
    "    :param key: Key object (numerai-blocks.key.Key) containing valid credentials for Numerai Signals.\n",
    "    *args, **kwargs will be passed to SignalsAPI initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, directory_path: str, key: Key, *args, **kwargs):\n",
    "        api = SignalsAPI(\n",
    "            public_id=key.pub_id, secret_key=key.secret_key, *args, **kwargs\n",
    "        )\n",
    "        super().__init__(\n",
    "            directory_path=directory_path, api=api\n",
    "        )\n",
    "        self.supported_ticker_formats = [\n",
    "            \"cusip\",\n",
    "            \"sedol\",\n",
    "            \"ticker\",\n",
    "            \"numerai_ticker\",\n",
    "            \"bloomberg_ticker\",\n",
    "        ]\n",
    "\n",
    "    def save_csv(\n",
    "        self, dataf: pd.DataFrame, file_name: str, cols: list = None, *args, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param dataf: DataFrame which should have at least the following columns:\n",
    "         1. One of supported ticker formats (cusip, sedol, ticker, numerai_ticker or bloomberg_ticker)\n",
    "         2. signal (Values between 0 and 1 (exclusive))\n",
    "         Additional columns for if you include validation data (optional):\n",
    "         3. friday_date (YYYYMMDD format date indication)\n",
    "         4. data_type ('val' and 'live' partitions)\n",
    "\n",
    "         :param file_name: .csv file path.\n",
    "         :param cols: All cols that should be passed to CSV. Defaults to 2 standard columns.\n",
    "          ('bloomberg_ticker', 'signal')\n",
    "        \"\"\"\n",
    "        if not cols:\n",
    "            cols = [\"bloomberg_ticker\", \"signal\"]\n",
    "\n",
    "        self._check_ticker_format(cols=cols)\n",
    "        self._check_value_range(dataf=dataf, cols=\"signal\")\n",
    "\n",
    "        full_path = str(self.dir / file_name)\n",
    "        rich_print(\n",
    "            f\":page_facing_up: Saving Signals predictions CSV to '{full_path}'. :page_facing_up:\"\n",
    "        )\n",
    "        dataf.loc[:, cols].reset_index(drop=True).to_csv(\n",
    "            full_path, index=False, *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def _check_ticker_format(self, cols: list):\n",
    "        \"\"\" Check for valid ticker format. \"\"\"\n",
    "        valid_tickers = set(cols).intersection(set(self.supported_ticker_formats))\n",
    "        if not valid_tickers:\n",
    "            raise NotImplementedError(\n",
    "                f\"No supported ticker format in {cols}). \\\n",
    "Supported: '{self.supported_ticker_formats}'\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumeraiSignalsSubmittor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ðŸ”‘ Numerai Auth key initialized with pub_id = \u001B[32m'UFVCTElDX0lE'\u001B[0m ðŸ”‘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”‘ Numerai Auth key initialized with pub_id = <span style=\"color: #008000; text-decoration-color: #008000\">'UFVCTElDX0lE'</span> ðŸ”‘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"# Initialization (Random credentials)\\ntest_dir_signals = \\\"test_sub_signals\\\"\\nsignals_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nsignals_sub = NumeraiSignalsSubmittor(directory_path=test_dir_signals, key=signals_key)\\nassert signals_sub.dir.is_dir()\";\n                var nbb_formatted_code = \"# Initialization (Random credentials)\\ntest_dir_signals = \\\"test_sub_signals\\\"\\nsignals_key = Key(pub_id=\\\"UFVCTElDX0lE\\\", secret_key=\\\"U1VQRVJfU0VDUkVUX0tFWQ==\\\")\\nsignals_sub = NumeraiSignalsSubmittor(directory_path=test_dir_signals, key=signals_key)\\nassert signals_sub.dir.is_dir()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization (Random credentials)\n",
    "test_dir_signals = \"test_sub_signals\"\n",
    "signals_key = Key(pub_id=\"UFVCTElDX0lE\", secret_key=\"U1VQRVJfU0VDUkVUX0tFWQ==\")\n",
    "signals_sub = NumeraiSignalsSubmittor(directory_path=test_dir_signals, key=signals_key)\n",
    "assert signals_sub.dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     signal ticker last_friday data_type\n0  0.811806   TETW    20220218      live\n1  0.526089   HHNK    20220218      live",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>signal</th>\n      <th>ticker</th>\n      <th>last_friday</th>\n      <th>data_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.811806</td>\n      <td>TETW</td>\n      <td>20220218</td>\n      <td>live</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.526089</td>\n      <td>HHNK</td>\n      <td>20220218</td>\n      <td>live</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"def create_random_signals_dataf(n_rows=5000):\\n    signals_test_dataf = pd.DataFrame(\\n        np.random.uniform(size=(n_rows, 1)), columns=[\\\"signal\\\"]\\n    )\\n    signals_test_dataf[\\\"ticker\\\"] = [\\n        \\\"\\\".join(choices(ascii_uppercase, k=4)) for _ in range(n_rows)\\n    ]\\n    last_friday = str((datetime.now() + relativedelta(weekday=FR(-1))).date()).replace(\\\"-\\\", \\\"\\\")\\n    signals_test_dataf['last_friday'] = last_friday\\n    signals_test_dataf['data_type'] = 'live'\\n    return signals_test_dataf\\n\\nsignals_test_dataf = create_random_signals_dataf()\\nsignals_test_dataf.head(2)\";\n                var nbb_formatted_code = \"def create_random_signals_dataf(n_rows=5000):\\n    signals_test_dataf = pd.DataFrame(\\n        np.random.uniform(size=(n_rows, 1)), columns=[\\\"signal\\\"]\\n    )\\n    signals_test_dataf[\\\"ticker\\\"] = [\\n        \\\"\\\".join(choices(ascii_uppercase, k=4)) for _ in range(n_rows)\\n    ]\\n    last_friday = str((datetime.now() + relativedelta(weekday=FR(-1))).date()).replace(\\n        \\\"-\\\", \\\"\\\"\\n    )\\n    signals_test_dataf[\\\"last_friday\\\"] = last_friday\\n    signals_test_dataf[\\\"data_type\\\"] = \\\"live\\\"\\n    return signals_test_dataf\\n\\n\\nsignals_test_dataf = create_random_signals_dataf()\\nsignals_test_dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_random_signals_dataf(n_rows=5000):\n",
    "    signals_test_dataf = pd.DataFrame(\n",
    "        np.random.uniform(size=(n_rows, 1)), columns=[\"signal\"]\n",
    "    )\n",
    "    signals_test_dataf[\"ticker\"] = [\n",
    "        \"\".join(choices(ascii_uppercase, k=4)) for _ in range(n_rows)\n",
    "    ]\n",
    "    last_friday = str((datetime.now() + relativedelta(weekday=FR(-1))).date()).replace(\"-\", \"\")\n",
    "    signals_test_dataf['last_friday'] = last_friday\n",
    "    signals_test_dataf['data_type'] = 'live'\n",
    "    return signals_test_dataf\n",
    "\n",
    "signals_test_dataf = create_random_signals_dataf()\n",
    "signals_test_dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ðŸ“„ Saving Signals predictions CSV to \u001B[32m'test_sub_signals/signals_test.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving Signals predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub_signals/signals_test.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "ðŸ“„ Saving Signals predictions CSV to \u001B[32m'test_sub_signals/signals_test2.csv'\u001B[0m. ðŸ“„\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“„ Saving Signals predictions CSV to <span style=\"color: #008000; text-decoration-color: #008000\">'test_sub_signals/signals_test2.csv'</span>. ðŸ“„\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     signal ticker data_type  last_friday\n0  0.811806   TETW      live     20220218\n1  0.526089   HHNK      live     20220218",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>signal</th>\n      <th>ticker</th>\n      <th>data_type</th>\n      <th>last_friday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.811806</td>\n      <td>TETW</td>\n      <td>live</td>\n      <td>20220218</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.526089</td>\n      <td>HHNK</td>\n      <td>live</td>\n      <td>20220218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"signals_cols = [\\\"signal\\\", \\\"ticker\\\", \\\"data_type\\\", \\\"last_friday\\\"]\\nfile_name = \\\"signals_test.csv\\\"\\nsignals_sub.save_csv(dataf=signals_test_dataf, file_name=file_name, cols=signals_cols)\\nsignals_sub.save_csv(dataf=signals_test_dataf, file_name=\\\"signals_test2.csv\\\", cols=signals_cols)\\npd.read_csv(f\\\"{test_dir_signals}/{file_name}\\\").head(2)\";\n                var nbb_formatted_code = \"signals_cols = [\\\"signal\\\", \\\"ticker\\\", \\\"data_type\\\", \\\"last_friday\\\"]\\nfile_name = \\\"signals_test.csv\\\"\\nsignals_sub.save_csv(dataf=signals_test_dataf, file_name=file_name, cols=signals_cols)\\nsignals_sub.save_csv(\\n    dataf=signals_test_dataf, file_name=\\\"signals_test2.csv\\\", cols=signals_cols\\n)\\npd.read_csv(f\\\"{test_dir_signals}/{file_name}\\\").head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signals_cols = [\"signal\", \"ticker\", \"data_type\", \"last_friday\"]\n",
    "file_name = \"signals_test.csv\"\n",
    "signals_sub.save_csv(dataf=signals_test_dataf, file_name=file_name, cols=signals_cols)\n",
    "signals_sub.save_csv(dataf=signals_test_dataf, file_name=\"signals_test2.csv\", cols=signals_cols)\n",
    "pd.read_csv(f\"{test_dir_signals}/{file_name}\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41a5e0a8c916498291661ce337c3aa9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                              signal\nticker last_friday data_type        \nTETW   20220218    live        0.817\nHHNK   20220218    live        0.529",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>signal</th>\n    </tr>\n    <tr>\n      <th>ticker</th>\n      <th>last_friday</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TETW</th>\n      <th>20220218</th>\n      <th>live</th>\n      <td>0.817</td>\n    </tr>\n    <tr>\n      <th>HHNK</th>\n      <th>20220218</th>\n      <th>live</th>\n      <td>0.529</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"combined_signals = signals_sub.combine_csvs(csv_paths=[\\\"test_sub_signals/signals_test.csv\\\",\\n                                               \\\"test_sub_signals/signals_test2.csv\\\"],\\n                                    aux_cols=['ticker', 'last_friday', 'data_type'],\\n                                    era_col='last_friday',\\n                                    pred_col='signal')\\nassert combined_signals.columns == ['signal']\\ncombined_signals.head(2)\";\n                var nbb_formatted_code = \"combined_signals = signals_sub.combine_csvs(\\n    csv_paths=[\\n        \\\"test_sub_signals/signals_test.csv\\\",\\n        \\\"test_sub_signals/signals_test2.csv\\\",\\n    ],\\n    aux_cols=[\\\"ticker\\\", \\\"last_friday\\\", \\\"data_type\\\"],\\n    era_col=\\\"last_friday\\\",\\n    pred_col=\\\"signal\\\",\\n)\\nassert combined_signals.columns == [\\\"signal\\\"]\\ncombined_signals.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_signals = signals_sub.combine_csvs(csv_paths=[\"test_sub_signals/signals_test.csv\",\n",
    "                                               \"test_sub_signals/signals_test2.csv\"],\n",
    "                                    aux_cols=['ticker', 'last_friday', 'data_type'],\n",
    "                                    era_col='last_friday',\n",
    "                                    pred_col='signal')\n",
    "assert combined_signals.columns == ['signal']\n",
    "combined_signals.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Signals CSV should fail if there is no valid ticker column or if `signal` has values outside the range $(0...1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"def test_signal_validity(\\n    submittor: NumeraiSignalsSubmittor, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\" Test value range of signal. \\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(signals_dataf)\\n        invalid_signal.loc[0, \\\"signal\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_signal.columns),\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\n\\ndef test_ticker_validity(\\n    submittor: NumeraiSignalsSubmittor, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\" Test safeguard if ticker column is not valid. \\\"\\\"\\\"\\n    try:\\n        invalid_ticker = deepcopy(signals_dataf)\\n        invalid_ticker = invalid_ticker.rename(\\n            {\\\"ticker\\\": \\\"not_a_valid_ticker_format\\\"}, axis=1\\n        )\\n        submittor.save_csv(\\n            invalid_ticker,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_ticker.columns),\\n        )\\n    except NotImplementedError:\\n        return True\\n    return False\\n\\nassert test_signal_validity(signals_sub, signals_test_dataf)\\nassert test_ticker_validity(signals_sub, signals_test_dataf)\";\n                var nbb_formatted_code = \"def test_signal_validity(\\n    submittor: NumeraiSignalsSubmittor, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\"Test value range of signal.\\\"\\\"\\\"\\n    try:\\n        invalid_signal = deepcopy(signals_dataf)\\n        invalid_signal.loc[0, \\\"signal\\\"] += 10\\n        submittor.save_csv(\\n            invalid_signal,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_signal.columns),\\n        )\\n    except ValueError:\\n        return True\\n    return False\\n\\n\\ndef test_ticker_validity(\\n    submittor: NumeraiSignalsSubmittor, signals_dataf: pd.DataFrame\\n):\\n    \\\"\\\"\\\"Test safeguard if ticker column is not valid.\\\"\\\"\\\"\\n    try:\\n        invalid_ticker = deepcopy(signals_dataf)\\n        invalid_ticker = invalid_ticker.rename(\\n            {\\\"ticker\\\": \\\"not_a_valid_ticker_format\\\"}, axis=1\\n        )\\n        submittor.save_csv(\\n            invalid_ticker,\\n            file_name=\\\"should_not_save.csv\\\",\\n            cols=list(invalid_ticker.columns),\\n        )\\n    except NotImplementedError:\\n        return True\\n    return False\\n\\n\\nassert test_signal_validity(signals_sub, signals_test_dataf)\\nassert test_ticker_validity(signals_sub, signals_test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_signal_validity(\n",
    "    submittor: NumeraiSignalsSubmittor, signals_dataf: pd.DataFrame\n",
    "):\n",
    "    \"\"\" Test value range of signal. \"\"\"\n",
    "    try:\n",
    "        invalid_signal = deepcopy(signals_dataf)\n",
    "        invalid_signal.loc[0, \"signal\"] += 10\n",
    "        submittor.save_csv(\n",
    "            invalid_signal,\n",
    "            file_name=\"should_not_save.csv\",\n",
    "            cols=list(invalid_signal.columns),\n",
    "        )\n",
    "    except ValueError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def test_ticker_validity(\n",
    "    submittor: NumeraiSignalsSubmittor, signals_dataf: pd.DataFrame\n",
    "):\n",
    "    \"\"\" Test safeguard if ticker column is not valid. \"\"\"\n",
    "    try:\n",
    "        invalid_ticker = deepcopy(signals_dataf)\n",
    "        invalid_ticker = invalid_ticker.rename(\n",
    "            {\"ticker\": \"not_a_valid_ticker_format\"}, axis=1\n",
    "        )\n",
    "        submittor.save_csv(\n",
    "            invalid_ticker,\n",
    "            file_name=\"should_not_save.csv\",\n",
    "            cols=list(invalid_ticker.columns),\n",
    "        )\n",
    "    except NotImplementedError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "assert test_signal_validity(signals_sub, signals_test_dataf)\n",
    "assert test_ticker_validity(signals_sub, signals_test_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"# Uncomment to save CSV and upload predictions\\n# signals_sub.full_submission(dataf=signals_test_dataf, file_name='signals_test.csv', cols=signals_cols, model_name=\\\"test\\\")\";\n                var nbb_formatted_code = \"# Uncomment to save CSV and upload predictions\\n# signals_sub.full_submission(dataf=signals_test_dataf, file_name='signals_test.csv', cols=signals_cols, model_name=\\\"test\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment to save CSV and upload predictions\n",
    "# signals_sub.full_submission(dataf=signals_test_dataf, file_name='signals_test.csv', cols=signals_cols, model_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "âš  \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiSignalsSubmittor\u001B[0m\u001B[32m'\u001B[0m âš \nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub_signals'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âš  <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiSignalsSubmittor</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> âš \nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_sub_signals'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"# Remove contents after submission is successful\\nsignals_sub.remove_base_directory()\\nassert not os.path.exists(test_dir_signals)\";\n                var nbb_formatted_code = \"# Remove contents after submission is successful\\nsignals_sub.remove_base_directory()\\nassert not os.path.exists(test_dir_signals)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove contents after submission is successful\n",
    "signals_sub.remove_base_directory()\n",
    "assert not os.path.exists(test_dir_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_misc.ipynb.\n",
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}