{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Feature/target selection, engineering and manipulation.\n",
    "output-file: preprocessing.html\n",
    "title: Preprocessing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 13:34:46.431000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 13:34:46.608470: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 13:34:47.391402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 13:34:47.391545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 13:34:47.391559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from umap import UMAP\n",
    "from tqdm.auto import tqdm\n",
    "from functools import wraps\n",
    "from scipy.stats import rankdata\n",
    "from typeguard import typechecked\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "from typing import Union, Tuple\n",
    "from multiprocessing.pool import Pool\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "\n",
    "from numerblox.numerframe import NumerFrame, create_numerframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These objects will provide a base for all pre- and post-processing functionality and log relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. BaseProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BaseProcessor` defines common functionality for `preprocessing` and `postprocessing` (Section 5).\n",
    "\n",
    "Every Preprocessor should inherit from `BaseProcessor` and implement the `.transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseProcessor(ABC):\n",
    "    \"\"\"Common functionality for preprocessors and postprocessors.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        ...\n",
    "\n",
    "    def __call__(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        return self.transform(dataf=dataf, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to keep an overview of which steps are done in a data pipeline and where processing bottlenecks occur.\n",
    "The decorator below will display for a given function/method:\n",
    "1. When it has finished.\n",
    "2. What the output shape of the data is.\n",
    "3. How long it took to finish.\n",
    "\n",
    "To use this functionality, simply add `@display_processor_info` as a decorator to the function/method you want to track.\n",
    "\n",
    "We will use this decorator throughout the pipeline (`preprocessing`, `model` and `postprocessing`).\n",
    "\n",
    "Inspiration for this decorator: [Calmcode Pandas Pipe Logs](https://calmcode.io/pandas-pipe/logs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def display_processor_info(func):\n",
    "    \"\"\"Fancy console output for data processing.\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tic = dt.datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "        time_taken = str(dt.datetime.now() - tic)\n",
    "        class_name = func.__qualname__.split(\".\")[0]\n",
    "        rich_print(\n",
    "            f\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\"\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TestDisplay</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1073</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:02</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">002079</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mTestDisplay\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1073\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:02\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m002079\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>feature_demisable_expiring_millepede</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0297</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.166667</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0003</td>\n      <td>train</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>nb64f06d3a9fc9f1</th>\n      <td>0472</td>\n      <td>train</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>n1927b4862500882</th>\n      <td>0265</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>nc3234b6eeacd6b7</th>\n      <td>0299</td>\n      <td>train</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.166667</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>n1b41d583e12f051</th>\n      <td>0009</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>n116898cdc07d4e2</th>\n      <td>0013</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>nb0a7aef640025dc</th>\n      <td>0232</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.500000</td>\n      <td>0.166667</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>n12466a161ab0a24</th>\n      <td>0092</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>n40132f4765f9185</th>\n      <td>0270</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 1073 columns</p>\n</div>",
      "text/plain": "                   era data_type  feature_dichasial_hammier_spawner  \\\nid                                                                    \nn559bd06a8861222  0297     train                               0.25   \nn9d39dea58c9e3cf  0003     train                               0.75   \nnb64f06d3a9fc9f1  0472     train                               1.00   \nn1927b4862500882  0265     train                               0.00   \nnc3234b6eeacd6b7  0299     train                               0.75   \nn1b41d583e12f051  0009     train                               0.00   \nn116898cdc07d4e2  0013     train                               0.50   \nnb0a7aef640025dc  0232     train                               0.25   \nn12466a161ab0a24  0092     train                               0.50   \nn40132f4765f9185  0270     train                               0.50   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \nnb64f06d3a9fc9f1                              1.00   \nn1927b4862500882                              0.00   \nnc3234b6eeacd6b7                              0.25   \nn1b41d583e12f051                              0.50   \nn116898cdc07d4e2                              1.00   \nnb0a7aef640025dc                              0.25   \nn12466a161ab0a24                              0.75   \nn40132f4765f9185                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \nnb64f06d3a9fc9f1                              1.00   \nn1927b4862500882                              0.25   \nnc3234b6eeacd6b7                              0.00   \nn1b41d583e12f051                              0.50   \nn116898cdc07d4e2                              1.00   \nnb0a7aef640025dc                              0.50   \nn12466a161ab0a24                              1.00   \nn40132f4765f9185                              0.00   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \nnb64f06d3a9fc9f1                                  0.50   \nn1927b4862500882                                  0.00   \nnc3234b6eeacd6b7                                  0.75   \nn1b41d583e12f051                                  0.25   \nn116898cdc07d4e2                                  0.75   \nnb0a7aef640025dc                                  0.00   \nn12466a161ab0a24                                  0.50   \nn40132f4765f9185                                  0.50   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \nnb64f06d3a9fc9f1                                  0.00   \nn1927b4862500882                                  1.00   \nnc3234b6eeacd6b7                                  1.00   \nn1b41d583e12f051                                  0.25   \nn116898cdc07d4e2                                  0.00   \nnb0a7aef640025dc                                  1.00   \nn12466a161ab0a24                                  0.25   \nn40132f4765f9185                                  0.75   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \nnb64f06d3a9fc9f1                                1.00   \nn1927b4862500882                                0.00   \nnc3234b6eeacd6b7                                0.25   \nn1b41d583e12f051                                0.50   \nn116898cdc07d4e2                                1.00   \nnb0a7aef640025dc                                0.00   \nn12466a161ab0a24                                0.25   \nn40132f4765f9185                                0.50   \n\n                  feature_koranic_rude_corf  \\\nid                                            \nn559bd06a8861222                       1.00   \nn9d39dea58c9e3cf                       0.50   \nnb64f06d3a9fc9f1                       0.25   \nn1927b4862500882                       0.00   \nnc3234b6eeacd6b7                       0.00   \nn1b41d583e12f051                       0.50   \nn116898cdc07d4e2                       0.50   \nnb0a7aef640025dc                       0.50   \nn12466a161ab0a24                       0.25   \nn40132f4765f9185                       0.00   \n\n                  feature_demisable_expiring_millepede  ...  target_paul_20  \\\nid                                                      ...                   \nn559bd06a8861222                                  0.25  ...            0.00   \nn9d39dea58c9e3cf                                  0.00  ...            0.50   \nnb64f06d3a9fc9f1                                  0.50  ...            0.00   \nn1927b4862500882                                  0.00  ...            0.75   \nnc3234b6eeacd6b7                                  0.00  ...            0.25   \nn1b41d583e12f051                                  1.00  ...            0.50   \nn116898cdc07d4e2                                  0.75  ...            0.50   \nnb0a7aef640025dc                                  0.00  ...            0.50   \nn12466a161ab0a24                                  0.75  ...            0.50   \nn40132f4765f9185                                  0.25  ...            0.25   \n\n                  target_paul_60  target_george_20  target_george_60  \\\nid                                                                     \nn559bd06a8861222            0.50              0.25              0.50   \nn9d39dea58c9e3cf            0.75              0.50              0.50   \nnb64f06d3a9fc9f1            0.25              0.50              0.50   \nn1927b4862500882            0.75              0.50              0.75   \nnc3234b6eeacd6b7            0.50              0.50              0.50   \nn1b41d583e12f051            0.25              0.50              0.00   \nn116898cdc07d4e2            0.75              0.50              0.50   \nnb0a7aef640025dc            0.25              0.50              0.00   \nn12466a161ab0a24            0.50              0.50              0.50   \nn40132f4765f9185            0.50              0.00              0.50   \n\n                  target_william_20  target_william_60  target_arthur_20  \\\nid                                                                         \nn559bd06a8861222           0.000000           0.500000          0.166667   \nn9d39dea58c9e3cf           0.666667           0.666667          0.500000   \nnb64f06d3a9fc9f1           0.333333           0.333333          0.333333   \nn1927b4862500882           0.833333           0.833333          0.666667   \nnc3234b6eeacd6b7           0.166667           0.666667          0.333333   \nn1b41d583e12f051           0.500000           0.333333          0.500000   \nn116898cdc07d4e2           0.500000           0.666667          0.500000   \nnb0a7aef640025dc           0.500000           0.166667          0.500000   \nn12466a161ab0a24           0.500000           0.500000          0.500000   \nn40132f4765f9185           0.333333           0.333333          0.333333   \n\n                  target_arthur_60  target_thomas_20  target_thomas_60  \nid                                                                      \nn559bd06a8861222          0.500000          0.333333          0.500000  \nn9d39dea58c9e3cf          0.666667          0.500000          0.666667  \nnb64f06d3a9fc9f1          0.333333          0.333333          0.333333  \nn1927b4862500882          0.833333          0.666667          0.666667  \nnc3234b6eeacd6b7          0.500000          0.500000          0.666667  \nn1b41d583e12f051          0.333333          0.500000          0.333333  \nn116898cdc07d4e2          0.666667          0.500000          0.666667  \nnb0a7aef640025dc          0.000000          0.666667          0.166667  \nn12466a161ab0a24          0.500000          0.500000          0.500000  \nn40132f4765f9185          0.333333          0.333333          0.500000  \n\n[10 rows x 1073 columns]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "class TestDisplay:\n",
    "    \"\"\"\n",
    "    Small test for logging.\n",
    "    Output should mention 'TestDisplay',\n",
    "    Return output shape of (10, 314) and\n",
    "    time taken for step should be close to 2 seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataf: NumerFrame):\n",
    "        self.dataf = dataf\n",
    "\n",
    "    @display_processor_info\n",
    "    def test(self) -> NumerFrame:\n",
    "        time.sleep(2)\n",
    "        return self.dataf\n",
    "\n",
    "\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "TestDisplay(dataf).test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common preprocessing steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section implements commonly used preprocessing for Numerai. We invite the Numerai community to develop new preprocessors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Tournament agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessors that can be applied for both Numerai Classic and Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.1. CopyPreProcessor\n",
    "\n",
    "The first and obvious preprocessor is copying, which is implemented as a default in `ModelPipeline` (Section 4) to avoid manipulation of the original DataFrame or `NumerFrame` that you load in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class CopyPreProcessor(BaseProcessor):\n",
    "    \"\"\"Copy DataFrame to avoid manipulation of original DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        return NumerFrame(dataf.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">CopyPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">002131</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mCopyPreProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m314\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m002131\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_1_data.csv\", metadata={\"version\": 1}\n",
    ")\n",
    "copied_dataset = CopyPreProcessor().transform(dataset)\n",
    "assert np.array_equal(copied_dataset.values, dataset.values)\n",
    "assert dataset.meta == copied_dataset.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.2. FeatureSelectionPreProcessor\n",
    "\n",
    "`FeatureSelectionPreProcessor` will keep all features that you pass + keeps all other columns that are not features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class FeatureSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_cols: Union[str, list]):\n",
    "        super().__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        keep_cols = (\n",
    "            self.feature_cols\n",
    "            + dataf.target_cols\n",
    "            + dataf.prediction_cols\n",
    "            + dataf.aux_cols\n",
    "        )\n",
    "        dataf = dataf.loc[:, keep_cols]\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">001287</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mFeatureSelectionPreProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m001287\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset = FeatureSelectionPreProcessor(\n",
    "    feature_cols=[\"feature_wisdom1\"]\n",
    ").transform(dataset)\n",
    "\n",
    "assert selected_dataset.get_feature_data.shape[1] == 1\n",
    "assert dataset.meta == selected_dataset.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_wisdom1</th>\n      <th>target</th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   feature_wisdom1  target                id   era data_type\n0             0.25    0.50  n000315175b67977  era1     train\n1             0.50    0.25  n0014af834a96cdd  era1     train"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.3. TargetSelectionPreProcessor\n",
    "\n",
    "`TargetSelectionPreProcessor` will keep all targets that you pass + all other columns that are not targets.\n",
    "\n",
    "Not relevant for an inference pipeline, but especially convenient for Numerai Classic training if you train on a subset of the available targets. Can also be applied to Signals if you are using engineered targets in your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class TargetSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_cols: Union[str, list]):\n",
    "        super().__init__()\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        keep_cols = (\n",
    "            self.target_cols\n",
    "            + dataf.feature_cols\n",
    "            + dataf.prediction_cols\n",
    "            + dataf.aux_cols\n",
    "        )\n",
    "        dataf = dataf.loc[:, keep_cols]\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TargetSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1055</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">019160</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mTargetSelectionPreProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1055\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m019160\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>target_nomi_20</th>\n      <th>target_nomi_60</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>...</th>\n      <th>feature_drawable_exhortative_dispersant</th>\n      <th>feature_metabolic_minded_armorist</th>\n      <th>feature_investigatory_inerasable_circumvallation</th>\n      <th>feature_centroclinal_incentive_lancelet</th>\n      <th>feature_unemotional_quietistic_chirper</th>\n      <th>feature_behaviorist_microbiological_farina</th>\n      <th>feature_lofty_acceptable_challenge</th>\n      <th>feature_coactive_prefatorial_lucy</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0297</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0003</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1055 columns</p>\n</div>",
      "text/plain": "                  target  target_nomi_20  target_nomi_60  \\\nid                                                         \nn559bd06a8861222    0.25            0.25            0.50   \nn9d39dea58c9e3cf    0.50            0.50            0.75   \n\n                  feature_dichasial_hammier_spawner  \\\nid                                                    \nn559bd06a8861222                               0.25   \nn9d39dea58c9e3cf                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  ...  \\\nid                                           ...   \nn559bd06a8861222                        1.0  ...   \nn9d39dea58c9e3cf                        0.5  ...   \n\n                  feature_drawable_exhortative_dispersant  \\\nid                                                          \nn559bd06a8861222                                     1.00   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_metabolic_minded_armorist  \\\nid                                                    \nn559bd06a8861222                                0.0   \nn9d39dea58c9e3cf                                0.5   \n\n                  feature_investigatory_inerasable_circumvallation  \\\nid                                                                   \nn559bd06a8861222                                               0.0   \nn9d39dea58c9e3cf                                               0.0   \n\n                  feature_centroclinal_incentive_lancelet  \\\nid                                                          \nn559bd06a8861222                                     0.25   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_unemotional_quietistic_chirper  \\\nid                                                         \nn559bd06a8861222                                    0.00   \nn9d39dea58c9e3cf                                    0.75   \n\n                  feature_behaviorist_microbiological_farina  \\\nid                                                             \nn559bd06a8861222                                         0.0   \nn9d39dea58c9e3cf                                         1.0   \n\n                  feature_lofty_acceptable_challenge  \\\nid                                                     \nn559bd06a8861222                                1.00   \nn9d39dea58c9e3cf                                0.75   \n\n                  feature_coactive_prefatorial_lucy   era  data_type  \nid                                                                    \nn559bd06a8861222                               0.25  0297      train  \nn9d39dea58c9e3cf                               1.00  0003      train  \n\n[2 rows x 1055 columns]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_2_data.parquet\", metadata={\"version\": 2}\n",
    ")\n",
    "target_cols = [\"target\", \"target_nomi_20\", \"target_nomi_60\"]\n",
    "selected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\n",
    "    dataset\n",
    ")\n",
    "assert selected_dataset.get_target_data.shape[1] == len(target_cols)\n",
    "selected_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.4. ReduceMemoryProcessor\n",
    "\n",
    "Numerai datasets can take up a lot of RAM and may put a strain on your compute environment.\n",
    "\n",
    "For Numerai Classic, many of the feature and target columns can be downscaled to `float16`. `int8` if you are using the Numerai int8 datasets. For Signals it depends on the features you are generating.\n",
    "\n",
    "`ReduceMemoryProcessor` downscales the type of your numeric columns to reduce the memory footprint as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReduceMemoryProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Reduce memory usage as much as possible.\n",
    "\n",
    "    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\n",
    "    https://forum.numer.ai/t/reducing-memory/313\n",
    "\n",
    "    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\n",
    "    Yields a more accurate representation of memory usage if you have complex object columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, deep_mem_inspect=False):\n",
    "        super().__init__()\n",
    "        self.deep_mem_inspect = deep_mem_inspect\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf = self._reduce_mem_usage(dataf)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Iterate through all columns and modify the numeric column types\n",
    "        to reduce memory usage.\n",
    "        \"\"\"\n",
    "        start_memory_usage = (\n",
    "            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\"\n",
    "        )\n",
    "\n",
    "        for col in dataf.columns:\n",
    "            col_type = dataf[col].dtype.name\n",
    "\n",
    "            if col_type not in [\n",
    "                \"object\",\n",
    "                \"category\",\n",
    "                \"datetime64[ns, UTC]\",\n",
    "                \"datetime64[ns]\",\n",
    "            ]:\n",
    "                c_min = dataf[col].min()\n",
    "                c_max = dataf[col].max()\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        dataf[col] = dataf[col].astype(np.int16)\n",
    "                    elif (\n",
    "                        c_min > np.iinfo(np.int16).min\n",
    "                        and c_max < np.iinfo(np.int16).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.int16)\n",
    "                    elif (\n",
    "                        c_min > np.iinfo(np.int32).min\n",
    "                        and c_max < np.iinfo(np.int32).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.int32)\n",
    "                    elif (\n",
    "                        c_min > np.iinfo(np.int64).min\n",
    "                        and c_max < np.iinfo(np.int64).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.int64)\n",
    "                else:\n",
    "                    if (\n",
    "                        c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.float16)\n",
    "                    elif (\n",
    "                        c_min > np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.float32)\n",
    "                    else:\n",
    "                        dataf[col] = dataf[col].astype(np.float64)\n",
    "\n",
    "        end_memory_usage = (\n",
    "            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\"\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\"\n",
    "        )\n",
    "        return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory usage of DataFrame is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04</span><span style=\"font-weight: bold\"> MB</span>\n</pre>\n",
      "text/plain": "Memory usage of DataFrame is \u001b[1;36m0.04\u001b[0m\u001b[1m MB\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory usage after optimization is: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span><span style=\"font-weight: bold\"> MB</span>\n</pre>\n",
      "text/plain": "Memory usage after optimization is: \u001b[1;36m0.02\u001b[0m\u001b[1m MB\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Usage decreased by </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">49.72</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">%</span>\n</pre>\n",
      "text/plain": "\u001b[32m Usage decreased by \u001b[0m\u001b[1;32m49.72\u001b[0m\u001b[1;32m%\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">ReduceMemoryProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1073</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">928589</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mReduceMemoryProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m1073\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m928589\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "rmp = ReduceMemoryProcessor()\n",
    "dataf = rmp.transform(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>feature_demisable_expiring_millepede</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0297</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.166626</td>\n      <td>0.500000</td>\n      <td>0.333252</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0003</td>\n      <td>train</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.666504</td>\n      <td>0.666504</td>\n      <td>0.500000</td>\n      <td>0.666504</td>\n      <td>0.500000</td>\n      <td>0.666504</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1073 columns</p>\n</div>",
      "text/plain": "                   era data_type  feature_dichasial_hammier_spawner  \\\nid                                                                    \nn559bd06a8861222  0297     train                               0.25   \nn9d39dea58c9e3cf  0003     train                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  \\\nid                                            \nn559bd06a8861222                        1.0   \nn9d39dea58c9e3cf                        0.5   \n\n                  feature_demisable_expiring_millepede  ...  target_paul_20  \\\nid                                                      ...                   \nn559bd06a8861222                                  0.25  ...             0.0   \nn9d39dea58c9e3cf                                  0.00  ...             0.5   \n\n                  target_paul_60  target_george_20  target_george_60  \\\nid                                                                     \nn559bd06a8861222            0.50              0.25               0.5   \nn9d39dea58c9e3cf            0.75              0.50               0.5   \n\n                  target_william_20  target_william_60  target_arthur_20  \\\nid                                                                         \nn559bd06a8861222           0.000000           0.500000          0.166626   \nn9d39dea58c9e3cf           0.666504           0.666504          0.500000   \n\n                  target_arthur_60  target_thomas_20  target_thomas_60  \nid                                                                      \nn559bd06a8861222          0.500000          0.333252          0.500000  \nn9d39dea58c9e3cf          0.666504          0.500000          0.666504  \n\n[2 rows x 1073 columns]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| include: false\n",
    "dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.6. UMAPFeatureGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform Manifold Approximation and Projection (UMAP) is a dimensionality reduction technique that we can utilize to generate new Numerai features. This processor uses [umap-learn](https://pypi.org/project/umap-learn) under the hood to model the manifold. The dimension of the input data will be reduced to `n_components` number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UMAPFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate new Numerai features using UMAP. Uses umap-learn under the hood: \\n\n",
    "    https://pypi.org/project/umap-learn/\n",
    "    :param n_components: How many new features to generate.\n",
    "    :param n_neighbors: Number of neighboring points used in local approximations of manifold structure.\n",
    "    :param min_dist: How tightly the embedding is allows to compress points together.\n",
    "    :param metric: Metric to measure distance in input space. Correlation by default.\n",
    "    :param feature_names: Selection of features used to perform UMAP on. All features by default.\n",
    "    *args, **kwargs will be passed to initialization of UMAP.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components: int = 5,\n",
    "        n_neighbors: int = 15,\n",
    "        min_dist: float = 0.0,\n",
    "        metric: str = \"correlation\",\n",
    "        feature_names: list = None,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.min_dist = min_dist\n",
    "        self.feature_names = feature_names\n",
    "        self.metric = metric\n",
    "        self.umap = UMAP(\n",
    "            n_components=self.n_components,\n",
    "            n_neighbors=self.n_neighbors,\n",
    "            min_dist=self.min_dist,\n",
    "            metric=self.metric,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        new_feature_data = self.umap.fit_transform(dataf[feature_names])\n",
    "        umap_feature_names = [f\"feature_umap_{i}\" for i in range(self.n_components)]\n",
    "        norm_new_feature_data = MinMaxScaler().fit_transform(new_feature_data)\n",
    "        dataf.loc[:, umap_feature_names] = norm_new_feature_data\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "umap_gen = UMAPFeatureGenerator(n_components=n_components, n_neighbors=9)\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "dataf = umap_gen(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new features will be names with the convention `f\"feature_umap_{i}\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_umap_0</th>\n      <th>feature_umap_1</th>\n      <th>feature_umap_2</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.851613</td>\n      <td>0.586444</td>\n      <td>0.101424</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.521932</td>\n      <td>1.000000</td>\n      <td>0.153269</td>\n    </tr>\n    <tr>\n      <th>nb64f06d3a9fc9f1</th>\n      <td>0.916870</td>\n      <td>0.297071</td>\n      <td>0.733413</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  feature_umap_0  feature_umap_1  feature_umap_2\nid                                                              \nn559bd06a8861222        0.851613        0.586444        0.101424\nn9d39dea58c9e3cf        0.521932        1.000000        0.153269\nnb64f06d3a9fc9f1        0.916870        0.297071        0.733413"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_features = [f\"feature_umap_{i}\" for i in range(n_components)]\n",
    "dataf[umap_features].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Numerai Classic dataset has a certain structure that you may not encounter in the Numerai Signals tournament.\n",
    "Therefore, this section has all preprocessors that can only be applied to Numerai Classic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 Numerai Classic: Version agnostic\n",
    "\n",
    "Preprocessors that work for all Numerai Classic versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.0.1. BayesianGMMTargetProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BayesianGMMTargetProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\n\n",
    "    Based on Michael Oliver's GitHub Gist implementation: \\n\n",
    "    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\n",
    "\n",
    "    :param target_col: Column from which to create fake target. \\n\n",
    "    :param feature_names: Selection of features used for Bayesian GMM. All features by default.\n",
    "    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_col: str = \"target\",\n",
    "        feature_names: list = None,\n",
    "        n_components: int = 6,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target_col = target_col\n",
    "        self.feature_names = feature_names\n",
    "        self.n_components = n_components\n",
    "        self.ridge = Ridge(fit_intercept=False)\n",
    "        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        all_eras = dataf[dataf.meta.era_col].unique()\n",
    "        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\n",
    "        bgmm = self._fit_bgmm(coefs=coefs)\n",
    "        fake_target = self._generate_target(dataf=dataf, bgmm=bgmm, all_eras=all_eras)\n",
    "        dataf[f\"{self.target_col}_fake\"] = fake_target\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate coefficients for BGMM.\n",
    "        Data should already be scaled between 0 and 1\n",
    "        (Already done with Numerai Classic data)\n",
    "        \"\"\"\n",
    "        coefs = []\n",
    "        for era in all_eras:\n",
    "            features, target = self.__get_features_target(dataf=dataf, era=era)\n",
    "            self.ridge.fit(features, target)\n",
    "            coefs.append(self.ridge.coef_)\n",
    "        stacked_coefs = np.vstack(coefs)\n",
    "        return stacked_coefs\n",
    "\n",
    "    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\n",
    "        \"\"\"\n",
    "        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\n",
    "        \"\"\"\n",
    "        bgmm = BayesianGaussianMixture(n_components=self.n_components)\n",
    "        bgmm.fit(coefs)\n",
    "        # make probability of sampling each component equal to better balance rare regimes\n",
    "        bgmm.weights_[:] = 1 / self.n_components\n",
    "        return bgmm\n",
    "\n",
    "    def _generate_target(\n",
    "        self, dataf: NumerFrame, bgmm: BayesianGaussianMixture, all_eras: list\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Generate fake target using Bayesian Gaussian Mixture model.\"\"\"\n",
    "        fake_target = []\n",
    "        for era in tqdm(all_eras, desc=\"Generating fake target\"):\n",
    "            features, _ = self.__get_features_target(dataf=dataf, era=era)\n",
    "            # Sample a set of weights from GMM\n",
    "            beta, _ = bgmm.sample(1)\n",
    "            # Create fake continuous target\n",
    "            fake_targ = features @ beta[0]\n",
    "            # Bin fake target like real target\n",
    "            fake_targ = (rankdata(fake_targ) - 0.5) / len(fake_targ)\n",
    "            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\n",
    "            fake_target.append(fake_targ)\n",
    "        return np.concatenate(fake_target)\n",
    "\n",
    "    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\n",
    "        \"\"\"Get features and target for one era and center data.\"\"\"\n",
    "        sub_df = dataf[dataf[dataf.meta.era_col] == era]\n",
    "        features = self.feature_names if self.feature_names else sub_df.feature_cols\n",
    "        target = sub_df[self.target_col].values - 0.5\n",
    "        features = sub_df[features].values - 0.5\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Numerai Classic: Version 1 specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessors that only work for version 1 (legacy data). When using version 1 preprocessor it is recommended that the input NumerFrame has version in its metadata. This avoids using version 1 preprocessors on version 2 data and encountering confusing error messages.\n",
    "\n",
    "As a new user we recommend to start modeling the version 2 data and avoid version 1. The preprocessors below are only there for legacy and compatibility reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.1. GroupStatsPreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version 1 legacy data has 6 groups of features which allows us to calculate aggregate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GroupStatsPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    WARNING: Only supported for Version 1 (legacy) data. \\n\n",
    "    Calculate group statistics for all data groups. \\n\n",
    "    | :param groups: Groups to create features for. All groups by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, groups: list = None):\n",
    "        super().__init__()\n",
    "        self.all_groups = [\n",
    "            \"intelligence\",\n",
    "            \"wisdom\",\n",
    "            \"charisma\",\n",
    "            \"dexterity\",\n",
    "            \"strength\",\n",
    "            \"constitution\",\n",
    "        ]\n",
    "        self.group_names = groups if groups else self.all_groups\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        \"\"\"Check validity and add group features.\"\"\"\n",
    "        dataf = dataf.pipe(self._add_group_features)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Mean, standard deviation and skew for each group.\"\"\"\n",
    "        for group in self.group_names:\n",
    "            cols = [col for col in dataf.columns if group in col]\n",
    "            dataf[f\"feature_{group}_mean\"] = dataf[cols].mean(axis=1)\n",
    "            dataf[f\"feature_{group}_std\"] = dataf[cols].std(axis=1)\n",
    "            dataf[f\"feature_{group}_skew\"] = dataf[cols].skew(axis=1)\n",
    "        return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">033687</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mGroupStatsPreProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m332\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m033687\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_1_data.csv\"\n",
    ")\n",
    "group_features_dataf = GroupStatsPreProcessor().transform(dataf)\n",
    "group_features_dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_intelligence_mean</th>\n      <th>feature_intelligence_std</th>\n      <th>feature_intelligence_skew</th>\n      <th>feature_wisdom_mean</th>\n      <th>feature_wisdom_std</th>\n      <th>feature_wisdom_skew</th>\n      <th>feature_charisma_mean</th>\n      <th>feature_charisma_std</th>\n      <th>feature_charisma_skew</th>\n      <th>feature_dexterity_mean</th>\n      <th>feature_dexterity_std</th>\n      <th>feature_dexterity_skew</th>\n      <th>feature_strength_mean</th>\n      <th>feature_strength_std</th>\n      <th>feature_strength_skew</th>\n      <th>feature_constitution_mean</th>\n      <th>feature_constitution_std</th>\n      <th>feature_constitution_skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>0.246183</td>\n      <td>0.558528</td>\n      <td>0.668478</td>\n      <td>0.236022</td>\n      <td>-0.115082</td>\n      <td>0.438953</td>\n      <td>0.259910</td>\n      <td>-0.004783</td>\n      <td>0.696429</td>\n      <td>0.200446</td>\n      <td>-0.607620</td>\n      <td>0.480263</td>\n      <td>0.292829</td>\n      <td>-0.372064</td>\n      <td>0.427632</td>\n      <td>0.27572</td>\n      <td>0.276155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.208333</td>\n      <td>0.234359</td>\n      <td>0.382554</td>\n      <td>0.559783</td>\n      <td>0.358177</td>\n      <td>-0.062362</td>\n      <td>0.485465</td>\n      <td>0.252501</td>\n      <td>-0.021737</td>\n      <td>0.267857</td>\n      <td>0.249312</td>\n      <td>0.382267</td>\n      <td>0.407895</td>\n      <td>0.309866</td>\n      <td>0.220625</td>\n      <td>0.644737</td>\n      <td>0.33408</td>\n      <td>-0.794938</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   feature_intelligence_mean  feature_intelligence_std  \\\n0                   0.333333                  0.246183   \n1                   0.208333                  0.234359   \n\n   feature_intelligence_skew  feature_wisdom_mean  feature_wisdom_std  \\\n0                   0.558528             0.668478            0.236022   \n1                   0.382554             0.559783            0.358177   \n\n   feature_wisdom_skew  feature_charisma_mean  feature_charisma_std  \\\n0            -0.115082               0.438953              0.259910   \n1            -0.062362               0.485465              0.252501   \n\n   feature_charisma_skew  feature_dexterity_mean  feature_dexterity_std  \\\n0              -0.004783                0.696429               0.200446   \n1              -0.021737                0.267857               0.249312   \n\n   feature_dexterity_skew  feature_strength_mean  feature_strength_std  \\\n0               -0.607620               0.480263              0.292829   \n1                0.382267               0.407895              0.309866   \n\n   feature_strength_skew  feature_constitution_mean  feature_constitution_std  \\\n0              -0.372064                   0.427632                   0.27572   \n1               0.220625                   0.644737                   0.33408   \n\n   feature_constitution_skew  \n0                   0.276155  \n1                  -0.794938  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| include: false\n",
    "new_cols = [\n",
    "    \"feature_intelligence_mean\",\n",
    "    \"feature_intelligence_std\",\n",
    "    \"feature_intelligence_skew\",\n",
    "    \"feature_wisdom_mean\",\n",
    "    \"feature_wisdom_std\",\n",
    "    \"feature_wisdom_skew\",\n",
    "    \"feature_charisma_mean\",\n",
    "    \"feature_charisma_std\",\n",
    "    \"feature_charisma_skew\",\n",
    "    \"feature_dexterity_mean\",\n",
    "    \"feature_dexterity_std\",\n",
    "    \"feature_dexterity_skew\",\n",
    "    \"feature_strength_mean\",\n",
    "    \"feature_strength_std\",\n",
    "    \"feature_strength_skew\",\n",
    "    \"feature_constitution_mean\",\n",
    "    \"feature_constitution_std\",\n",
    "    \"feature_constitution_skew\",\n",
    "]\n",
    "assert set(group_features_dataf.columns).intersection(new_cols)\n",
    "group_features_dataf.get_feature_data[new_cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Numerai Signals\n",
    "\n",
    "Preprocessors that are specific to Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. KatsuFeatureGenerator\n",
    "\n",
    "[Katsu1110](https://www.kaggle.com/code1110) provides an excellent and fast feature engineering scheme in his [Kaggle notebook on starting with Numerai Signals](https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners). It is surprisingly effective, fast and works well for modeling. This preprocessor is based on his feature engineering setup in that notebook.\n",
    "\n",
    "Features generated:\n",
    "1. MACD and MACD signal\n",
    "2. RSI\n",
    "3. Percentage rate of return\n",
    "4. Volatility\n",
    "5. MA (moving average) gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class KatsuFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Effective feature engineering setup based on Katsu's starter notebook.\n",
    "    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\n",
    "\n",
    "    :param windows: Time interval to apply for window features: \\n\n",
    "    1. Percentage Rate of change \\n\n",
    "    2. Volatility \\n\n",
    "    3. Moving Average gap \\n\n",
    "    :param ticker_col: Columns with tickers to iterate over. \\n\n",
    "    :param close_col: Column name where you have closing price stored.\n",
    "    \"\"\"\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list,\n",
    "        ticker_col: str = \"ticker\",\n",
    "        close_col: str = \"close\",\n",
    "        num_cores: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows\n",
    "        self.ticker_col = ticker_col\n",
    "        self.close_col = close_col\n",
    "        self.num_cores = num_cores if num_cores else os.cpu_count()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        \"\"\"Multiprocessing feature engineering.\"\"\"\n",
    "        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\n",
    "        rich_print(\n",
    "            f\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\"\n",
    "        )\n",
    "        dataf_list = [\n",
    "            x\n",
    "            for _, x in tqdm(\n",
    "                dataf.groupby(self.ticker_col), desc=\"Generating ticker DataFrames\"\n",
    "            )\n",
    "        ]\n",
    "        dataf = self._generate_features(dataf_list=dataf_list)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Feature engineering for single ticker.\"\"\"\n",
    "        close_series = dataf.loc[:, self.close_col]\n",
    "        for x in self.windows:\n",
    "            dataf.loc[\n",
    "                :, f\"feature_{self.close_col}_ROCP_{x}\"\n",
    "            ] = close_series.pct_change(x)\n",
    "\n",
    "            dataf.loc[:, f\"feature_{self.close_col}_VOL_{x}\"] = (\n",
    "                np.log1p(close_series).pct_change().rolling(x).std()\n",
    "            )\n",
    "\n",
    "            dataf.loc[:, f\"feature_{self.close_col}_MA_gap_{x}\"] = (\n",
    "                close_series / close_series.rolling(x).mean()\n",
    "            )\n",
    "\n",
    "        dataf.loc[:, \"feature_RSI\"] = self._rsi(close_series)\n",
    "        macd, macd_signal = self._macd(close_series)\n",
    "        dataf.loc[:, \"feature_MACD\"] = macd\n",
    "        dataf.loc[:, \"feature_MACD_signal\"] = macd_signal\n",
    "        return dataf.bfill()\n",
    "\n",
    "    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\n",
    "        \"\"\"Add features for list of ticker DataFrames and concatenate.\"\"\"\n",
    "        with Pool(self.num_cores) as p:\n",
    "            feature_datafs = list(\n",
    "                tqdm(\n",
    "                    p.imap(self.feature_engineering, dataf_list),\n",
    "                    desc=\"Generating features\",\n",
    "                    total=len(dataf_list),\n",
    "                )\n",
    "            )\n",
    "        return pd.concat(feature_datafs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\n",
    "        \"\"\"\n",
    "        See source https://github.com/peerchemist/finta\n",
    "        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\n",
    "        \"\"\"\n",
    "        delta = close.diff()\n",
    "        up, down = delta.copy(), delta.copy()\n",
    "        up[up < 0] = 0\n",
    "        down[down > 0] = 0\n",
    "\n",
    "        gain = up.ewm(com=(period - 1), min_periods=period).mean()\n",
    "        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\n",
    "\n",
    "        rs = gain / loss\n",
    "        return pd.Series(100 - (100 / (1 + rs)))\n",
    "\n",
    "    def _macd(\n",
    "        self, close: pd.Series, span1=12, span2=26, span3=9\n",
    "    ) -> Tuple[pd.Series, pd.Series]:\n",
    "        \"\"\"Compute MACD and MACD signal.\"\"\"\n",
    "        exp1 = self.__ema1(close, span1)\n",
    "        exp2 = self.__ema1(close, span2)\n",
    "        macd = 100 * (exp1 - exp2) / exp2\n",
    "        signal = self.__ema1(macd, span3)\n",
    "        return macd, signal\n",
    "\n",
    "    @staticmethod\n",
    "    def __ema1(series: pd.Series, span: int) -> pd.Series:\n",
    "        \"\"\"Exponential moving average\"\"\"\n",
    "        a = 2 / (span + 1)\n",
    "        return series.ewm(alpha=a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find kaggle.json credentials. Make sure it's located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/numerblox/numerblox/download.py:418\u001b[0m, in \u001b[0;36mKaggleDownloader.__check_kaggle_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/kaggle/__init__.py:23\u001b[0m\n\u001b[1;32m     22\u001b[0m api \u001b[38;5;241m=\u001b[39m KaggleApi(ApiClient())\n\u001b[0;32m---> 23\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py:164\u001b[0m, in \u001b[0;36mKaggleApi.authenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Make sure it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms located in\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Or use the environment method.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    166\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_dir))\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Step 3: load into configuration!\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /home/clepelaars/.kaggle. Or use the environment method.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get price data from Kaggle\u001b[39;00m\n\u001b[1;32m      5\u001b[0m home_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkatsu_features_test/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m kd \u001b[38;5;241m=\u001b[39m \u001b[43mKaggleDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhome_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m kd\u001b[38;5;241m.\u001b[39mdownload_training_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode1110/yfinance-stock-price-data-for-numerai-signals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/numerblox/numerblox/download.py:396\u001b[0m, in \u001b[0;36mKaggleDownloader.__init__\u001b[0;34m(self, directory_path)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__check_kaggle_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(directory_path\u001b[38;5;241m=\u001b[39mdirectory_path)\n",
      "File \u001b[0;32m~/numerblox/numerblox/download.py:420\u001b[0m, in \u001b[0;36mKaggleDownloader.__check_kaggle_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find kaggle.json credentials. Make sure it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json credentials. Make sure it's located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication."
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from numerblox.download import KaggleDownloader\n",
    "\n",
    "# Get price data from Kaggle\n",
    "home_dir = \"katsu_features_test/\"\n",
    "kd = KaggleDownloader(home_dir)\n",
    "kd.download_training_data(\"code1110/yfinance-stock-price-data-for-numerai-signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dataf = create_numerframe(f\"{home_dir}/full_data.parquet\")\n",
    "dataf.loc[:, \"friday_date\"] = dataf[\"date\"]\n",
    "# Take 500 ticker sample for test\n",
    "dataf = dataf[dataf[\"ticker\"].isin(dataf[\"ticker\"].unique()[:500])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "kfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\n",
    "new_dataf = kfpp.transform(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 features are generated in this test (3*3 window features + 3 non window features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "new_dataf.sort_values([\"ticker\", \"date\"]).get_feature_data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. EraQuantileProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerai Signals' objective is predicting a ranking of equities. Therefore, we can benefit from creating rankings out of the features. Doing this reduces noise and works as a normalization mechanism for your features. `EraQuantileProcessor` bins features in a given number of quantiles for each era in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EraQuantileProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Transform features into quantiles on a per-era basis\n",
    "\n",
    "    :param num_quantiles: Number of buckets to split data into. \\n\n",
    "    :param era_col: Era column name in the dataframe to perform each transformation. \\n\n",
    "    :param features: All features that you want quantized. All feature cols by default. \\n\n",
    "    :param num_cores: CPU cores to allocate for quantile transforming. All available cores by default. \\n\n",
    "    :param random_state: Seed for QuantileTransformer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_quantiles: int = 50,\n",
    "        era_col: str = \"friday_date\",\n",
    "        features: list = None,\n",
    "        num_cores: int = None,\n",
    "        random_state: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.era_col = era_col\n",
    "        self.num_cores = num_cores if num_cores else os.cpu_count()\n",
    "        self.features = features\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _process_eras(self, groupby_object):\n",
    "        quantizer = QuantileTransformer(\n",
    "            n_quantiles=self.num_quantiles, random_state=self.random_state\n",
    "        )\n",
    "        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "        column = groupby_object.transform(qt)\n",
    "        return column\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(\n",
    "        self,\n",
    "        dataf: Union[pd.DataFrame, NumerFrame],\n",
    "    ) -> NumerFrame:\n",
    "        \"\"\"Multiprocessing quantile transforms by era.\"\"\"\n",
    "        self.features = self.features if self.features else dataf.feature_cols\n",
    "        rich_print(\n",
    "            f\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\"\n",
    "        )\n",
    "\n",
    "        date_groups = dataf.groupby(self.era_col)\n",
    "        groupby_objects = [date_groups[feature] for feature in self.features]\n",
    "\n",
    "        with Pool() as p:\n",
    "            results = list(\n",
    "                tqdm(\n",
    "                    p.imap(self._process_eras, groupby_objects),\n",
    "                    total=len(groupby_objects),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        quantiles = pd.concat(results, axis=1)\n",
    "        dataf[\n",
    "            [f\"{feature}_quantile{self.num_quantiles}\" for feature in self.features]\n",
    "        ] = quantiles\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "new_dataf = new_dataf.sample(10000)\n",
    "era_quantiler = EraQuantileProcessor(num_quantiles=50)\n",
    "era_dataf = era_quantiler.transform(new_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "era_dataf.get_feature_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "#| include: false\n",
    "kd.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. TickerMapper\n",
    "\n",
    "Numerai Signals data APIs may work with different ticker formats. Our goal with `TickerMapper` is to map `ticker_col` to `target_ticker_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TickerMapper(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Map ticker from one format to another. \\n\n",
    "    :param ticker_col: Column used for mapping. Must already be present in the input data. \\n\n",
    "    :param target_ticker_format: Format to map tickers to. Must be present in the ticker map. \\n\n",
    "    For default mapper supported ticker formats are: ['ticker', 'bloomberg_ticker', 'yahoo'] \\n\n",
    "    :param mapper_path: Path to CSV file containing at least ticker_col and target_ticker_format columns. \\n\n",
    "    Can be either a web link of local path. Numerai Signals mapping by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, ticker_col: str = \"ticker\", target_ticker_format: str = \"bloomberg_ticker\",\n",
    "        mapper_path: str = \"https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ticker_col = ticker_col\n",
    "        self.target_ticker_format = target_ticker_format\n",
    "\n",
    "        self.signals_map_path = mapper_path\n",
    "        self.ticker_map = pd.read_csv(self.signals_map_path)\n",
    "\n",
    "        assert (\n",
    "            self.ticker_col in self.ticker_map.columns\n",
    "        ), f\"Ticker column '{self.ticker_col}' is not available in ticker mapping.\"\n",
    "        assert (\n",
    "            self.target_ticker_format in self.ticker_map.columns\n",
    "        ), f\"Target ticker column '{self.target_ticker_format}' is not available in ticker mapping.\"\n",
    "\n",
    "        self.mapping = dict(\n",
    "            self.ticker_map[[self.ticker_col, self.target_ticker_format]].values\n",
    "        )\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        dataf[self.target_ticker_format] = dataf[self.ticker_col].map(self.mapping)\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use default signals mapping to convert between Numerai ticker, Bloomberg ticker and Yahoo ticker formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataf = pd.DataFrame([\"AAPL\", \"MSFT\"], columns=[\"ticker\"])\n",
    "mapper = TickerMapper()\n",
    "mapper.transform(test_dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a CSV file for mapping. For example, the mapping Numerai user degerhan provides in [dsignals](https://github.com/degerhan/dsignals) for EOD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataf = pd.DataFrame([\"LLB SW\", \"DRAK NA\", \"SWB MK\", \"ELEKTRA* MF\", \"NOT_A_TICKER\"], columns=[\"bloomberg_ticker\"])\n",
    "mapper = TickerMapper(ticker_col=\"bloomberg_ticker\", target_ticker_format=\"signals_ticker\",\n",
    "                      mapper_path=\"test_assets/eodhd-map.csv\")\n",
    "mapper.transform(test_dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5. SignalsTargetProcessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerai provides [targets for 5000 stocks](https://docs.numer.ai/numerai-signals/signals-overview#universe) that are neutralized against all sorts of factors. However, it can be helpful to experiment with creating your own targets. You might want to explore different windows, different target binning and/or neutralization. `SignalsTargetProcessor` engineers 3 different targets for every given windows:\n",
    "- `_raw`: Raw return based on price movements.\n",
    "- `_rank`: Ranks of raw return.\n",
    "- `_group`: Binned returns based on rank.\n",
    "\n",
    "Note that Numerai provides targets based on 4-day returns and 20-day returns. While you can explore any window you like, it makes sense to start with `windows` close to these timeframes.\n",
    "\n",
    "For the `bins` argument there are also many options possible. The followed are commonly used binning:\n",
    "- Nomi bins: `[0, 0.05, 0.25, 0.75, 0.95, 1]`\n",
    "- Uniform bins: `[0, 0.20, 0.40, 0.60, 0.80, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SignalsTargetProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Engineer targets for Numerai Signals. \\n\n",
    "    More information on implements Numerai Signals targets: \\n\n",
    "    https://forum.numer.ai/t/decoding-the-signals-target/2501\n",
    "\n",
    "    :param price_col: Column from which target will be derived. \\n\n",
    "    :param windows: Timeframes to use for engineering targets. 10 and 20-day by default. \\n\n",
    "    :param bins: Binning used to create group targets. Nomi binning by default. \\n\n",
    "    :param labels: Scaling for binned target. Must be same length as resulting bins (bins-1). Numerai labels by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        price_col: str = \"close\",\n",
    "        windows: list = None,\n",
    "        bins: list = None,\n",
    "        labels: list = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.price_col = price_col\n",
    "        self.windows = windows if windows else [10, 20]\n",
    "        self.bins = bins if bins else [0, 0.05, 0.25, 0.75, 0.95, 1]\n",
    "        self.labels = labels if labels else [0, 0.25, 0.50, 0.75, 1]\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        for window in tqdm(self.windows, desc=\"Signals target engineering windows\"):\n",
    "            dataf.loc[:, f\"target_{window}d_raw\"] = (\n",
    "                dataf[self.price_col].pct_change(periods=window).shift(-window)\n",
    "            )\n",
    "            era_groups = dataf.groupby(dataf.meta.era_col)\n",
    "\n",
    "            dataf.loc[:, f\"target_{window}d_rank\"] = era_groups[\n",
    "                f\"target_{window}d_raw\"\n",
    "            ].rank(pct=True, method=\"first\")\n",
    "            dataf.loc[:, f\"target_{window}d_group\"] = era_groups[\n",
    "                f\"target_{window}d_rank\"\n",
    "            ].transform(\n",
    "                lambda group: pd.cut(\n",
    "                    group, bins=self.bins, labels=self.labels, include_lowest=True\n",
    "                )\n",
    "            )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "stp = SignalsTargetProcessor()\n",
    "era_dataf.meta.era_col = \"date\"\n",
    "new_target_dataf = stp.transform(era_dataf)\n",
    "new_target_dataf.get_target_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6. LagPreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models like Gradient Boosting Machines (GBMs) don't learn any time-series patterns by itself. However, if we create lags of our features the models will pick up on time dependencies between features. `LagPreProcessor` create lag features for given features and windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LagPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Add lag features based on given windows.\n",
    "\n",
    "    :param windows: All lag windows to process for all features. \\n\n",
    "    [5, 10, 15, 20] by default (4 weeks lookback) \\n\n",
    "    :param ticker_col: Column name for grouping by tickers. \\n\n",
    "    :param feature_names: All features for which you want to create lags. All features by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list = None,\n",
    "        ticker_col: str = \"bloomberg_ticker\",\n",
    "        feature_names: list = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows if windows else [5, 10, 15, 20]\n",
    "        self.ticker_col = ticker_col\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        ticker_groups = dataf.groupby(self.ticker_col)\n",
    "        for feature in tqdm(feature_names, desc=\"Lag feature generation\"):\n",
    "            feature_group = ticker_groups[feature]\n",
    "            for day in self.windows:\n",
    "                shifted = feature_group.shift(day, axis=0)\n",
    "                dataf.loc[:, f\"{feature}_lag{day}\"] = shifted\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "lpp = LagPreProcessor(ticker_col=\"ticker\", feature_names=[\"close\", \"volume\"])\n",
    "dataf = lpp(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All lag features will contain `lag` in the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dataf.get_pattern_data(\"lag\").tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7. DifferencePreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating lags with the `LagPreProcessor`, it may be useful to create new features that calculate the difference between those lags. Through this process in `DifferencePreProcessor`, we can provide models with more time-series related patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DifferencePreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Add difference features based on given windows. Run LagPreProcessor first.\n",
    "\n",
    "    :param windows: All lag windows to process for all features. \\n\n",
    "    :param feature_names: All features for which you want to create differences. All features that also have lags by default. \\n\n",
    "    :param pct_change: Method to calculate differences. If True, will calculate differences with a percentage change. Otherwise calculates a simple difference. Defaults to False \\n\n",
    "    :param abs_diff: Whether to also calculate the absolute value of all differences. Defaults to True \\n\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list = None,\n",
    "        feature_names: list = None,\n",
    "        pct_diff: bool = False,\n",
    "        abs_diff: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows if windows else [5, 10, 15, 20]\n",
    "        self.feature_names = feature_names\n",
    "        self.pct_diff = pct_diff\n",
    "        self.abs_diff = abs_diff\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        for feature in tqdm(self.feature_names, desc=\"Difference feature generation\"):\n",
    "            lag_columns = dataf.get_pattern_data(f\"{feature}_lag\").columns\n",
    "            if not lag_columns.empty:\n",
    "                for day in self.windows:\n",
    "                    differenced_values = (\n",
    "                        (dataf[feature] / dataf[f\"{feature}_lag{day}\"]) - 1\n",
    "                        if self.pct_diff\n",
    "                        else dataf[feature] - dataf[f\"{feature}_lag{day}\"]\n",
    "                    )\n",
    "                    dataf[f\"{feature}_diff{day}\"] = differenced_values\n",
    "                    if self.abs_diff:\n",
    "                        dataf[f\"{feature}_absdiff{day}\"] = np.abs(\n",
    "                            dataf[f\"{feature}_diff{day}\"]\n",
    "                        )\n",
    "            else:\n",
    "                rich_print(\n",
    "                    f\":warning: WARNING: Skipping {feature}. Lag features for feature: {feature} were not detected. Have you already run LagPreProcessor? :warning:\"\n",
    "                )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dpp = DifferencePreProcessor(\n",
    "    feature_names=[\"close\", \"volume\"], windows=[5, 10, 15, 20], pct_diff=True\n",
    ")\n",
    "dataf = dpp.transform(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All difference features will contain `diff` in the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dataf.get_pattern_data(\"diff\").tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an almost unlimited number of ways to preprocess (selection, engineering and manipulation). We have only scratched the surface with the preprocessors currently implemented. We invite the Numerai community to develop Numerai Classic and Numerai Signals preprocessors.\n",
    "\n",
    "A new Preprocessor should inherit from `BaseProcessor` and implement a `transform` method. For efficient implementation, we recommend you use `NumerFrame` functionality for preprocessing. You can also support Pandas DataFrame input as long as the `transform` method returns a `NumerFrame`. This ensures that the Preprocessor still works within a full `numerai-blocks` pipeline. A template for new preprocessors is given below.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AwesomePreProcessor(BaseProcessor):\n",
    "    \"\"\" TEMPLATE - Do some awesome preprocessing. \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Parse all contents of NumerFrame to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
