{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Functionality to easily download data to your environment.\n",
    "output-file: download.html\n",
    "title: Download\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import concurrent\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from rich.tree import Tree\n",
    "from functools import partial\n",
    "from numerapi import NumerAPI\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import storage\n",
    "from rich.console import Console\n",
    "from eod import EodHistoricalData\n",
    "from typeguard import typechecked\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path, PosixPath\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from numerblox.numerframe import NumerFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. BaseIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are common methods needed for `Downloaders` and `Submittors`. `BaseIO` implements this functionality and allows us to make abstract base classes. Namely, `BaseDownloader` and `BaseSubmitter` (implemented in `submission` section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class BaseIO(ABC):\n",
    "    \"\"\"\n",
    "    Basic functionality for IO (downloading and uploading).\n",
    "\n",
    "    :param directory_path: Base folder for IO. Will be created if it does not exist.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        self.dir = Path(directory_path)\n",
    "        self._create_directory()\n",
    "\n",
    "    def remove_base_directory(self):\n",
    "        \"\"\"Remove directory with all contents.\"\"\"\n",
    "        abs_path = self.dir.resolve()\n",
    "        rich_print(\n",
    "            f\":warning: [red]Deleting directory for '{self.__class__.__name__}[/red]' :warning:\\nPath: '{abs_path}'\"\n",
    "        )\n",
    "        shutil.rmtree(abs_path)\n",
    "\n",
    "    def download_file_from_gcs(self, bucket_name: str, gcs_path: str):\n",
    "        \"\"\"\n",
    "        Get file from GCS bucket and download to local directory.\n",
    "        :param gcs_path: Path to file on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob_path = str(self.dir.resolve())\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\n",
    "        blob.download_to_filename(gcs_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :page_facing_up: Downloaded GCS object '{gcs_path}' from bucket '{blob.bucket.id}' to local directory '{blob_path}'. :page_facing_up: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def upload_file_to_gcs(self, bucket_name: str, gcs_path: str, local_path: str):\n",
    "        \"\"\"\n",
    "        Upload file to some GCS bucket.\n",
    "        :param gcs_path: Path to file on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\n",
    "        blob.upload_from_filename(local_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :page_facing_up: Local file '{local_path}' uploaded to '{gcs_path}' in bucket {blob.bucket.id}:page_facing_up: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def download_directory_from_gcs(self, bucket_name: str, gcs_path: str):\n",
    "        \"\"\"\n",
    "        Copy full directory from GCS bucket to local environment.\n",
    "        :param gcs_path: Name of directory on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob_path = str(self.dir.resolve())\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\n",
    "        for gcs_file in glob.glob(gcs_path + \"/**\", recursive=True):\n",
    "            if os.path.isfile(gcs_file):\n",
    "                blob.download_to_filename(blob_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :folder: Directory '{gcs_path}' from bucket '{blob.bucket.id}' downloaded to '{blob_path}' :folder: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def upload_directory_to_gcs(self, bucket_name: str, gcs_path: str):\n",
    "        \"\"\"\n",
    "        Upload full base directory to GCS bucket.\n",
    "        :param gcs_path: Name of directory on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\n",
    "        for local_path in glob.glob(str(self.dir) + \"/**\", recursive=True):\n",
    "            if os.path.isfile(local_path):\n",
    "                blob.upload_from_filename(local_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :folder: Directory '{self.dir}' uploaded to '{gcs_path}' in bucket {blob.bucket.id} :folder: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def _get_gcs_blob(self, bucket_name: str, blob_path: str) -> storage.Blob:\n",
    "        \"\"\" Create blob that interacts with Google Cloud Storage (GCS). \"\"\"\n",
    "        client = storage.Client()\n",
    "        # https://console.cloud.google.com/storage/browser/[bucket_name]\n",
    "        bucket = client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_path)\n",
    "        return blob\n",
    "\n",
    "    def _append_folder(self, folder: str) -> Path:\n",
    "        \"\"\"\n",
    "        Return base directory Path object appended with 'folder'.\n",
    "        Create directory if it does not exist.\n",
    "        \"\"\"\n",
    "        dir = Path(self.dir / folder)\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "        return dir\n",
    "\n",
    "    def _create_directory(self):\n",
    "        \"\"\" Create base directory if it does not exist. \"\"\"\n",
    "        if not self.dir.is_dir():\n",
    "            rich_print(\n",
    "                f\"No existing directory found at '[blue]{self.dir}[/blue]'. Creating directory...\"\n",
    "            )\n",
    "            self.dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @property\n",
    "    def get_all_files(self) -> list:\n",
    "        \"\"\" Return all paths of contents in directory. \"\"\"\n",
    "        return list(self.dir.iterdir())\n",
    "\n",
    "    @property\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\" Check if directory is empty. \"\"\"\n",
    "        return not bool(self.get_all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BaseDownloader\n",
    "\n",
    "`BaseDownloader` is an object which implements logic common to all downloaders.\n",
    "\n",
    "To implement a new Downloader, you should inherit from `BaseDownloader` and be sure to implement at least methods for `.download_training_data` and `.download_inference_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class BaseDownloader(BaseIO):\n",
    "    \"\"\"\n",
    "    Abstract base class for downloaders.\n",
    "\n",
    "    :param directory_path: Base folder to download files to.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "\n",
    "    @abstractmethod\n",
    "    def download_training_data(self, *args, **kwargs):\n",
    "        \"\"\" Download all necessary files needed for training. \"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def download_inference_data(self, *args, **kwargs):\n",
    "        \"\"\" Download minimal amount of files needed for weekly inference. \"\"\"\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_json(file_path: str, verbose=False, *args, **kwargs) -> dict:\n",
    "        \"\"\" Load JSON from file and return as dictionary. \"\"\"\n",
    "        with open(Path(file_path)) as json_file:\n",
    "            json_data = json.load(json_file, *args, **kwargs)\n",
    "        if verbose:\n",
    "            rich_print(json_data)\n",
    "        return json_data\n",
    "\n",
    "    def _default_save_path(self, start: dt, end: dt, backend: str):\n",
    "        \"\"\" Save to downloader directory indicating backend, start date and end date as parquet file. \"\"\"\n",
    "        return f\"{self.dir}/{backend}_{start.strftime('%Y%m%d')}_{end.strftime('%Y%m%d')}.parquet\"\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        The most common use case will be to get weekly inference data. So calling the class itself returns inference data.\n",
    "        \"\"\"\n",
    "        self.download_inference_data(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numerai Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NumeraiClassicDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    WARNING: Versions 1 and 2 (legacy data) are deprecated. Only supporting version 3+.\n",
    "\n",
    "    Downloading from NumerAPI for Numerai Classic data. \\n\n",
    "    :param directory_path: Base folder to download files to. \\n\n",
    "    All *args, **kwargs will be passed to NumerAPI initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str, *args, **kwargs):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "        self.napi = NumerAPI(*args, **kwargs)\n",
    "        self.current_round = self.napi.get_current_round()\n",
    "        # NumerAPI filenames corresponding to version, class and data type\n",
    "        self.version_mapping = {\"3\": {\n",
    "            \"train\": {\n",
    "                \"int8\": [\n",
    "                    \"v3/numerai_training_data_int8.parquet\",\n",
    "                    \"v3/numerai_validation_data_int8.parquet\"\n",
    "                ],\n",
    "                \"float\": [\n",
    "                    \"v3/numerai_training_data.parquet\",\n",
    "                    \"v3/numerai_validation_data.parquet\"\n",
    "                ]\n",
    "            },\n",
    "            \"inference\": {\n",
    "                \"int8\": [\"v3/numerai_tournament_data_int8.parquet\"],\n",
    "                \"float\": [\"v3/numerai_tournament_data.parquet\"]\n",
    "            },\n",
    "            \"live\": {\n",
    "                \"int8\": [\"v3/numerai_live_data_int8.parquet\"],\n",
    "                \"float\": [\"v3/numerai_live_data.parquet\"]\n",
    "            },\n",
    "        },\n",
    "            \"4\": {\n",
    "                \"train\": {\n",
    "                    \"int8\": [\n",
    "                        \"v4/train_int8.parquet\",\n",
    "                        \"v4/validation_int8.parquet\"\n",
    "                    ],\n",
    "                    \"float\": [\n",
    "                        \"v4/train.parquet\",\n",
    "                        \"v4/validation.parquet\"\n",
    "                    ]\n",
    "                },\n",
    "                \"inference\": {\n",
    "                    \"int8\": [\"v4/live_int8.parquet\"],\n",
    "                    \"float\": [\"v4/live.parquet\"]\n",
    "                },\n",
    "                \"live\": {\n",
    "                    \"int8\": [\"v4/live_int8.parquet\"],\n",
    "                    \"float\": [\"v4/live.parquet\"]\n",
    "                },\n",
    "                \"example\": [\n",
    "                    \"v4/live_example_preds.parquet\",\n",
    "                    \"v4/validation_example_preds.parquet\"\n",
    "                ]\n",
    "            },\n",
    "            \"4.1\": {\n",
    "                \"train\": {\n",
    "                    \"int8\": [\n",
    "                        \"v4.1/train_int8.parquet\",\n",
    "                        \"v4.1/validation_int8.parquet\"\n",
    "                    ],\n",
    "                    \"float\": [\n",
    "                        \"v4.1/train.parquet\",\n",
    "                        \"v4.1/validation.parquet\"\n",
    "                    ]\n",
    "                },\n",
    "                \"inference\": {\n",
    "                    \"int8\": [\"v4.1/live_int8.parquet\"],\n",
    "                    \"float\": [\"v4.1/live.parquet\"]\n",
    "                },\n",
    "                \"live\": {\n",
    "                    \"int8\": [\"v4.1/live_int8.parquet\"],\n",
    "                    \"float\": [\"v4.1/live.parquet\"]\n",
    "                },\n",
    "                \"example\": [\n",
    "                    \"v4.1/live_example_preds.parquet\",\n",
    "                    \"v4.1/validation_example_preds.parquet\"\n",
    "                ],\n",
    "                \"meta_model\": [\n",
    "                    \"v4.1/meta_model.parquet\",\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def download_training_data(\n",
    "        self, subfolder: str = \"\", version: str = \"4.1\", int8: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get Numerai classic training and validation data.\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param version: Numerai dataset version (4.1=Sunshine dataset)\n",
    "        :param int8: Integer version of data\n",
    "        \"\"\"\n",
    "        data_type = \"int8\" if int8 else \"float\"\n",
    "        train_val_files = self._get_version_mapping(str(version))[\"train\"][data_type]\n",
    "        for file in train_val_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path\n",
    "            )\n",
    "\n",
    "    def download_inference_data(\n",
    "        self,\n",
    "        subfolder: str = \"\",\n",
    "        version: str = \"4.1\",\n",
    "        int8: bool = False,\n",
    "        round_num: int = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get Numerai classic inference (tournament) data.\n",
    "        If only minimal live data is needed, consider .download_live_data.\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param version: Numerai dataset version (4.1=Sunshine dataset)\n",
    "        :param int8: Integer version of data\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        data_type = \"int8\" if int8 else \"float\"\n",
    "        inference_files = self._get_version_mapping(str(version))[\"inference\"][data_type]\n",
    "        for file in inference_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path,\n",
    "                round_num=round_num\n",
    "            )\n",
    "\n",
    "    def download_single_dataset(\n",
    "        self, filename: str, dest_path: str, round_num: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Download one of the available datasets through NumerAPI.\n",
    "\n",
    "        :param filename: Name as listed in NumerAPI (Check NumerAPI().list_datasets() for full overview)\n",
    "        :param dest_path: Full path where file will be saved.\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        rich_print(\n",
    "            f\":file_folder: [green]Downloading[/green] '{filename}' :file_folder:\"\n",
    "        )\n",
    "        self.napi.download_dataset(\n",
    "            filename=filename,\n",
    "            dest_path=dest_path,\n",
    "            round_num=round_num\n",
    "        )\n",
    "\n",
    "    def download_live_data(\n",
    "            self,\n",
    "            subfolder: str = \"\",\n",
    "            version: str = \"4.1\",\n",
    "            int8: bool = False,\n",
    "            round_num: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Download all live data in specified folder for given version (i.e. minimal data needed for inference).\n",
    "\n",
    "        :param subfolder: Specify folder to create folder within directory root.\n",
    "        Saves in directory root by default.\n",
    "        :param version: Numerai dataset version (4.1=Sunshine dataset)\n",
    "        :param int8: Integer version of data\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        data_type = \"int8\" if int8 else \"float\"\n",
    "        live_files = self._get_version_mapping(str(version))[\"live\"][data_type]\n",
    "        for file in live_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path,\n",
    "                round_num=round_num\n",
    "            )\n",
    "\n",
    "    def download_example_data(\n",
    "        self, subfolder: str = \"\", version: str = \"4.1\", round_num: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Download all example prediction data in specified folder for given version.\n",
    "\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param version: Numerai dataset version (4.1=Sunshine dataset)\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        example_files = self._get_version_mapping(str(version))[\"example\"]\n",
    "        for file in example_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path,\n",
    "                round_num=round_num\n",
    "            )\n",
    "\n",
    "    def get_classic_features(self, subfolder: str = \"\", filename=\"v4.1/features.json\", *args, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Download feature overview (stats and feature sets) through NumerAPI and load as dict.\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param filename: name for feature overview.\n",
    "        Currently defined as 'features.json' in NumerAPI and used as default.\n",
    "        *args, **kwargs will be passed to the JSON loader.\n",
    "        \"\"\"\n",
    "        dest_path = self.__get_dest_path(subfolder, filename)\n",
    "        self.download_single_dataset(filename=filename,\n",
    "                                     dest_path=dest_path)\n",
    "        json_data = self._load_json(dest_path, *args, **kwargs)\n",
    "        return json_data\n",
    "\n",
    "    def _get_version_mapping(self, version: int) -> dict:\n",
    "        \"\"\" Check if data version is supported and return file mapping for version. \"\"\"\n",
    "        try:\n",
    "            mapping_dictionary = self.version_mapping[str(version)]\n",
    "        except KeyError:\n",
    "            raise NotImplementedError(\n",
    "                f\"Version '{version}' is not available. Available versions are {list(self.version_mapping.keys())}\"\n",
    "            )\n",
    "        return mapping_dictionary\n",
    "\n",
    "    def __get_dest_path(self, subfolder: str, filename: str) -> str:\n",
    "        \"\"\" Prepare destination path for downloading. \"\"\"\n",
    "        dir = self._append_folder(subfolder)\n",
    "        dest_path = str(dir.joinpath(filename.split(\"/\")[-1]))\n",
    "        return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_numclassic_general</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No existing directory found at \u001b[32m'\u001b[0m\u001b[34mtest_numclassic_general\u001b[0m\u001b[32m'\u001b[0m. Creating directory\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Directory contents:\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Path</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_numclassic_general/test.txt'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Directory contents:\n",
       "\u001b[1m[\u001b[0m\u001b[1;35mPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'test_numclassic_general/test.txt'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4.1/live_example_preds.parquet'</span> üìÅ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ \u001b[32mDownloading\u001b[0m \u001b[32m'v4.1/live_example_preds.parquet'\u001b[0m üìÅ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:40:32,652 INFO numerapi.utils: starting download\n",
      "test_numclassic_general/test/live_example_preds.parquet: 136kB [00:00, 566kB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4.1/validation_example_preds.parquet'</span> üìÅ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ \u001b[32mDownloading\u001b[0m \u001b[32m'v4.1/validation_example_preds.parquet'\u001b[0m üìÅ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:40:33,970 INFO numerapi.utils: starting download\n",
      "test_numclassic_general/test/validation_example_preds.parquet: 56.5MB [00:02, 21.7MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4.1/features.json'</span> üìÅ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ \u001b[32mDownloading\u001b[0m \u001b[32m'v4.1/features.json'\u001b[0m üìÅ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:40:37,208 INFO numerapi.utils: starting download\n",
      "test_numclassic_general/features.json: 671kB [00:00, 1.56MB/s]                           \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ö† <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ‚ö†\n",
       "Path: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/clepelaars/numerblox/nbs/test_numclassic_general'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ö† \u001b[31mDeleting directory for \u001b[0m\u001b[31m'NumeraiClassicDownloader\u001b[0m\u001b[32m'\u001b[0m ‚ö†\n",
       "Path: \u001b[32m'/home/clepelaars/numerblox/nbs/test_numclassic_general'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "test_dir_classic = \"test_numclassic_general\"\n",
    "numer_classic_downloader = NumeraiClassicDownloader(test_dir_classic)\n",
    "\n",
    "# Test building class\n",
    "assert isinstance(numer_classic_downloader.dir, PosixPath)\n",
    "assert numer_classic_downloader.dir.is_dir()\n",
    "\n",
    "# Test is_empty\n",
    "(numer_classic_downloader.dir / \"test.txt\").write_text(\"test\")\n",
    "rich_print(f\"Directory contents:\\n{numer_classic_downloader.get_all_files}\")\n",
    "assert not numer_classic_downloader.is_empty\n",
    "\n",
    "# Downloading example data\n",
    "numer_classic_downloader.download_example_data(\"test/\", version=\"4.1\", round_num=390)\n",
    "\n",
    "# Features\n",
    "feature_stats_test = numer_classic_downloader.get_classic_features()\n",
    "assert isinstance(feature_stats_test, dict)\n",
    "assert len(feature_stats_test[\"feature_sets\"][\"medium\"]) == 641\n",
    "\n",
    "# Remove contents\n",
    "numer_classic_downloader.remove_base_directory()\n",
    "assert not os.path.exists(test_dir_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will explain how to quickly get started with `NumeraiClassicDownloader`.\n",
    "\n",
    "The more advanced use case of working with GCS (Google Cloud Storage) is discussed in `edu_nbs/google_cloud_storage.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training + validation data for Numerai Classic can be downloaded with effectively 2 lines of code.\n",
    "Feature stats and overview can be downloaded with `.get_classic_features()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_numclassic_train</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No existing directory found at \u001b[32m'\u001b[0m\u001b[34mtest_numclassic_train\u001b[0m\u001b[32m'\u001b[0m. Creating directory\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4.1/features.json'</span> üìÅ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ \u001b[32mDownloading\u001b[0m \u001b[32m'v4.1/features.json'\u001b[0m üìÅ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:40:38,744 INFO numerapi.utils: starting download\n",
      "test_numclassic_train/features.json: 671kB [00:00, 1.65MB/s]                           \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ö† <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ‚ö†\n",
       "Path: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/clepelaars/numerblox/nbs/test_numclassic_train'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ö† \u001b[31mDeleting directory for \u001b[0m\u001b[31m'NumeraiClassicDownloader\u001b[0m\u001b[32m'\u001b[0m ‚ö†\n",
       "Path: \u001b[32m'/home/clepelaars/numerblox/nbs/test_numclassic_train'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization\n",
    "train_base_directory = \"test_numclassic_train\"\n",
    "numer_classic_downloader = NumeraiClassicDownloader(train_base_directory)\n",
    "\n",
    "# Uncomment line below to download training and validation data\n",
    "# numer_classic_downloader.download_training_data(\"train_val\", int8=False)\n",
    "\n",
    "# Get feature overview (dict)\n",
    "numer_classic_downloader.get_classic_features()\n",
    "\n",
    "# Remove contents (To clean up environment)\n",
    "numer_classic_downloader.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For the training example the directory structure will be:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ test_numclassic_train (base_directory)\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">‚î£‚îÅ‚îÅ </span>üìÑ features.json\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">‚îó‚îÅ‚îÅ </span>üìÅ train_val\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">    ‚î£‚îÅ‚îÅ </span>üìÑ numerai_training_data.parquet\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">    ‚îó‚îÅ‚îÅ </span>üìÑ numerai_validation_data.parquet\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ test_numclassic_train (base_directory)\n",
       "\u001b[90m‚î£‚îÅ‚îÅ \u001b[0müìÑ features.json\n",
       "\u001b[90m‚îó‚îÅ‚îÅ \u001b[0müìÅ train_val\n",
       "\u001b[90m    \u001b[0m\u001b[90m‚î£‚îÅ‚îÅ \u001b[0müìÑ numerai_training_data.parquet\n",
       "\u001b[90m    \u001b[0m\u001b[90m‚îó‚îÅ‚îÅ \u001b[0müìÑ numerai_validation_data.parquet\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "console = Console(record=True, width=100)\n",
    "\n",
    "tree = Tree(\n",
    "    f\":file_folder: {train_base_directory} (base_directory)\",\n",
    "    guide_style=\"bold bright_black\",\n",
    ")\n",
    "folder_tree = tree.add(\":page_facing_up: features.json\")\n",
    "train_val_tree = tree.add(\":file_folder: train_val\")\n",
    "train_val_tree.add(\":page_facing_up: numerai_training_data.parquet\")\n",
    "train_val_tree.add(\":page_facing_up: numerai_validation_data.parquet\")\n",
    "\n",
    "console.print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Inference data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference data for the most recent round of Numerai Classic can be downloaded with effectively 2 lines of code.\n",
    "It can also easily be deleted after you are done with inference by calling `.remove_base_directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_numclassic_inference</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No existing directory found at \u001b[32m'\u001b[0m\u001b[34mtest_numclassic_inference\u001b[0m\u001b[32m'\u001b[0m. Creating directory\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4.1/live_int8.parquet'</span> üìÅ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ \u001b[32mDownloading\u001b[0m \u001b[32m'v4.1/live_int8.parquet'\u001b[0m üìÅ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:40:40,532 INFO numerapi.utils: starting download\n",
      "test_numclassic_inference/inference/live_int8.parquet: 4.51MB [00:00, 7.43MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ö† <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ‚ö†\n",
       "Path: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/clepelaars/numerblox/nbs/test_numclassic_inference'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ö† \u001b[31mDeleting directory for \u001b[0m\u001b[31m'NumeraiClassicDownloader\u001b[0m\u001b[32m'\u001b[0m ‚ö†\n",
       "Path: \u001b[32m'/home/clepelaars/numerblox/nbs/test_numclassic_inference'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization\n",
    "inference_base_dir = \"test_numclassic_inference\"\n",
    "numer_classic_downloader = NumeraiClassicDownloader(directory_path=inference_base_dir)\n",
    "\n",
    "# Download tournament (inference) data\n",
    "numer_classic_downloader.download_inference_data(\"inference\", version=\"4.1\", int8=True)\n",
    "\n",
    "# Remove folder when done with inference\n",
    "numer_classic_downloader.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For the inference example the directory structure will be:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÅ test_numclassic_inference (base_directory)\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">‚îó‚îÅ‚îÅ </span>üìÅ inference\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">    ‚îó‚îÅ‚îÅ </span>üìÑ numerai_tournament_data.parquet\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÅ test_numclassic_inference (base_directory)\n",
       "\u001b[90m‚îó‚îÅ‚îÅ \u001b[0müìÅ inference\n",
       "\u001b[90m    \u001b[0m\u001b[90m‚îó‚îÅ‚îÅ \u001b[0müìÑ numerai_tournament_data.parquet\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "console = Console(record=True, width=100)\n",
    "\n",
    "tree = Tree(\n",
    "    f\":file_folder: {inference_base_dir} (base_directory)\",\n",
    "    guide_style=\"bold bright_black\",\n",
    ")\n",
    "inference_tree = tree.add(\":file_folder: inference\")\n",
    "inference_tree.add(\":page_facing_up: numerai_tournament_data.parquet\")\n",
    "\n",
    "console.print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KaggleDownloader (Numerai Signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Numerai community maintains some excellent datasets on Kaggle for Numerai Signals.\n",
    "\n",
    "For example, [Katsu1110](https://www.kaggle.com/code1110) maintains a [dataset with yfinance price data](https://www.kaggle.com/code1110/yfinance-stock-price-data-for-numerai-signals) on Kaggle that is updated daily. `KaggleDownloader` allows you to easily pull data through the Kaggle API. We will be using this dataset in an example below.\n",
    "\n",
    "In this case, `download_inference_data` and `download_training_data` have the same functionality as we can't make the distinction beforehand for an arbitrary dataset on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class KaggleDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    Download awesome financial data from Kaggle.\n",
    "\n",
    "    For authentication, make sure you have a directory called .kaggle in your home directory\n",
    "    with therein a kaggle.json file. kaggle.json should have the following structure: \\n\n",
    "    `{\"username\": USERNAME, \"key\": KAGGLE_API_KEY}` \\n\n",
    "    More info on authentication: github.com/Kaggle/kaggle-api#api-credentials \\n\n",
    "\n",
    "    More info on the Kaggle Python API: kaggle.com/donkeys/kaggle-python-api \\n\n",
    "\n",
    "    :param directory_path: Base folder to download files to.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        self.__check_kaggle_import()\n",
    "        super().__init__(directory_path=directory_path)\n",
    "\n",
    "    def download_inference_data(self, kaggle_dataset_path: str):\n",
    "        \"\"\"\n",
    "        Download arbitrary Kaggle dataset.\n",
    "        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\n",
    "        \"\"\"\n",
    "        self.download_training_data(kaggle_dataset_path)\n",
    "\n",
    "    def download_training_data(self, kaggle_dataset_path: str):\n",
    "        \"\"\"\n",
    "        Download arbitrary Kaggle dataset.\n",
    "        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\n",
    "        \"\"\"\n",
    "        import kaggle\n",
    "        kaggle.api.dataset_download_files(kaggle_dataset_path,\n",
    "                                          path=self.dir, unzip=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def __check_kaggle_import():\n",
    "        try:\n",
    "            import kaggle\n",
    "        except OSError:\n",
    "            raise OSError(\"Could not find kaggle.json credentials. Make sure it's located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to Katsu1110's yfinance price dataset is [https://www.kaggle.com/code1110/yfinance-stock-price-data-for-numerai-signals](https://www.kaggle.com/code1110/yfinance-stock-price-data-for-numerai-signals). In `.download_training_data` we define the slug after kaggle.com (`code1110/yfinance-stock-price-data-for-numerai-signals`) as an argument. The full Kaggle dataset is downloaded and unzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "home_directory = \"test_kaggle_downloader\"\n",
    "kd = KaggleDownloader(home_directory)\n",
    "kd.download_training_data(\"code1110/yfinance-stock-price-data-for-numerai-signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kaggle dataset contains one file called `\"full_data.parquet\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('test_kaggle_downloader/full_data.parquet')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "list(kd.dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>raw_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000060 KS</td>\n",
       "      <td>20020103</td>\n",
       "      <td>534.924377</td>\n",
       "      <td>1248.795166</td>\n",
       "      <td>1248.795166</td>\n",
       "      <td>1248.795166</td>\n",
       "      <td>1248.795166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000060 KS</td>\n",
       "      <td>20020104</td>\n",
       "      <td>566.944519</td>\n",
       "      <td>1323.546997</td>\n",
       "      <td>1363.121460</td>\n",
       "      <td>1213.617798</td>\n",
       "      <td>1275.178223</td>\n",
       "      <td>3937763.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker      date       close    raw_close         high          low  \\\n",
       "0  000060 KS  20020103  534.924377  1248.795166  1248.795166  1248.795166   \n",
       "1  000060 KS  20020104  566.944519  1323.546997  1363.121460  1213.617798   \n",
       "\n",
       "          open     volume  \n",
       "0  1248.795166        0.0  \n",
       "1  1275.178223  3937763.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = pd.read_parquet(f\"{home_directory}/full_data.parquet\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder can be cleaned up when done with inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ö† <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'KaggleDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ‚ö†\n",
       "Path: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/clepelaars/numerblox/nbs/test_kaggle_downloader'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ö† \u001b[31mDeleting directory for \u001b[0m\u001b[31m'KaggleDownloader\u001b[0m\u001b[32m'\u001b[0m ‚ö†\n",
       "Path: \u001b[32m'/home/clepelaars/numerblox/nbs/test_kaggle_downloader'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "kd.remove_base_directory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EODDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[EOD Historical data](https://eodhistoricaldata.com/) is an affordable Financial data APIs that offers a large range of global stock tickers. Very convenient for Numerai Signals modeling. We will use a Python API build on top of EOD Historical data to download stock ticker data for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EODDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    Download data from EOD historical data. \\n\n",
    "    More info: https://eodhistoricaldata.com/\n",
    "\n",
    "    :param directory_path: Base folder to download files to. \\n\n",
    "    :param key: Valid EOD client key. \\n\n",
    "    :param tickers: List of valid EOD tickers (Bloomberg ticker format). \\n\n",
    "    :param frequency: Choose from [d, w, m]. \\n\n",
    "    Daily data by default.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 directory_path: str,\n",
    "                 key: str,\n",
    "                 tickers: list,\n",
    "                 frequency: str = \"d\"):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "        self.key = key\n",
    "        self.tickers = tickers\n",
    "        self.client = EodHistoricalData(self.key)\n",
    "        self.frequency = frequency\n",
    "        self.current_time = dt.now()\n",
    "        self.end_date = self.current_time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    def download_inference_data(self):\n",
    "        \"\"\" Download one year of data for defined tickers. \"\"\"\n",
    "        start = (pd.Timestamp(self.current_time) - relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n",
    "        dataf = self.get_live_data(start=start)\n",
    "        dataf.to_parquet(self._default_save_path(start=pd.Timestamp(start),\n",
    "                                                 end=pd.Timestamp(self.end_date),\n",
    "                                                 backend=\"eod\"))\n",
    "\n",
    "    def download_training_data(self, start: str = None):\n",
    "        \"\"\"\n",
    "        Download full date length available.\n",
    "        start: Starting data in %Y-%m-%d format.\n",
    "        \"\"\"\n",
    "        start = start if start else \"1970-01-01\"\n",
    "        dataf = self.generate_full_dataf(start=start)\n",
    "        dataf.to_parquet(self._default_save_path(start=pd.Timestamp(start),\n",
    "                                                 end=pd.Timestamp(self.end_date),\n",
    "                                                 backend=\"eod\"))\n",
    "\n",
    "    def get_live_data(self, start: str) -> NumerFrame:\n",
    "        \"\"\"\n",
    "        Get NumerFrame containing one year of data.\n",
    "        start: Starting data in %Y-%m-%d format.\n",
    "        \"\"\"\n",
    "        dataf = self.generate_full_dataf(start=start)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def generate_full_dataf(self, start: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Collect all price data for list of EOD ticker symbols (Bloomberg tickers).\n",
    "        start: Starting data in %Y-%m-%d format.\n",
    "        \"\"\"\n",
    "        price_datafs = []\n",
    "        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "            tasks = [executor.submit(self.generate_stock_dataf, ticker, start) for ticker in self.tickers]\n",
    "            for task in tqdm(concurrent.futures.as_completed(tasks),\n",
    "                             total=len(self.tickers),\n",
    "                             desc=\"EOD price data extraction\"):\n",
    "                price_datafs.append(task.result())\n",
    "        return pd.concat(price_datafs)\n",
    "\n",
    "    def generate_stock_dataf(self, ticker: str, start: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate Price DataFrame for a single ticker.\n",
    "        ticker: EOD ticker symbol (Bloomberg tickers).\n",
    "        For example, Apple stock = AAPL.US.\n",
    "        start: Starting data in %Y-%m-%d format.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            resp = self.client.get_prices_eod(ticker, period=self.frequency,\n",
    "                                              from_=start, to=self.end_date)\n",
    "            stock_df = pd.DataFrame(resp).set_index('date')\n",
    "            stock_df['ticker'] = ticker\n",
    "        except:\n",
    "            rich_print(f\":warning: WARNING: No data found for ticker: [red]'{ticker}'[/red]. :warning:\")\n",
    "            stock_df = pd.DataFrame()\n",
    "        return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_assets/keys.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m key \u001b[39m=\u001b[39m BaseDownloader\u001b[39m.\u001b[39;49m_load_json(\u001b[39m\"\u001b[39;49m\u001b[39mtest_assets/keys.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39meod_key\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# YOUR_EOD_KEY_HERE\u001b[39;00m\n\u001b[1;32m      3\u001b[0m eodd \u001b[39m=\u001b[39m EODDownloader(directory_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meod_test\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m=\u001b[39mkey, tickers\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mAAPL.US\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMSFT.US\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCOIN.US\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNOT_A_TICKER\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mBaseDownloader._load_json\u001b[0;34m(file_path, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_json\u001b[39m(file_path: \u001b[39mstr\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Load JSON from file and return as dictionary. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(Path(file_path)) \u001b[39mas\u001b[39;00m json_file:\n\u001b[1;32m     26\u001b[0m         json_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     27\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_assets/keys.json'"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "key = BaseDownloader._load_json(\"test_assets/keys.json\")['eod_key'] # YOUR_EOD_KEY_HERE\n",
    "eodd = EODDownloader(directory_path=\"eod_test\", key=key, tickers=['AAPL.US', 'MSFT.US', 'COIN.US', 'NOT_A_TICKER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no starting date is passed in `download_training_data` this downloader will take the earliest date available. That is why the starting date in the filename is the 1st Unix timestamp (January 1st 1970)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eodd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m eodd\u001b[39m.\u001b[39mdownload_inference_data()\n\u001b[1;32m      3\u001b[0m eodd\u001b[39m.\u001b[39mdownload_training_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eodd' is not defined"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "eodd.download_inference_data()\n",
    "eodd.download_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eod_test/eod_19700101_20230104.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| eval: false\u001b[39;00m\n\u001b[1;32m      2\u001b[0m today \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meod_test/eod_19700101_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtoday\u001b[39m}\u001b[39;49;00m\u001b[39m.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    504\u001b[0m     path,\n\u001b[1;32m    505\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    506\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    507\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    508\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    509\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/pandas/io/parquet.py:244\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     to_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39msplit_blocks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    245\u001b[0m     path,\n\u001b[1;32m    246\u001b[0m     kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mfilesystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    248\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[1;32m    252\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    253\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/pandas/io/parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m handles \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m     \u001b[39mnot\u001b[39;00m fs\n\u001b[1;32m     95\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     handles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    103\u001b[0m         path_or_handle, mode, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m     fs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     path_or_handle \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/envs/numerblox38/lib/python3.8/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eod_test/eod_19700101_20230104.parquet'"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "today = dt.now().strftime(\"%Y%m%d\")\n",
    "df = pd.read_parquet(f\"eod_test/eod_19700101_{today}.parquet\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live data with a custom starting date can be retrieved as a `NumerFrame` directly with `get_live_data`. The starting date can be either in `datetime`, `pd.Timestamp` or string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fhd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m live_dataf \u001b[39m=\u001b[39m fhd\u001b[39m.\u001b[39mget_live_data(start\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mTimestamp(year\u001b[39m=\u001b[39m\u001b[39m2021\u001b[39m, month\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, day\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      3\u001b[0m live_dataf\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fhd' is not defined"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "live_dataf = fhd.get_live_data(start=pd.Timestamp(year=2021, month=1, day=1))\n",
    "live_dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'live_dataf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m live_dataf[live_dataf[\u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAAPL\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mplot(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m6\u001b[39m), title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAAPL from January 2021\u001b[39m\u001b[39m\"\u001b[39m);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'live_dataf' is not defined"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "live_dataf[live_dataf['ticker']==\"AAPL\"].set_index(\"date\")['close'].plot(figsize=(15, 6), title=\"AAPL from January 2021\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "eodd.remove_base_directory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We invite the Numerai Community to implement new downloaders for this project using interesting APIs.\n",
    "\n",
    "These are especially important for creating innovative Numerai Signals models.\n",
    "\n",
    "A new Downloader can be created by inheriting from `BaseDownloader`. You should implement methods for `.download_inference_data` and `.download_training_data` so every downloader has a common interface. Below you will find a template for a new downloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AwesomeCustomDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    TEMPLATE -\n",
    "    Download awesome financial data from who knows where.\n",
    "\n",
    "    :param directory_path: Base folder to download files to.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "\n",
    "    def download_inference_data(self, *args, **kwargs):\n",
    "        \"\"\" (minimal) weekly inference downloading here. \"\"\"\n",
    "        ...\n",
    "\n",
    "    def download_training_data(self, *args, **kwargs):\n",
    "        \"\"\" Training + validation dataset downloading here. \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numerblox38",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
