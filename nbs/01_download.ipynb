{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp download\";\n                var nbb_formatted_code = \"# default_exp download\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download\n",
    "\n",
    "\n",
    "\n",
    "> Functionality to easily download data to your environment.\n",
    "\n",
    "## Overview\n",
    "\n",
    "`numerblox` currently provides the following Downloaders:\n",
    "1. `NumeraiClassicDownloader`\n",
    "2. `KaggleDownloader` (Numerai Signals)\n",
    "3. `PandasDataReader` (Numerai Signals)\n",
    "4. `FinnhubDownloader` (Numerai Signals)\n",
    "\n",
    "This notebook also implements a general base class for IO (`BaseIO`) that handles directory logic and integration with GCS (Google Cloud Storage).\n",
    "\n",
    "The last section at the bottom explains how you can implement your own Downloader in `numerblox`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# export\\nimport os\\nimport glob\\nimport json\\nimport shutil\\nimport finnhub\\nimport concurrent\\nimport pandas as pd\\nfrom tqdm.auto import tqdm\\nfrom rich.tree import Tree\\nfrom functools import partial\\nfrom numerapi import NumerAPI\\nimport pandas_datareader as web\\nimport matplotlib.pyplot as plt\\nfrom google.cloud import storage\\nfrom rich.console import Console\\nfrom typeguard import typechecked\\nfrom datetime import datetime as dt\\nfrom pathlib import Path, PosixPath\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom dateutil.relativedelta import relativedelta\\nfrom pandas_datareader._utils import RemoteDataError\\n\\nfrom numerblox.numerframe import NumerFrame\";\n                var nbb_formatted_code = \"# export\\nimport os\\nimport glob\\nimport json\\nimport shutil\\nimport finnhub\\nimport concurrent\\nimport pandas as pd\\nfrom tqdm.auto import tqdm\\nfrom rich.tree import Tree\\nfrom functools import partial\\nfrom numerapi import NumerAPI\\nimport pandas_datareader as web\\nimport matplotlib.pyplot as plt\\nfrom google.cloud import storage\\nfrom rich.console import Console\\nfrom typeguard import typechecked\\nfrom datetime import datetime as dt\\nfrom pathlib import Path, PosixPath\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom dateutil.relativedelta import relativedelta\\nfrom pandas_datareader._utils import RemoteDataError\\n\\nfrom numerblox.numerframe import NumerFrame\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import finnhub\n",
    "import concurrent\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from rich.tree import Tree\n",
    "from functools import partial\n",
    "from numerapi import NumerAPI\n",
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import storage\n",
    "from rich.console import Console\n",
    "from typeguard import typechecked\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path, PosixPath\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pandas_datareader._utils import RemoteDataError\n",
    "\n",
    "from numerblox.numerframe import NumerFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. BaseIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are common methods needed for `Downloaders` and `Submittors`. `BaseIO` implements this functionality and allows us to make abstract base classes. Namely, `BaseDownloader` and `BaseSubmitter` (implemented in `submission` section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass BaseIO(ABC):\\n    \\\"\\\"\\\"\\n    Basic functionality for IO (downloading and uploading).\\n\\n    :param directory_path: Base folder for IO. Will be created if it does not exist.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str):\\n        self.dir = Path(directory_path)\\n        self._create_directory()\\n\\n    def remove_base_directory(self):\\n        \\\"\\\"\\\"Remove directory with all contents.\\\"\\\"\\\"\\n        abs_path = self.dir.resolve()\\n        rich_print(\\n            f\\\":warning: [red]Deleting directory for '{self.__class__.__name__}[/red]' :warning:\\\\nPath: '{abs_path}'\\\"\\n        )\\n        shutil.rmtree(abs_path)\\n\\n    def download_file_from_gcs(self, bucket_name: str, gcs_path: str):\\n        \\\"\\\"\\\"\\n        Get file from GCS bucket and download to local directory.\\n        :param gcs_path: Path to file on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob_path = str(self.dir.resolve())\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\\n        blob.download_to_filename(gcs_path)\\n        rich_print(\\n            f\\\":cloud: :page_facing_up: Downloaded GCS object '{gcs_path}' from bucket '{blob.bucket.id}' to local directory '{blob_path}'. :page_facing_up: :cloud:\\\"\\n        )\\n\\n    def upload_file_to_gcs(self, bucket_name: str, gcs_path: str, local_path: str):\\n        \\\"\\\"\\\"\\n        Upload file to some GCS bucket.\\n        :param gcs_path: Path to file on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\\n        blob.upload_from_filename(local_path)\\n        rich_print(\\n            f\\\":cloud: :page_facing_up: Local file '{local_path}' uploaded to '{gcs_path}' in bucket {blob.bucket.id}:page_facing_up: :cloud:\\\"\\n        )\\n\\n    def download_directory_from_gcs(self, bucket_name: str, gcs_path: str):\\n        \\\"\\\"\\\"\\n        Copy full directory from GCS bucket to local environment.\\n        :param gcs_path: Name of directory on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob_path = str(self.dir.resolve())\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\\n        for gcs_file in glob.glob(gcs_path + \\\"/**\\\", recursive=True):\\n            if os.path.isfile(gcs_file):\\n                blob.download_to_filename(blob_path)\\n        rich_print(\\n            f\\\":cloud: :folder: Directory '{gcs_path}' from bucket '{blob.bucket.id}' downloaded to '{blob_path}' :folder: :cloud:\\\"\\n        )\\n\\n    def upload_directory_to_gcs(self, bucket_name: str, gcs_path: str):\\n        \\\"\\\"\\\"\\n        Upload full base directory to GCS bucket.\\n        :param gcs_path: Name of directory on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\\n        for local_path in glob.glob(str(self.dir) + \\\"/**\\\", recursive=True):\\n            if os.path.isfile(local_path):\\n                blob.upload_from_filename(local_path)\\n        rich_print(\\n            f\\\":cloud: :folder: Directory '{self.dir}' uploaded to '{gcs_path}' in bucket {blob.bucket.id} :folder: :cloud:\\\"\\n        )\\n\\n    def _get_gcs_blob(self, bucket_name: str, blob_path: str) -> storage.Blob:\\n        \\\"\\\"\\\" Create blob that interacts with Google Cloud Storage (GCS). \\\"\\\"\\\"\\n        client = storage.Client()\\n        # https://console.cloud.google.com/storage/browser/[bucket_name]\\n        bucket = client.get_bucket(bucket_name)\\n        blob = bucket.blob(blob_path)\\n        return blob\\n\\n    def _append_folder(self, folder: str) -> Path:\\n        \\\"\\\"\\\"\\n        Return base directory Path object appended with 'folder'.\\n        Create directory if it does not exist.\\n        \\\"\\\"\\\"\\n        dir = Path(self.dir / folder)\\n        dir.mkdir(parents=True, exist_ok=True)\\n        return dir\\n\\n    def _create_directory(self):\\n        \\\"\\\"\\\" Create base directory if it does not exist. \\\"\\\"\\\"\\n        if not self.dir.is_dir():\\n            rich_print(\\n                f\\\"No existing directory found at '[blue]{self.dir}[/blue]'. Creating directory...\\\"\\n            )\\n            self.dir.mkdir(parents=True, exist_ok=True)\\n\\n    @property\\n    def get_all_files(self) -> list:\\n        \\\"\\\"\\\" Return all paths of contents in directory. \\\"\\\"\\\"\\n        return list(self.dir.iterdir())\\n\\n    @property\\n    def is_empty(self) -> bool:\\n        \\\"\\\"\\\" Check if directory is empty. \\\"\\\"\\\"\\n        return not bool(self.get_all_files)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass BaseIO(ABC):\\n    \\\"\\\"\\\"\\n    Basic functionality for IO (downloading and uploading).\\n\\n    :param directory_path: Base folder for IO. Will be created if it does not exist.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str):\\n        self.dir = Path(directory_path)\\n        self._create_directory()\\n\\n    def remove_base_directory(self):\\n        \\\"\\\"\\\"Remove directory with all contents.\\\"\\\"\\\"\\n        abs_path = self.dir.resolve()\\n        rich_print(\\n            f\\\":warning: [red]Deleting directory for '{self.__class__.__name__}[/red]' :warning:\\\\nPath: '{abs_path}'\\\"\\n        )\\n        shutil.rmtree(abs_path)\\n\\n    def download_file_from_gcs(self, bucket_name: str, gcs_path: str):\\n        \\\"\\\"\\\"\\n        Get file from GCS bucket and download to local directory.\\n        :param gcs_path: Path to file on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob_path = str(self.dir.resolve())\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\\n        blob.download_to_filename(gcs_path)\\n        rich_print(\\n            f\\\":cloud: :page_facing_up: Downloaded GCS object '{gcs_path}' from bucket '{blob.bucket.id}' to local directory '{blob_path}'. :page_facing_up: :cloud:\\\"\\n        )\\n\\n    def upload_file_to_gcs(self, bucket_name: str, gcs_path: str, local_path: str):\\n        \\\"\\\"\\\"\\n        Upload file to some GCS bucket.\\n        :param gcs_path: Path to file on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\\n        blob.upload_from_filename(local_path)\\n        rich_print(\\n            f\\\":cloud: :page_facing_up: Local file '{local_path}' uploaded to '{gcs_path}' in bucket {blob.bucket.id}:page_facing_up: :cloud:\\\"\\n        )\\n\\n    def download_directory_from_gcs(self, bucket_name: str, gcs_path: str):\\n        \\\"\\\"\\\"\\n        Copy full directory from GCS bucket to local environment.\\n        :param gcs_path: Name of directory on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob_path = str(self.dir.resolve())\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\\n        for gcs_file in glob.glob(gcs_path + \\\"/**\\\", recursive=True):\\n            if os.path.isfile(gcs_file):\\n                blob.download_to_filename(blob_path)\\n        rich_print(\\n            f\\\":cloud: :folder: Directory '{gcs_path}' from bucket '{blob.bucket.id}' downloaded to '{blob_path}' :folder: :cloud:\\\"\\n        )\\n\\n    def upload_directory_to_gcs(self, bucket_name: str, gcs_path: str):\\n        \\\"\\\"\\\"\\n        Upload full base directory to GCS bucket.\\n        :param gcs_path: Name of directory on GCS bucket.\\n        \\\"\\\"\\\"\\n        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\\n        for local_path in glob.glob(str(self.dir) + \\\"/**\\\", recursive=True):\\n            if os.path.isfile(local_path):\\n                blob.upload_from_filename(local_path)\\n        rich_print(\\n            f\\\":cloud: :folder: Directory '{self.dir}' uploaded to '{gcs_path}' in bucket {blob.bucket.id} :folder: :cloud:\\\"\\n        )\\n\\n    def _get_gcs_blob(self, bucket_name: str, blob_path: str) -> storage.Blob:\\n        \\\"\\\"\\\"Create blob that interacts with Google Cloud Storage (GCS).\\\"\\\"\\\"\\n        client = storage.Client()\\n        # https://console.cloud.google.com/storage/browser/[bucket_name]\\n        bucket = client.get_bucket(bucket_name)\\n        blob = bucket.blob(blob_path)\\n        return blob\\n\\n    def _append_folder(self, folder: str) -> Path:\\n        \\\"\\\"\\\"\\n        Return base directory Path object appended with 'folder'.\\n        Create directory if it does not exist.\\n        \\\"\\\"\\\"\\n        dir = Path(self.dir / folder)\\n        dir.mkdir(parents=True, exist_ok=True)\\n        return dir\\n\\n    def _create_directory(self):\\n        \\\"\\\"\\\"Create base directory if it does not exist.\\\"\\\"\\\"\\n        if not self.dir.is_dir():\\n            rich_print(\\n                f\\\"No existing directory found at '[blue]{self.dir}[/blue]'. Creating directory...\\\"\\n            )\\n            self.dir.mkdir(parents=True, exist_ok=True)\\n\\n    @property\\n    def get_all_files(self) -> list:\\n        \\\"\\\"\\\"Return all paths of contents in directory.\\\"\\\"\\\"\\n        return list(self.dir.iterdir())\\n\\n    @property\\n    def is_empty(self) -> bool:\\n        \\\"\\\"\\\"Check if directory is empty.\\\"\\\"\\\"\\n        return not bool(self.get_all_files)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class BaseIO(ABC):\n",
    "    \"\"\"\n",
    "    Basic functionality for IO (downloading and uploading).\n",
    "\n",
    "    :param directory_path: Base folder for IO. Will be created if it does not exist.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        self.dir = Path(directory_path)\n",
    "        self._create_directory()\n",
    "\n",
    "    def remove_base_directory(self):\n",
    "        \"\"\"Remove directory with all contents.\"\"\"\n",
    "        abs_path = self.dir.resolve()\n",
    "        rich_print(\n",
    "            f\":warning: [red]Deleting directory for '{self.__class__.__name__}[/red]' :warning:\\nPath: '{abs_path}'\"\n",
    "        )\n",
    "        shutil.rmtree(abs_path)\n",
    "\n",
    "    def download_file_from_gcs(self, bucket_name: str, gcs_path: str):\n",
    "        \"\"\"\n",
    "        Get file from GCS bucket and download to local directory.\n",
    "        :param gcs_path: Path to file on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob_path = str(self.dir.resolve())\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\n",
    "        blob.download_to_filename(gcs_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :page_facing_up: Downloaded GCS object '{gcs_path}' from bucket '{blob.bucket.id}' to local directory '{blob_path}'. :page_facing_up: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def upload_file_to_gcs(self, bucket_name: str, gcs_path: str, local_path: str):\n",
    "        \"\"\"\n",
    "        Upload file to some GCS bucket.\n",
    "        :param gcs_path: Path to file on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\n",
    "        blob.upload_from_filename(local_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :page_facing_up: Local file '{local_path}' uploaded to '{gcs_path}' in bucket {blob.bucket.id}:page_facing_up: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def download_directory_from_gcs(self, bucket_name: str, gcs_path: str):\n",
    "        \"\"\"\n",
    "        Copy full directory from GCS bucket to local environment.\n",
    "        :param gcs_path: Name of directory on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob_path = str(self.dir.resolve())\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=blob_path)\n",
    "        for gcs_file in glob.glob(gcs_path + \"/**\", recursive=True):\n",
    "            if os.path.isfile(gcs_file):\n",
    "                blob.download_to_filename(blob_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :folder: Directory '{gcs_path}' from bucket '{blob.bucket.id}' downloaded to '{blob_path}' :folder: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def upload_directory_to_gcs(self, bucket_name: str, gcs_path: str):\n",
    "        \"\"\"\n",
    "        Upload full base directory to GCS bucket.\n",
    "        :param gcs_path: Name of directory on GCS bucket.\n",
    "        \"\"\"\n",
    "        blob = self._get_gcs_blob(bucket_name=bucket_name, blob_path=gcs_path)\n",
    "        for local_path in glob.glob(str(self.dir) + \"/**\", recursive=True):\n",
    "            if os.path.isfile(local_path):\n",
    "                blob.upload_from_filename(local_path)\n",
    "        rich_print(\n",
    "            f\":cloud: :folder: Directory '{self.dir}' uploaded to '{gcs_path}' in bucket {blob.bucket.id} :folder: :cloud:\"\n",
    "        )\n",
    "\n",
    "    def _get_gcs_blob(self, bucket_name: str, blob_path: str) -> storage.Blob:\n",
    "        \"\"\" Create blob that interacts with Google Cloud Storage (GCS). \"\"\"\n",
    "        client = storage.Client()\n",
    "        # https://console.cloud.google.com/storage/browser/[bucket_name]\n",
    "        bucket = client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_path)\n",
    "        return blob\n",
    "\n",
    "    def _append_folder(self, folder: str) -> Path:\n",
    "        \"\"\"\n",
    "        Return base directory Path object appended with 'folder'.\n",
    "        Create directory if it does not exist.\n",
    "        \"\"\"\n",
    "        dir = Path(self.dir / folder)\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "        return dir\n",
    "\n",
    "    def _create_directory(self):\n",
    "        \"\"\" Create base directory if it does not exist. \"\"\"\n",
    "        if not self.dir.is_dir():\n",
    "            rich_print(\n",
    "                f\"No existing directory found at '[blue]{self.dir}[/blue]'. Creating directory...\"\n",
    "            )\n",
    "            self.dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @property\n",
    "    def get_all_files(self) -> list:\n",
    "        \"\"\" Return all paths of contents in directory. \"\"\"\n",
    "        return list(self.dir.iterdir())\n",
    "\n",
    "    @property\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\" Check if directory is empty. \"\"\"\n",
    "        return not bool(self.get_all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BaseDownloader\n",
    "\n",
    "`BaseDownloader` is an object which implements logic common to all downloaders.\n",
    "\n",
    "To implement a new Downloader, you should inherit from `BaseDownloader` and be sure to implement at least methods for `.download_training_data` and `.download_inference_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass BaseDownloader(BaseIO):\\n    \\\"\\\"\\\"\\n    Abstract base class for downloaders.\\n\\n    :param directory_path: Base folder to download files to.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str):\\n        super().__init__(directory_path=directory_path)\\n\\n    @abstractmethod\\n    def download_training_data(self, *args, **kwargs):\\n        \\\"\\\"\\\" Download all necessary files needed for training. \\\"\\\"\\\"\\n        ...\\n\\n    @abstractmethod\\n    def download_inference_data(self, *args, **kwargs):\\n        \\\"\\\"\\\" Download minimal amount of files needed for weekly inference. \\\"\\\"\\\"\\n        ...\\n\\n    @staticmethod\\n    def _load_json(file_path: str, verbose=False, *args, **kwargs) -> dict:\\n        \\\"\\\"\\\" Load JSON from file and return as dictionary. \\\"\\\"\\\"\\n        with open(Path(file_path)) as json_file:\\n            json_data = json.load(json_file, *args, **kwargs)\\n        if verbose:\\n            rich_print(json_data)\\n        return json_data\\n\\n    def __call__(self, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        The most common use case will be to get weekly inference data. So calling the class itself returns inference data.\\n        \\\"\\\"\\\"\\n        self.download_inference_data(*args, **kwargs)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass BaseDownloader(BaseIO):\\n    \\\"\\\"\\\"\\n    Abstract base class for downloaders.\\n\\n    :param directory_path: Base folder to download files to.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str):\\n        super().__init__(directory_path=directory_path)\\n\\n    @abstractmethod\\n    def download_training_data(self, *args, **kwargs):\\n        \\\"\\\"\\\"Download all necessary files needed for training.\\\"\\\"\\\"\\n        ...\\n\\n    @abstractmethod\\n    def download_inference_data(self, *args, **kwargs):\\n        \\\"\\\"\\\"Download minimal amount of files needed for weekly inference.\\\"\\\"\\\"\\n        ...\\n\\n    @staticmethod\\n    def _load_json(file_path: str, verbose=False, *args, **kwargs) -> dict:\\n        \\\"\\\"\\\"Load JSON from file and return as dictionary.\\\"\\\"\\\"\\n        with open(Path(file_path)) as json_file:\\n            json_data = json.load(json_file, *args, **kwargs)\\n        if verbose:\\n            rich_print(json_data)\\n        return json_data\\n\\n    def __call__(self, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        The most common use case will be to get weekly inference data. So calling the class itself returns inference data.\\n        \\\"\\\"\\\"\\n        self.download_inference_data(*args, **kwargs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class BaseDownloader(BaseIO):\n",
    "    \"\"\"\n",
    "    Abstract base class for downloaders.\n",
    "\n",
    "    :param directory_path: Base folder to download files to.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "\n",
    "    @abstractmethod\n",
    "    def download_training_data(self, *args, **kwargs):\n",
    "        \"\"\" Download all necessary files needed for training. \"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def download_inference_data(self, *args, **kwargs):\n",
    "        \"\"\" Download minimal amount of files needed for weekly inference. \"\"\"\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_json(file_path: str, verbose=False, *args, **kwargs) -> dict:\n",
    "        \"\"\" Load JSON from file and return as dictionary. \"\"\"\n",
    "        with open(Path(file_path)) as json_file:\n",
    "            json_data = json.load(json_file, *args, **kwargs)\n",
    "        if verbose:\n",
    "            rich_print(json_data)\n",
    "        return json_data\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        The most common use case will be to get weekly inference data. So calling the class itself returns inference data.\n",
    "        \"\"\"\n",
    "        self.download_inference_data(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numerai Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# export\\nclass NumeraiClassicDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    WARNING: Versions 1 and 2 (legacy data) are deprecated. Only supporting version 3+.\\n\\n    Downloading from NumerAPI for Numerai Classic data. \\\\n\\n    :param directory_path: Base folder to download files to. \\\\n\\n    All *args, **kwargs will be passed to NumerAPI initialization.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str, *args, **kwargs):\\n        super().__init__(directory_path=directory_path)\\n        self.napi = NumerAPI(*args, **kwargs)\\n        self.current_round = self.napi.get_current_round()\\n        # NumerAPI filenames corresponding to version, class and data type\\n        self.version_mapping = {\\\"3\\\": {\\n            \\\"train\\\": {\\n                \\\"int8\\\": [\\n                    \\\"v3/numerai_training_data_int8.parquet\\\",\\n                    \\\"v3/numerai_validation_data_int8.parquet\\\"\\n                ],\\n                \\\"float\\\": [\\n                    \\\"v3/numerai_training_data.parquet\\\",\\n                    \\\"v3/numerai_validation_data.parquet\\\"\\n                ]\\n            },\\n            \\\"inference\\\": {\\n                \\\"int8\\\": [\\\"v3/numerai_tournament_data_int8.parquet\\\"],\\n                \\\"float\\\": [\\\"v3/numerai_tournament_data.parquet\\\"]\\n            },\\n            \\\"live\\\": {\\n                \\\"int8\\\": [\\\"v3/numerai_live_data_int8.parquet\\\"],\\n                \\\"float\\\": [\\\"v3/numerai_live_data.parquet\\\"]\\n            },\\n            \\\"example\\\": [\\n                \\\"v3/example_predictions.parquet\\\",\\n                \\\"v3/example_validation_predictions.parquet\\\"\\n            ]\\n        },\\n            \\\"4\\\": {\\n                \\\"train\\\": {\\n                    \\\"int8\\\": [\\n                        \\\"v4/train_int8.parquet\\\",\\n                        \\\"v4/validation_int8.parquet\\\"\\n                    ],\\n                    \\\"float\\\": [\\n                        \\\"v4/train.parquet\\\",\\n                        \\\"v4/validation.parquet\\\"\\n                    ]\\n                },\\n                \\\"inference\\\": {\\n                    \\\"int8\\\": [\\\"v4/live_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v4/live.parquet\\\"]\\n                },\\n                \\\"live\\\": {\\n                    \\\"int8\\\": [\\\"v4/live_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v4/live.parquet\\\"]\\n                },\\n                \\\"example\\\": [\\n                    \\\"v4/live_example_preds.parquet\\\",\\n                    \\\"v4/validation_example_preds.parquet\\\"\\n                ]\\n            }\\n        }\\n\\n    def download_training_data(\\n        self, subfolder: str = \\\"\\\", version: int = 4, int8: bool = False\\n    ):\\n        \\\"\\\"\\\"\\n        Get Numerai classic training and validation data.\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param version: Numerai dataset version (3=1050+ features dataset (parquet))\\n        :param int8: Integer version of data\\n        \\\"\\\"\\\"\\n        data_type = \\\"int8\\\" if int8 else \\\"float\\\"\\n        train_val_files = self._get_version_mapping(version)[\\\"train\\\"][data_type]\\n        for file in train_val_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file,\\n                dest_path=dest_path\\n            )\\n\\n    def download_inference_data(\\n        self,\\n        subfolder: str = \\\"\\\",\\n        version: int = 4,\\n        int8: bool = False,\\n        round_num: int = None,\\n    ):\\n        \\\"\\\"\\\"\\n        Get Numerai classic inference (tournament) data.\\n        If only minimal live data is needed, consider .download_live_data.\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param version: Numerai dataset version (2=super massive dataset (parquet))\\n        :param int8: Integer version of data\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        data_type = \\\"int8\\\" if int8 else \\\"float\\\"\\n        inference_files = self._get_version_mapping(version)[\\\"inference\\\"][data_type]\\n        for file in inference_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file,\\n                dest_path=dest_path,\\n                round_num=round_num\\n            )\\n\\n    def download_single_dataset(\\n        self, filename: str, dest_path: str, round_num: int = None\\n    ):\\n        \\\"\\\"\\\"\\n        Download one of the available datasets through NumerAPI.\\n\\n        :param filename: Name as listed in NumerAPI (Check NumerAPI().list_datasets() for full overview)\\n        :param dest_path: Full path where file will be saved.\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        rich_print(\\n            f\\\":file_folder: [green]Downloading[/green] '{filename}' :file_folder:\\\"\\n        )\\n        self.napi.download_dataset(\\n            filename=filename,\\n            dest_path=dest_path,\\n            round_num=round_num\\n        )\\n\\n    def download_live_data(\\n            self,\\n            subfolder: str = \\\"\\\",\\n            version: int = 4,\\n            int8: bool = False,\\n            round_num: int = None\\n    ):\\n        \\\"\\\"\\\"\\n        Download all live data in specified folder for given version (i.e. minimal data needed for inference).\\n\\n        :param subfolder: Specify folder to create folder within directory root.\\n        Saves in directory root by default.\\n        :param version: Numerai dataset version (2=super massive dataset (parquet))\\n        :param int8: Integer version of data\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        data_type = \\\"int8\\\" if int8 else \\\"float\\\"\\n        live_files = self._get_version_mapping(version)[\\\"live\\\"][data_type]\\n        for file in live_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file,\\n                dest_path=dest_path,\\n                round_num=round_num\\n            )\\n\\n    def download_example_data(\\n        self, subfolder: str = \\\"\\\", version: int = 4, round_num: int = None\\n    ):\\n        \\\"\\\"\\\"\\n        Download all example prediction data in specified folder for given version.\\n\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param version: Numerai dataset version (2=super massive dataset (parquet))\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        example_files = self._get_version_mapping(version)[\\\"example\\\"]\\n        for file in example_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file,\\n                dest_path=dest_path,\\n                round_num=round_num\\n            )\\n\\n    def get_classic_features(self, subfolder: str = \\\"\\\", filename=\\\"v4/features.json\\\", *args, **kwargs) -> dict:\\n        \\\"\\\"\\\"\\n        Download feature overview (stats and feature sets) through NumerAPI and load as dict.\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param filename: name for feature overview.\\n        Currently defined as 'features.json' in NumerAPI and used as default.\\n        *args, **kwargs will be passed to the JSON loader.\\n        \\\"\\\"\\\"\\n        dest_path = self.__get_dest_path(subfolder, filename)\\n        self.download_single_dataset(filename=filename,\\n                                     dest_path=dest_path)\\n        json_data = self._load_json(dest_path, *args, **kwargs)\\n        return json_data\\n\\n    def _get_version_mapping(self, version: int) -> dict:\\n        \\\"\\\"\\\" Check if data version is supported and return file mapping for version. \\\"\\\"\\\"\\n        try:\\n            mapping_dictionary = self.version_mapping[str(version)]\\n        except KeyError:\\n            raise NotImplementedError(\\n                f\\\"Version '{version}' is not available. Available versions are {list(self.version_mapping.keys())}\\\"\\n            )\\n        return mapping_dictionary\\n\\n    def __get_dest_path(self, subfolder: str, filename: str) -> str:\\n        \\\"\\\"\\\" Prepare destination path for downloading. \\\"\\\"\\\"\\n        dir = self._append_folder(subfolder)\\n        dest_path = str(dir.joinpath(filename.split(\\\"/\\\")[-1]))\\n        return dest_path\";\n                var nbb_formatted_code = \"# export\\nclass NumeraiClassicDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    WARNING: Versions 1 and 2 (legacy data) are deprecated. Only supporting version 3+.\\n\\n    Downloading from NumerAPI for Numerai Classic data. \\\\n\\n    :param directory_path: Base folder to download files to. \\\\n\\n    All *args, **kwargs will be passed to NumerAPI initialization.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, *args, **kwargs):\\n        super().__init__(directory_path=directory_path)\\n        self.napi = NumerAPI(*args, **kwargs)\\n        self.current_round = self.napi.get_current_round()\\n        # NumerAPI filenames corresponding to version, class and data type\\n        self.version_mapping = {\\n            \\\"3\\\": {\\n                \\\"train\\\": {\\n                    \\\"int8\\\": [\\n                        \\\"v3/numerai_training_data_int8.parquet\\\",\\n                        \\\"v3/numerai_validation_data_int8.parquet\\\",\\n                    ],\\n                    \\\"float\\\": [\\n                        \\\"v3/numerai_training_data.parquet\\\",\\n                        \\\"v3/numerai_validation_data.parquet\\\",\\n                    ],\\n                },\\n                \\\"inference\\\": {\\n                    \\\"int8\\\": [\\\"v3/numerai_tournament_data_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v3/numerai_tournament_data.parquet\\\"],\\n                },\\n                \\\"live\\\": {\\n                    \\\"int8\\\": [\\\"v3/numerai_live_data_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v3/numerai_live_data.parquet\\\"],\\n                },\\n                \\\"example\\\": [\\n                    \\\"v3/example_predictions.parquet\\\",\\n                    \\\"v3/example_validation_predictions.parquet\\\",\\n                ],\\n            },\\n            \\\"4\\\": {\\n                \\\"train\\\": {\\n                    \\\"int8\\\": [\\\"v4/train_int8.parquet\\\", \\\"v4/validation_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v4/train.parquet\\\", \\\"v4/validation.parquet\\\"],\\n                },\\n                \\\"inference\\\": {\\n                    \\\"int8\\\": [\\\"v4/live_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v4/live.parquet\\\"],\\n                },\\n                \\\"live\\\": {\\n                    \\\"int8\\\": [\\\"v4/live_int8.parquet\\\"],\\n                    \\\"float\\\": [\\\"v4/live.parquet\\\"],\\n                },\\n                \\\"example\\\": [\\n                    \\\"v4/live_example_preds.parquet\\\",\\n                    \\\"v4/validation_example_preds.parquet\\\",\\n                ],\\n            },\\n        }\\n\\n    def download_training_data(\\n        self, subfolder: str = \\\"\\\", version: int = 4, int8: bool = False\\n    ):\\n        \\\"\\\"\\\"\\n        Get Numerai classic training and validation data.\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param version: Numerai dataset version (3=1050+ features dataset (parquet))\\n        :param int8: Integer version of data\\n        \\\"\\\"\\\"\\n        data_type = \\\"int8\\\" if int8 else \\\"float\\\"\\n        train_val_files = self._get_version_mapping(version)[\\\"train\\\"][data_type]\\n        for file in train_val_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(filename=file, dest_path=dest_path)\\n\\n    def download_inference_data(\\n        self,\\n        subfolder: str = \\\"\\\",\\n        version: int = 4,\\n        int8: bool = False,\\n        round_num: int = None,\\n    ):\\n        \\\"\\\"\\\"\\n        Get Numerai classic inference (tournament) data.\\n        If only minimal live data is needed, consider .download_live_data.\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param version: Numerai dataset version (2=super massive dataset (parquet))\\n        :param int8: Integer version of data\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        data_type = \\\"int8\\\" if int8 else \\\"float\\\"\\n        inference_files = self._get_version_mapping(version)[\\\"inference\\\"][data_type]\\n        for file in inference_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file, dest_path=dest_path, round_num=round_num\\n            )\\n\\n    def download_single_dataset(\\n        self, filename: str, dest_path: str, round_num: int = None\\n    ):\\n        \\\"\\\"\\\"\\n        Download one of the available datasets through NumerAPI.\\n\\n        :param filename: Name as listed in NumerAPI (Check NumerAPI().list_datasets() for full overview)\\n        :param dest_path: Full path where file will be saved.\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        rich_print(\\n            f\\\":file_folder: [green]Downloading[/green] '{filename}' :file_folder:\\\"\\n        )\\n        self.napi.download_dataset(\\n            filename=filename, dest_path=dest_path, round_num=round_num\\n        )\\n\\n    def download_live_data(\\n        self,\\n        subfolder: str = \\\"\\\",\\n        version: int = 4,\\n        int8: bool = False,\\n        round_num: int = None,\\n    ):\\n        \\\"\\\"\\\"\\n        Download all live data in specified folder for given version (i.e. minimal data needed for inference).\\n\\n        :param subfolder: Specify folder to create folder within directory root.\\n        Saves in directory root by default.\\n        :param version: Numerai dataset version (2=super massive dataset (parquet))\\n        :param int8: Integer version of data\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        data_type = \\\"int8\\\" if int8 else \\\"float\\\"\\n        live_files = self._get_version_mapping(version)[\\\"live\\\"][data_type]\\n        for file in live_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file, dest_path=dest_path, round_num=round_num\\n            )\\n\\n    def download_example_data(\\n        self, subfolder: str = \\\"\\\", version: int = 4, round_num: int = None\\n    ):\\n        \\\"\\\"\\\"\\n        Download all example prediction data in specified folder for given version.\\n\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param version: Numerai dataset version (2=super massive dataset (parquet))\\n        :param round_num: Numerai tournament round number. Downloads latest round by default.\\n        \\\"\\\"\\\"\\n        example_files = self._get_version_mapping(version)[\\\"example\\\"]\\n        for file in example_files:\\n            dest_path = self.__get_dest_path(subfolder, file)\\n            self.download_single_dataset(\\n                filename=file, dest_path=dest_path, round_num=round_num\\n            )\\n\\n    def get_classic_features(\\n        self, subfolder: str = \\\"\\\", filename=\\\"v4/features.json\\\", *args, **kwargs\\n    ) -> dict:\\n        \\\"\\\"\\\"\\n        Download feature overview (stats and feature sets) through NumerAPI and load as dict.\\n        :param subfolder: Specify folder to create folder within base directory root.\\n        Saves in base directory root by default.\\n        :param filename: name for feature overview.\\n        Currently defined as 'features.json' in NumerAPI and used as default.\\n        *args, **kwargs will be passed to the JSON loader.\\n        \\\"\\\"\\\"\\n        dest_path = self.__get_dest_path(subfolder, filename)\\n        self.download_single_dataset(filename=filename, dest_path=dest_path)\\n        json_data = self._load_json(dest_path, *args, **kwargs)\\n        return json_data\\n\\n    def _get_version_mapping(self, version: int) -> dict:\\n        \\\"\\\"\\\"Check if data version is supported and return file mapping for version.\\\"\\\"\\\"\\n        try:\\n            mapping_dictionary = self.version_mapping[str(version)]\\n        except KeyError:\\n            raise NotImplementedError(\\n                f\\\"Version '{version}' is not available. Available versions are {list(self.version_mapping.keys())}\\\"\\n            )\\n        return mapping_dictionary\\n\\n    def __get_dest_path(self, subfolder: str, filename: str) -> str:\\n        \\\"\\\"\\\"Prepare destination path for downloading.\\\"\\\"\\\"\\n        dir = self._append_folder(subfolder)\\n        dest_path = str(dir.joinpath(filename.split(\\\"/\\\")[-1]))\\n        return dest_path\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class NumeraiClassicDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    WARNING: Versions 1 and 2 (legacy data) are deprecated. Only supporting version 3+.\n",
    "\n",
    "    Downloading from NumerAPI for Numerai Classic data. \\n\n",
    "    :param directory_path: Base folder to download files to. \\n\n",
    "    All *args, **kwargs will be passed to NumerAPI initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str, *args, **kwargs):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "        self.napi = NumerAPI(*args, **kwargs)\n",
    "        self.current_round = self.napi.get_current_round()\n",
    "        # NumerAPI filenames corresponding to version, class and data type\n",
    "        self.version_mapping = {\"3\": {\n",
    "            \"train\": {\n",
    "                \"int8\": [\n",
    "                    \"v3/numerai_training_data_int8.parquet\",\n",
    "                    \"v3/numerai_validation_data_int8.parquet\"\n",
    "                ],\n",
    "                \"float\": [\n",
    "                    \"v3/numerai_training_data.parquet\",\n",
    "                    \"v3/numerai_validation_data.parquet\"\n",
    "                ]\n",
    "            },\n",
    "            \"inference\": {\n",
    "                \"int8\": [\"v3/numerai_tournament_data_int8.parquet\"],\n",
    "                \"float\": [\"v3/numerai_tournament_data.parquet\"]\n",
    "            },\n",
    "            \"live\": {\n",
    "                \"int8\": [\"v3/numerai_live_data_int8.parquet\"],\n",
    "                \"float\": [\"v3/numerai_live_data.parquet\"]\n",
    "            },\n",
    "            \"example\": [\n",
    "                \"v3/example_predictions.parquet\",\n",
    "                \"v3/example_validation_predictions.parquet\"\n",
    "            ]\n",
    "        },\n",
    "            \"4\": {\n",
    "                \"train\": {\n",
    "                    \"int8\": [\n",
    "                        \"v4/train_int8.parquet\",\n",
    "                        \"v4/validation_int8.parquet\"\n",
    "                    ],\n",
    "                    \"float\": [\n",
    "                        \"v4/train.parquet\",\n",
    "                        \"v4/validation.parquet\"\n",
    "                    ]\n",
    "                },\n",
    "                \"inference\": {\n",
    "                    \"int8\": [\"v4/live_int8.parquet\"],\n",
    "                    \"float\": [\"v4/live.parquet\"]\n",
    "                },\n",
    "                \"live\": {\n",
    "                    \"int8\": [\"v4/live_int8.parquet\"],\n",
    "                    \"float\": [\"v4/live.parquet\"]\n",
    "                },\n",
    "                \"example\": [\n",
    "                    \"v4/live_example_preds.parquet\",\n",
    "                    \"v4/validation_example_preds.parquet\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def download_training_data(\n",
    "        self, subfolder: str = \"\", version: int = 4, int8: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get Numerai classic training and validation data.\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param version: Numerai dataset version (3=1050+ features dataset (parquet))\n",
    "        :param int8: Integer version of data\n",
    "        \"\"\"\n",
    "        data_type = \"int8\" if int8 else \"float\"\n",
    "        train_val_files = self._get_version_mapping(version)[\"train\"][data_type]\n",
    "        for file in train_val_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path\n",
    "            )\n",
    "\n",
    "    def download_inference_data(\n",
    "        self,\n",
    "        subfolder: str = \"\",\n",
    "        version: int = 4,\n",
    "        int8: bool = False,\n",
    "        round_num: int = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get Numerai classic inference (tournament) data.\n",
    "        If only minimal live data is needed, consider .download_live_data.\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param version: Numerai dataset version (2=super massive dataset (parquet))\n",
    "        :param int8: Integer version of data\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        data_type = \"int8\" if int8 else \"float\"\n",
    "        inference_files = self._get_version_mapping(version)[\"inference\"][data_type]\n",
    "        for file in inference_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path,\n",
    "                round_num=round_num\n",
    "            )\n",
    "\n",
    "    def download_single_dataset(\n",
    "        self, filename: str, dest_path: str, round_num: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Download one of the available datasets through NumerAPI.\n",
    "\n",
    "        :param filename: Name as listed in NumerAPI (Check NumerAPI().list_datasets() for full overview)\n",
    "        :param dest_path: Full path where file will be saved.\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        rich_print(\n",
    "            f\":file_folder: [green]Downloading[/green] '{filename}' :file_folder:\"\n",
    "        )\n",
    "        self.napi.download_dataset(\n",
    "            filename=filename,\n",
    "            dest_path=dest_path,\n",
    "            round_num=round_num\n",
    "        )\n",
    "\n",
    "    def download_live_data(\n",
    "            self,\n",
    "            subfolder: str = \"\",\n",
    "            version: int = 4,\n",
    "            int8: bool = False,\n",
    "            round_num: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Download all live data in specified folder for given version (i.e. minimal data needed for inference).\n",
    "\n",
    "        :param subfolder: Specify folder to create folder within directory root.\n",
    "        Saves in directory root by default.\n",
    "        :param version: Numerai dataset version (2=super massive dataset (parquet))\n",
    "        :param int8: Integer version of data\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        data_type = \"int8\" if int8 else \"float\"\n",
    "        live_files = self._get_version_mapping(version)[\"live\"][data_type]\n",
    "        for file in live_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path,\n",
    "                round_num=round_num\n",
    "            )\n",
    "\n",
    "    def download_example_data(\n",
    "        self, subfolder: str = \"\", version: int = 4, round_num: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Download all example prediction data in specified folder for given version.\n",
    "\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param version: Numerai dataset version (2=super massive dataset (parquet))\n",
    "        :param round_num: Numerai tournament round number. Downloads latest round by default.\n",
    "        \"\"\"\n",
    "        example_files = self._get_version_mapping(version)[\"example\"]\n",
    "        for file in example_files:\n",
    "            dest_path = self.__get_dest_path(subfolder, file)\n",
    "            self.download_single_dataset(\n",
    "                filename=file,\n",
    "                dest_path=dest_path,\n",
    "                round_num=round_num\n",
    "            )\n",
    "\n",
    "    def get_classic_features(self, subfolder: str = \"\", filename=\"v4/features.json\", *args, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Download feature overview (stats and feature sets) through NumerAPI and load as dict.\n",
    "        :param subfolder: Specify folder to create folder within base directory root.\n",
    "        Saves in base directory root by default.\n",
    "        :param filename: name for feature overview.\n",
    "        Currently defined as 'features.json' in NumerAPI and used as default.\n",
    "        *args, **kwargs will be passed to the JSON loader.\n",
    "        \"\"\"\n",
    "        dest_path = self.__get_dest_path(subfolder, filename)\n",
    "        self.download_single_dataset(filename=filename,\n",
    "                                     dest_path=dest_path)\n",
    "        json_data = self._load_json(dest_path, *args, **kwargs)\n",
    "        return json_data\n",
    "\n",
    "    def _get_version_mapping(self, version: int) -> dict:\n",
    "        \"\"\" Check if data version is supported and return file mapping for version. \"\"\"\n",
    "        try:\n",
    "            mapping_dictionary = self.version_mapping[str(version)]\n",
    "        except KeyError:\n",
    "            raise NotImplementedError(\n",
    "                f\"Version '{version}' is not available. Available versions are {list(self.version_mapping.keys())}\"\n",
    "            )\n",
    "        return mapping_dictionary\n",
    "\n",
    "    def __get_dest_path(self, subfolder: str, filename: str) -> str:\n",
    "        \"\"\" Prepare destination path for downloading. \"\"\"\n",
    "        dir = self._append_folder(subfolder)\n",
    "        dest_path = str(dir.joinpath(filename.split(\"/\")[-1]))\n",
    "        return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_numclassic_general\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_numclassic_general</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Directory contents:\n\u001B[1m[\u001B[0m\u001B[1;35mPath\u001B[0m\u001B[1m(\u001B[0m\u001B[32m'test_numclassic_general/test.txt'\u001B[0m\u001B[1m)\u001B[0m\u001B[1m]\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Directory contents:\n<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Path</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_numclassic_general/test.txt'</span><span style=\"font-weight: bold\">)]</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": " \u001B[32mDownloading\u001B[0m \u001B[32m'v3/example_predictions.parquet'\u001B[0m \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v3/example_predictions.parquet'</span> \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:06:47,718 INFO numerapi.utils: starting download\n",
      "test_numclassic_general/test/example_predictions.parquet: 33.5MB [00:24, 1.36MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": " \u001B[32mDownloading\u001B[0m \u001B[32m'v3/example_validation_predictions.parquet'\u001B[0m \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v3/example_validation_predictions.parquet'</span> \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:07:13,535 INFO numerapi.utils: starting download\n",
      "test_numclassic_general/test/example_validation_predictions.parquet: 13.0MB [00:06, 2.03MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": " \u001B[32mDownloading\u001B[0m \u001B[32m'v4/features.json'\u001B[0m \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4/features.json'</span> \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:07:21,023 INFO numerapi.utils: starting download\n",
      "test_numclassic_general/features.json: 562kB [00:00, 762kB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": " \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicDownloader\u001B[0m\u001B[32m'\u001B[0m \nPath: \n\u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_numclassic_general'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> \nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_numclassic_general'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# hide\\n# slow\\ntest_dir_classic = \\\"test_numclassic_general\\\"\\nnumer_classic_downloader = NumeraiClassicDownloader(test_dir_classic)\\n\\n# Test building class\\nassert isinstance(numer_classic_downloader.dir, PosixPath)\\nassert numer_classic_downloader.dir.is_dir()\\n\\n# Test is_empty\\n(numer_classic_downloader.dir / \\\"test.txt\\\").write_text(\\\"test\\\")\\nrich_print(f\\\"Directory contents:\\\\n{numer_classic_downloader.get_all_files}\\\")\\nassert not numer_classic_downloader.is_empty\\n\\n# Downloading example data\\nnumer_classic_downloader.download_example_data(\\\"test/\\\", version=3, round_num=310)\\n\\n# Features\\nfeature_stats_test = numer_classic_downloader.get_classic_features()\\nassert isinstance(feature_stats_test, dict)\\nassert len(feature_stats_test[\\\"feature_sets\\\"][\\\"medium\\\"]) == 472\\n\\n# Remove contents\\nnumer_classic_downloader.remove_base_directory()\\nassert not os.path.exists(test_dir_classic)\";\n                var nbb_formatted_code = \"# hide\\n# slow\\ntest_dir_classic = \\\"test_numclassic_general\\\"\\nnumer_classic_downloader = NumeraiClassicDownloader(test_dir_classic)\\n\\n# Test building class\\nassert isinstance(numer_classic_downloader.dir, PosixPath)\\nassert numer_classic_downloader.dir.is_dir()\\n\\n# Test is_empty\\n(numer_classic_downloader.dir / \\\"test.txt\\\").write_text(\\\"test\\\")\\nrich_print(f\\\"Directory contents:\\\\n{numer_classic_downloader.get_all_files}\\\")\\nassert not numer_classic_downloader.is_empty\\n\\n# Downloading example data\\nnumer_classic_downloader.download_example_data(\\\"test/\\\", version=3, round_num=310)\\n\\n# Features\\nfeature_stats_test = numer_classic_downloader.get_classic_features()\\nassert isinstance(feature_stats_test, dict)\\nassert len(feature_stats_test[\\\"feature_sets\\\"][\\\"medium\\\"]) == 472\\n\\n# Remove contents\\nnumer_classic_downloader.remove_base_directory()\\nassert not os.path.exists(test_dir_classic)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# slow\n",
    "test_dir_classic = \"test_numclassic_general\"\n",
    "numer_classic_downloader = NumeraiClassicDownloader(test_dir_classic)\n",
    "\n",
    "# Test building class\n",
    "assert isinstance(numer_classic_downloader.dir, PosixPath)\n",
    "assert numer_classic_downloader.dir.is_dir()\n",
    "\n",
    "# Test is_empty\n",
    "(numer_classic_downloader.dir / \"test.txt\").write_text(\"test\")\n",
    "rich_print(f\"Directory contents:\\n{numer_classic_downloader.get_all_files}\")\n",
    "assert not numer_classic_downloader.is_empty\n",
    "\n",
    "# Downloading example data\n",
    "numer_classic_downloader.download_example_data(\"test/\", version=3, round_num=310)\n",
    "\n",
    "# Features\n",
    "feature_stats_test = numer_classic_downloader.get_classic_features()\n",
    "assert isinstance(feature_stats_test, dict)\n",
    "assert len(feature_stats_test[\"feature_sets\"][\"medium\"]) == 472\n",
    "\n",
    "# Remove contents\n",
    "numer_classic_downloader.remove_base_directory()\n",
    "assert not os.path.exists(test_dir_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This section will explain how to quickly get started with `NumeraiClassicDownloader`.\n",
    "\n",
    "The more advanced use case of working with GCS (Google Cloud Storage) is discussed in `edu_nbs/google_cloud_storage.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Training + validation data for Numerai Classic can be downloaded with effectively 2 lines of code.\n",
    "Feature stats and overview can be downloaded with `.get_classic_features()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_numclassic_train\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_numclassic_train</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": " \u001B[32mDownloading\u001B[0m \u001B[32m'v4/features.json'\u001B[0m \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4/features.json'</span> \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:07:23,822 INFO numerapi.utils: starting download\n",
      "test_numclassic_train/features.json: 562kB [00:00, 800kB/s]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": " \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicDownloader\u001B[0m\u001B[32m'\u001B[0m \nPath: \n\u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_numclassic_train'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> \nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_numclassic_train'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# slow\\n# Initialization\\ntrain_base_directory = \\\"test_numclassic_train\\\"\\nnumer_classic_downloader = NumeraiClassicDownloader(train_base_directory)\\n\\n# Uncomment line below to download training and validation data\\n# numer_classic_downloader.download_training_data(\\\"train_val\\\", int8=False)\\n\\n# Get feature overview (dict)\\nnumer_classic_downloader.get_classic_features()\\n\\n# Remove contents (To clean up environment)\\nnumer_classic_downloader.remove_base_directory()\";\n                var nbb_formatted_code = \"# slow\\n# Initialization\\ntrain_base_directory = \\\"test_numclassic_train\\\"\\nnumer_classic_downloader = NumeraiClassicDownloader(train_base_directory)\\n\\n# Uncomment line below to download training and validation data\\n# numer_classic_downloader.download_training_data(\\\"train_val\\\", int8=False)\\n\\n# Get feature overview (dict)\\nnumer_classic_downloader.get_classic_features()\\n\\n# Remove contents (To clean up environment)\\nnumer_classic_downloader.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# Initialization\n",
    "train_base_directory = \"test_numclassic_train\"\n",
    "numer_classic_downloader = NumeraiClassicDownloader(train_base_directory)\n",
    "\n",
    "# Uncomment line below to download training and validation data\n",
    "# numer_classic_downloader.download_training_data(\"train_val\", int8=False)\n",
    "\n",
    "# Get feature overview (dict)\n",
    "numer_classic_downloader.get_classic_features()\n",
    "\n",
    "# Remove contents (To clean up environment)\n",
    "numer_classic_downloader.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For the training example the directory structure will be:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": " test_numclassic_train (base_directory)                                                           \n\u001B[90m \u001B[0m features.json                                                                                \n\u001B[90m \u001B[0m train_val                                                                                    \n\u001B[90m    \u001B[0m\u001B[90m \u001B[0m numerai_training_data.parquet                                                            \n\u001B[90m    \u001B[0m\u001B[90m \u001B[0m numerai_validation_data.parquet                                                          \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> test_numclassic_train (base_directory)                                                           \n<span style=\"color: #808080; text-decoration-color: #808080\"> </span> features.json                                                                                \n<span style=\"color: #808080; text-decoration-color: #808080\"> </span> train_val                                                                                    \n<span style=\"color: #808080; text-decoration-color: #808080\">     </span> numerai_training_data.parquet                                                            \n<span style=\"color: #808080; text-decoration-color: #808080\">     </span> numerai_validation_data.parquet                                                          \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# hide_input\\nconsole = Console(record=True, width=100)\\n\\ntree = Tree(\\n    f\\\":file_folder: {train_base_directory} (base_directory)\\\",\\n    guide_style=\\\"bold bright_black\\\",\\n)\\nfolder_tree = tree.add(\\\":page_facing_up: features.json\\\")\\ntrain_val_tree = tree.add(\\\":file_folder: train_val\\\")\\ntrain_val_tree.add(\\\":page_facing_up: numerai_training_data.parquet\\\")\\ntrain_val_tree.add(\\\":page_facing_up: numerai_validation_data.parquet\\\")\\n\\nconsole.print(tree)\";\n                var nbb_formatted_code = \"# hide_input\\nconsole = Console(record=True, width=100)\\n\\ntree = Tree(\\n    f\\\":file_folder: {train_base_directory} (base_directory)\\\",\\n    guide_style=\\\"bold bright_black\\\",\\n)\\nfolder_tree = tree.add(\\\":page_facing_up: features.json\\\")\\ntrain_val_tree = tree.add(\\\":file_folder: train_val\\\")\\ntrain_val_tree.add(\\\":page_facing_up: numerai_training_data.parquet\\\")\\ntrain_val_tree.add(\\\":page_facing_up: numerai_validation_data.parquet\\\")\\n\\nconsole.print(tree)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "console = Console(record=True, width=100)\n",
    "\n",
    "tree = Tree(\n",
    "    f\":file_folder: {train_base_directory} (base_directory)\",\n",
    "    guide_style=\"bold bright_black\",\n",
    ")\n",
    "folder_tree = tree.add(\":page_facing_up: features.json\")\n",
    "train_val_tree = tree.add(\":file_folder: train_val\")\n",
    "train_val_tree.add(\":page_facing_up: numerai_training_data.parquet\")\n",
    "train_val_tree.add(\":page_facing_up: numerai_validation_data.parquet\")\n",
    "\n",
    "console.print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Inference data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inference data for the most recent round of Numerai Classic can be downloaded with effectively 2 lines of code.\n",
    "It can also easily be deleted after you are done with inference by calling `.remove_base_directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_numclassic_inference\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_numclassic_inference</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": " \u001B[32mDownloading\u001B[0m \u001B[32m'v4/live_int8.parquet'\u001B[0m \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v4/live_int8.parquet'</span> \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:07:26,979 INFO numerapi.utils: starting download\n",
      "test_numclassic_inference/inference/live_int8.parquet: 3.54MB [00:01, 2.16MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": " \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicDownloader\u001B[0m\u001B[32m'\u001B[0m \nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_numclassic_in\u001B[0m\n\u001B[32mference'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> \nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_numclassic_in</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">ference'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# slow\\n# Initialization\\ninference_base_dir = \\\"test_numclassic_inference\\\"\\nnumer_classic_downloader = NumeraiClassicDownloader(directory_path=inference_base_dir)\\n\\n# Download tournament (inference) data\\nnumer_classic_downloader.download_inference_data(\\\"inference\\\", version=4, int8=True)\\n\\n# Remove folder when done with inference\\nnumer_classic_downloader.remove_base_directory()\";\n                var nbb_formatted_code = \"# slow\\n# Initialization\\ninference_base_dir = \\\"test_numclassic_inference\\\"\\nnumer_classic_downloader = NumeraiClassicDownloader(directory_path=inference_base_dir)\\n\\n# Download tournament (inference) data\\nnumer_classic_downloader.download_inference_data(\\\"inference\\\", version=4, int8=True)\\n\\n# Remove folder when done with inference\\nnumer_classic_downloader.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# Initialization\n",
    "inference_base_dir = \"test_numclassic_inference\"\n",
    "numer_classic_downloader = NumeraiClassicDownloader(directory_path=inference_base_dir)\n",
    "\n",
    "# Download tournament (inference) data\n",
    "numer_classic_downloader.download_inference_data(\"inference\", version=4, int8=True)\n",
    "\n",
    "# Remove folder when done with inference\n",
    "numer_classic_downloader.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For the inference example the directory structure will be:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": " test_numclassic_inference (base_directory)                                                       \n\u001B[90m \u001B[0m inference                                                                                    \n\u001B[90m    \u001B[0m\u001B[90m \u001B[0m numerai_tournament_data.parquet                                                          \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> test_numclassic_inference (base_directory)                                                       \n<span style=\"color: #808080; text-decoration-color: #808080\"> </span> inference                                                                                    \n<span style=\"color: #808080; text-decoration-color: #808080\">     </span> numerai_tournament_data.parquet                                                          \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"# hide_input\\nconsole = Console(record=True, width=100)\\n\\ntree = Tree(\\n    f\\\":file_folder: {inference_base_dir} (base_directory)\\\",\\n    guide_style=\\\"bold bright_black\\\",\\n)\\ninference_tree = tree.add(\\\":file_folder: inference\\\")\\ninference_tree.add(\\\":page_facing_up: numerai_tournament_data.parquet\\\")\\n\\nconsole.print(tree)\";\n                var nbb_formatted_code = \"# hide_input\\nconsole = Console(record=True, width=100)\\n\\ntree = Tree(\\n    f\\\":file_folder: {inference_base_dir} (base_directory)\\\",\\n    guide_style=\\\"bold bright_black\\\",\\n)\\ninference_tree = tree.add(\\\":file_folder: inference\\\")\\ninference_tree.add(\\\":page_facing_up: numerai_tournament_data.parquet\\\")\\n\\nconsole.print(tree)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "console = Console(record=True, width=100)\n",
    "\n",
    "tree = Tree(\n",
    "    f\":file_folder: {inference_base_dir} (base_directory)\",\n",
    "    guide_style=\"bold bright_black\",\n",
    ")\n",
    "inference_tree = tree.add(\":file_folder: inference\")\n",
    "inference_tree.add(\":page_facing_up: numerai_tournament_data.parquet\")\n",
    "\n",
    "console.print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. KaggleDownloader (Numerai Signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Numerai community maintains some excellent datasets on Kaggle for Numerai Signals.\n",
    "\n",
    "For example, [Katsu1110](https://www.kaggle.com/code1110) maintains a [dataset with yfinance price data](https://www.kaggle.com/code1110/yfinance-stock-price-data-for-numerai-signals) on Kaggle that is updated daily. `KaggleDownloader` allows you to easily pull data through the Kaggle API. We will be using this dataset in an example below.\n",
    "\n",
    "In this case, `download_inference_data` and `download_training_data` have the same functionality as we can't make the distinction beforehand for an arbitrary dataset on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# export\\nclass KaggleDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    Download awesome financial data from Kaggle.\\n\\n    For authentication, make sure you have a directory called .kaggle in your home directory\\n    with therein a kaggle.json file. kaggle.json should have the following structure: \\\\n\\n    `{\\\"username\\\": USERNAME, \\\"key\\\": KAGGLE_API_KEY}` \\\\n\\n    More info on authentication: github.com/Kaggle/kaggle-api#api-credentials \\\\n\\n\\n    More info on the Kaggle Python API: kaggle.com/donkeys/kaggle-python-api \\\\n\\n\\n    :param directory_path: Base folder to download files to.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str):\\n        self.__check_kaggle_import()\\n        super().__init__(directory_path=directory_path)\\n\\n    def download_inference_data(self, kaggle_dataset_path: str):\\n        \\\"\\\"\\\"\\n        Download arbitrary Kaggle dataset.\\n        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\\n        \\\"\\\"\\\"\\n        self.download_training_data(kaggle_dataset_path)\\n\\n    def download_training_data(self, kaggle_dataset_path: str):\\n        \\\"\\\"\\\"\\n        Download arbitrary Kaggle dataset.\\n        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\\n        \\\"\\\"\\\"\\n        import kaggle\\n        kaggle.api.dataset_download_files(kaggle_dataset_path,\\n                                          path=self.dir, unzip=True)\\n\\n    @staticmethod\\n    def __check_kaggle_import():\\n        try:\\n            import kaggle\\n        except OSError:\\n            raise OSError(\\\"Could not find kaggle.json credentials. Make sure it's located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication.\\\")\";\n                var nbb_formatted_code = \"# export\\nclass KaggleDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    Download awesome financial data from Kaggle.\\n\\n    For authentication, make sure you have a directory called .kaggle in your home directory\\n    with therein a kaggle.json file. kaggle.json should have the following structure: \\\\n\\n    `{\\\"username\\\": USERNAME, \\\"key\\\": KAGGLE_API_KEY}` \\\\n\\n    More info on authentication: github.com/Kaggle/kaggle-api#api-credentials \\\\n\\n\\n    More info on the Kaggle Python API: kaggle.com/donkeys/kaggle-python-api \\\\n\\n\\n    :param directory_path: Base folder to download files to.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str):\\n        self.__check_kaggle_import()\\n        super().__init__(directory_path=directory_path)\\n\\n    def download_inference_data(self, kaggle_dataset_path: str):\\n        \\\"\\\"\\\"\\n        Download arbitrary Kaggle dataset.\\n        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\\n        \\\"\\\"\\\"\\n        self.download_training_data(kaggle_dataset_path)\\n\\n    def download_training_data(self, kaggle_dataset_path: str):\\n        \\\"\\\"\\\"\\n        Download arbitrary Kaggle dataset.\\n        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\\n        \\\"\\\"\\\"\\n        import kaggle\\n\\n        kaggle.api.dataset_download_files(\\n            kaggle_dataset_path, path=self.dir, unzip=True\\n        )\\n\\n    @staticmethod\\n    def __check_kaggle_import():\\n        try:\\n            import kaggle\\n        except OSError:\\n            raise OSError(\\n                \\\"Could not find kaggle.json credentials. Make sure it's located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication.\\\"\\n            )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class KaggleDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    Download awesome financial data from Kaggle.\n",
    "\n",
    "    For authentication, make sure you have a directory called .kaggle in your home directory\n",
    "    with therein a kaggle.json file. kaggle.json should have the following structure: \\n\n",
    "    `{\"username\": USERNAME, \"key\": KAGGLE_API_KEY}` \\n\n",
    "    More info on authentication: github.com/Kaggle/kaggle-api#api-credentials \\n\n",
    "\n",
    "    More info on the Kaggle Python API: kaggle.com/donkeys/kaggle-python-api \\n\n",
    "\n",
    "    :param directory_path: Base folder to download files to.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        self.__check_kaggle_import()\n",
    "        super().__init__(directory_path=directory_path)\n",
    "\n",
    "    def download_inference_data(self, kaggle_dataset_path: str):\n",
    "        \"\"\"\n",
    "        Download arbitrary Kaggle dataset.\n",
    "        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\n",
    "        \"\"\"\n",
    "        self.download_training_data(kaggle_dataset_path)\n",
    "\n",
    "    def download_training_data(self, kaggle_dataset_path: str):\n",
    "        \"\"\"\n",
    "        Download arbitrary Kaggle dataset.\n",
    "        :param kaggle_dataset_path: Path on Kaggle (URL slug on kaggle.com/)\n",
    "        \"\"\"\n",
    "        import kaggle\n",
    "        kaggle.api.dataset_download_files(kaggle_dataset_path,\n",
    "                                          path=self.dir, unzip=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def __check_kaggle_import():\n",
    "        try:\n",
    "            import kaggle\n",
    "        except OSError:\n",
    "            raise OSError(\"Could not find kaggle.json credentials. Make sure it's located in /home/runner/.kaggle. Or use the environment method. Check github.com/Kaggle/kaggle-api#api-credentials for more information on authentication.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The link to Katsu1110's yfinance price dataset is [https://www.kaggle.com/code1110/yfinance-stock-price-data-for-numerai-signals](https://www.kaggle.com/code1110/yfinance-stock-price-data-for-numerai-signals). In `.download_training_data` we define the slug after kaggle.com (`code1110/yfinance-stock-price-data-for-numerai-signals`) as an argument. The full Kaggle dataset is downloaded and unzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mtest_kaggle_downloader\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">test_kaggle_downloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"# other\\nhome_directory = \\\"test_kaggle_downloader\\\"\\nkd = KaggleDownloader(home_directory)\\nkd.download_training_data(\\\"code1110/yfinance-stock-price-data-for-numerai-signals\\\")\";\n                var nbb_formatted_code = \"# other\\nhome_directory = \\\"test_kaggle_downloader\\\"\\nkd = KaggleDownloader(home_directory)\\nkd.download_training_data(\\\"code1110/yfinance-stock-price-data-for-numerai-signals\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "home_directory = \"test_kaggle_downloader\"\n",
    "kd = KaggleDownloader(home_directory)\n",
    "kd.download_training_data(\"code1110/yfinance-stock-price-data-for-numerai-signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This Kaggle dataset contains one file called `\"full_data.parquet\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Path('test_kaggle_downloader/full_data.parquet')]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"# other\\nlist(kd.dir.iterdir())\";\n                var nbb_formatted_code = \"# other\\nlist(kd.dir.iterdir())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "list(kd.dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      ticker      date       close    raw_close         high          low  \\\n0  000060 KS  20020103  534.924255  1248.795166  1248.795166  1248.795166   \n1  000060 KS  20020104  566.944397  1323.546997  1363.121460  1213.617798   \n\n          open     volume  \n0  1248.795166        0.0  \n1  1275.178223  3937763.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ticker</th>\n      <th>date</th>\n      <th>close</th>\n      <th>raw_close</th>\n      <th>high</th>\n      <th>low</th>\n      <th>open</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000060 KS</td>\n      <td>20020103</td>\n      <td>534.924255</td>\n      <td>1248.795166</td>\n      <td>1248.795166</td>\n      <td>1248.795166</td>\n      <td>1248.795166</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000060 KS</td>\n      <td>20020104</td>\n      <td>566.944397</td>\n      <td>1323.546997</td>\n      <td>1363.121460</td>\n      <td>1213.617798</td>\n      <td>1275.178223</td>\n      <td>3937763.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"# other\\ndf = pd.read_parquet(f\\\"{home_directory}/full_data.parquet\\\")\\ndf.head(2)\";\n                var nbb_formatted_code = \"# other\\ndf = pd.read_parquet(f\\\"{home_directory}/full_data.parquet\\\")\\ndf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "df = pd.read_parquet(f\"{home_directory}/full_data.parquet\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Folder can be cleaned up when done with inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": " \u001B[31mDeleting directory for \u001B[0m\u001B[31m'KaggleDownloader\u001B[0m\u001B[32m'\u001B[0m \nPath: \n\u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_kaggle_downloader'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'KaggleDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> \nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/test_kaggle_downloader'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"# other\\nkd.remove_base_directory()\";\n                var nbb_formatted_code = \"# other\\nkd.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "kd.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Pandas Datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[pandas-datareader](https://pydata.github.io/pandas-datareader/stable/readers/index.html) is a library maintained by pydata. It offers several backends to directly retrieve data, including [Yahoo! Finance](https://finance.yahoo.com/) and [FRED database](https://fred.stlouisfed.org/). Our `PandasDataReader` object simplifies pulling training, inference and live data for Numerai Signals pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"# export\\nclass PandasDataReader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    Download financial data using Pandas Datareader.\\n\\n    :param directory_path: Base folder to download files to. \\\\n\\n    :param tickers: list of tickers used for downloading. \\\\n\\n    :param backend: Data provider you want to use. Yahoo Finance by default. \\\\n\\n    Check pydata.github.io/pandas-datareader/stable/readers/index.html to see all data readers.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str, tickers: list, backend: str = 'yahoo'):\\n        super().__init__(directory_path=directory_path)\\n        self.tickers = tickers\\n        self.backend = backend\\n        self.current_time = dt.now()\\n\\n    def download_inference_data(self, save_path: str = None, *args, **kwargs):\\n        \\\"\\\"\\\" Download a year of data. \\\"\\\"\\\"\\n        start = self.current_time - relativedelta(years=1)\\n        dataf = self._get_all_ticker_data(start=start, *args, **kwargs)\\n        save_path = save_path if save_path else self.__format_default_save_path(start)\\n        dataf.to_parquet(save_path)\\n\\n    def download_training_data(self, start: dt, save_path: str = None, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        Download full training dataset with given start_date.\\n        :param start: datetime object defining starting date.\\n        :param save_path: Path for Parquet file.\\n        \\\"\\\"\\\"\\n        dataf = self._get_all_ticker_data(start=start, *args, **kwargs)\\n        save_path = save_path if save_path else self.__format_default_save_path(start)\\n        dataf.to_parquet(save_path)\\n\\n    def download_live_data(self, save_path: str = None, *args, **kwargs):\\n        \\\"\\\"\\\" Download a month of data. \\\"\\\"\\\"\\n        start = self.current_time - relativedelta(months=1)\\n        save_path = save_path if save_path else self.__format_default_save_path(start)\\n        dataf = self.get_live_data(*args, **kwargs)\\n        dataf.to_parquet(save_path)\\n\\n    def get_live_data(self, *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\" Get a month of data as DataFrame. \\\"\\\"\\\"\\n        start = self.current_time - relativedelta(months=1)\\n        return NumerFrame(self._get_all_ticker_data(start=start, *args, **kwargs))\\n\\n    def _get_all_ticker_data(self, start: dt, *args, **kwargs) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Get data for all tickers defined in class using given starting date.\\n        :param start: datetime object defining starting date.\\n        \\\"\\\"\\\"\\n        func = partial(self.__get_ticker_data, start=start)\\n        results = []\\n        for tick in tqdm(self.tickers):\\n            try:\\n                res = func(ticker=tick, *args, **kwargs)\\n            except RemoteDataError:\\n                rich_print(f\\\":warning: WARNING: No data found for ticker: [red]'{tick}'[/red]. :warning:\\\")\\n                continue\\n            results.append(res)\\n        dataf = pd.concat(results)\\n        return dataf\\n\\n    def __get_ticker_data(self, ticker: str, start: dt, *args, **kwargs) -> pd.DataFrame:\\n        dataf = web.DataReader(ticker, self.backend, start, self.current_time, *args, **kwargs)\\n        dataf['ticker'] = ticker\\n        dataf.index.names = ['date']\\n        dataf = dataf.reset_index(drop=False)\\n        return dataf\\n\\n    def __format_default_save_path(self, start: dt):\\n        return f\\\"{self.dir}/{self.backend}_{start.strftime('%Y%m%d')}_{self.current_time.strftime('%Y%m%d')}.parquet\\\"\";\n                var nbb_formatted_code = \"# export\\nclass PandasDataReader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    Download financial data using Pandas Datareader.\\n\\n    :param directory_path: Base folder to download files to. \\\\n\\n    :param tickers: list of tickers used for downloading. \\\\n\\n    :param backend: Data provider you want to use. Yahoo Finance by default. \\\\n\\n    Check pydata.github.io/pandas-datareader/stable/readers/index.html to see all data readers.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str, tickers: list, backend: str = \\\"yahoo\\\"):\\n        super().__init__(directory_path=directory_path)\\n        self.tickers = tickers\\n        self.backend = backend\\n        self.current_time = dt.now()\\n\\n    def download_inference_data(self, save_path: str = None, *args, **kwargs):\\n        \\\"\\\"\\\"Download a year of data.\\\"\\\"\\\"\\n        start = self.current_time - relativedelta(years=1)\\n        dataf = self._get_all_ticker_data(start=start, *args, **kwargs)\\n        save_path = save_path if save_path else self.__format_default_save_path(start)\\n        dataf.to_parquet(save_path)\\n\\n    def download_training_data(self, start: dt, save_path: str = None, *args, **kwargs):\\n        \\\"\\\"\\\"\\n        Download full training dataset with given start_date.\\n        :param start: datetime object defining starting date.\\n        :param save_path: Path for Parquet file.\\n        \\\"\\\"\\\"\\n        dataf = self._get_all_ticker_data(start=start, *args, **kwargs)\\n        save_path = save_path if save_path else self.__format_default_save_path(start)\\n        dataf.to_parquet(save_path)\\n\\n    def download_live_data(self, save_path: str = None, *args, **kwargs):\\n        \\\"\\\"\\\"Download a month of data.\\\"\\\"\\\"\\n        start = self.current_time - relativedelta(months=1)\\n        save_path = save_path if save_path else self.__format_default_save_path(start)\\n        dataf = self.get_live_data(*args, **kwargs)\\n        dataf.to_parquet(save_path)\\n\\n    def get_live_data(self, *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\"Get a month of data as DataFrame.\\\"\\\"\\\"\\n        start = self.current_time - relativedelta(months=1)\\n        return NumerFrame(self._get_all_ticker_data(start=start, *args, **kwargs))\\n\\n    def _get_all_ticker_data(self, start: dt, *args, **kwargs) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Get data for all tickers defined in class using given starting date.\\n        :param start: datetime object defining starting date.\\n        \\\"\\\"\\\"\\n        func = partial(self.__get_ticker_data, start=start)\\n        results = []\\n        for tick in tqdm(self.tickers):\\n            try:\\n                res = func(ticker=tick, *args, **kwargs)\\n            except RemoteDataError:\\n                rich_print(\\n                    f\\\":warning: WARNING: No data found for ticker: [red]'{tick}'[/red]. :warning:\\\"\\n                )\\n                continue\\n            results.append(res)\\n        dataf = pd.concat(results)\\n        return dataf\\n\\n    def __get_ticker_data(\\n        self, ticker: str, start: dt, *args, **kwargs\\n    ) -> pd.DataFrame:\\n        dataf = web.DataReader(\\n            ticker, self.backend, start, self.current_time, *args, **kwargs\\n        )\\n        dataf[\\\"ticker\\\"] = ticker\\n        dataf.index.names = [\\\"date\\\"]\\n        dataf = dataf.reset_index(drop=False)\\n        return dataf\\n\\n    def __format_default_save_path(self, start: dt):\\n        return f\\\"{self.dir}/{self.backend}_{start.strftime('%Y%m%d')}_{self.current_time.strftime('%Y%m%d')}.parquet\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class PandasDataReader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    Download financial data using Pandas Datareader.\n",
    "\n",
    "    :param directory_path: Base folder to download files to. \\n\n",
    "    :param tickers: list of tickers used for downloading. \\n\n",
    "    :param backend: Data provider you want to use. Yahoo Finance by default. \\n\n",
    "    Check pydata.github.io/pandas-datareader/stable/readers/index.html to see all data readers.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str, tickers: list, backend: str = 'yahoo'):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "        self.tickers = tickers\n",
    "        self.backend = backend\n",
    "        self.current_time = dt.now()\n",
    "\n",
    "    def download_inference_data(self, save_path: str = None, *args, **kwargs):\n",
    "        \"\"\" Download a year of data. \"\"\"\n",
    "        start = self.current_time - relativedelta(years=1)\n",
    "        dataf = self._get_all_ticker_data(start=start, *args, **kwargs)\n",
    "        save_path = save_path if save_path else self.__format_default_save_path(start)\n",
    "        dataf.to_parquet(save_path)\n",
    "\n",
    "    def download_training_data(self, start: dt, save_path: str = None, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Download full training dataset with given start_date.\n",
    "        :param start: datetime object defining starting date.\n",
    "        :param save_path: Path for Parquet file.\n",
    "        \"\"\"\n",
    "        dataf = self._get_all_ticker_data(start=start, *args, **kwargs)\n",
    "        save_path = save_path if save_path else self.__format_default_save_path(start)\n",
    "        dataf.to_parquet(save_path)\n",
    "\n",
    "    def download_live_data(self, save_path: str = None, *args, **kwargs):\n",
    "        \"\"\" Download a month of data. \"\"\"\n",
    "        start = self.current_time - relativedelta(months=1)\n",
    "        save_path = save_path if save_path else self.__format_default_save_path(start)\n",
    "        dataf = self.get_live_data(*args, **kwargs)\n",
    "        dataf.to_parquet(save_path)\n",
    "\n",
    "    def get_live_data(self, *args, **kwargs) -> NumerFrame:\n",
    "        \"\"\" Get a month of data as DataFrame. \"\"\"\n",
    "        start = self.current_time - relativedelta(months=1)\n",
    "        return NumerFrame(self._get_all_ticker_data(start=start, *args, **kwargs))\n",
    "\n",
    "    def _get_all_ticker_data(self, start: dt, *args, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get data for all tickers defined in class using given starting date.\n",
    "        :param start: datetime object defining starting date.\n",
    "        \"\"\"\n",
    "        func = partial(self.__get_ticker_data, start=start)\n",
    "        results = []\n",
    "        for tick in tqdm(self.tickers):\n",
    "            try:\n",
    "                res = func(ticker=tick, *args, **kwargs)\n",
    "            except RemoteDataError:\n",
    "                rich_print(f\":warning: WARNING: No data found for ticker: [red]'{tick}'[/red]. :warning:\")\n",
    "                continue\n",
    "            results.append(res)\n",
    "        dataf = pd.concat(results)\n",
    "        return dataf\n",
    "\n",
    "    def __get_ticker_data(self, ticker: str, start: dt, *args, **kwargs) -> pd.DataFrame:\n",
    "        dataf = web.DataReader(ticker, self.backend, start, self.current_time, *args, **kwargs)\n",
    "        dataf['ticker'] = ticker\n",
    "        dataf.index.names = ['date']\n",
    "        dataf = dataf.reset_index(drop=False)\n",
    "        return dataf\n",
    "\n",
    "    def __format_default_save_path(self, start: dt):\n",
    "        return f\"{self.dir}/{self.backend}_{start.strftime('%Y%m%d')}_{self.current_time.strftime('%Y%m%d')}.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mpandas_datareader_test\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">pandas_datareader_test</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"pdr = PandasDataReader(directory_path=\\\"pandas_datareader_test\\\", tickers=['AAPL', 'MSFT', 'NOTATICKER'])\";\n                var nbb_formatted_code = \"pdr = PandasDataReader(\\n    directory_path=\\\"pandas_datareader_test\\\", tickers=[\\\"AAPL\\\", \\\"MSFT\\\", \\\"NOTATICKER\\\"]\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdr = PandasDataReader(directory_path=\"pandas_datareader_test\", tickers=['AAPL', 'MSFT', 'NOTATICKER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`.download_training_data` downloads all data from given start date (`datetime` object).\n",
    "\n",
    "`.download_inference_data` downloads data for a year.\n",
    "\n",
    "`.download_live_data` downloads data for a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7eacc610ceb345c98683c7f830703077"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 18:08:21,118 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-11 18:08:21,119 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": " WARNING: No data found for ticker: \u001B[31m'NOTATICKER'\u001B[0m. \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> WARNING: No data found for ticker: <span style=\"color: #800000; text-decoration-color: #800000\">'NOTATICKER'</span>. \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9a8a31721264944a54359a9b0a3a447"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": " WARNING: No data found for ticker: \u001B[31m'NOTATICKER'\u001B[0m. \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> WARNING: No data found for ticker: <span style=\"color: #800000; text-decoration-color: #800000\">'NOTATICKER'</span>. \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "961bb675c6ca4f3487dcd9b6110438a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": " WARNING: No data found for ticker: \u001B[31m'NOTATICKER'\u001B[0m. \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> WARNING: No data found for ticker: <span style=\"color: #800000; text-decoration-color: #800000\">'NOTATICKER'</span>. \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"pdr.download_training_data(start=dt(year=2008, month=1, day=1))\\npdr.download_inference_data()\\npdr.download_live_data()\\n\\nassert Path(f\\\"pandas_datareader_test/yahoo_20080101_{dt.now().strftime('%Y%m%d')}.parquet\\\").is_file()\";\n                var nbb_formatted_code = \"pdr.download_training_data(start=dt(year=2008, month=1, day=1))\\npdr.download_inference_data()\\npdr.download_live_data()\\n\\nassert Path(\\n    f\\\"pandas_datareader_test/yahoo_20080101_{dt.now().strftime('%Y%m%d')}.parquet\\\"\\n).is_file()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdr.download_training_data(start=dt(year=2008, month=1, day=1))\n",
    "pdr.download_inference_data()\n",
    "pdr.download_live_data()\n",
    "\n",
    "assert Path(f\"pandas_datareader_test/yahoo_20080101_{dt.now().strftime('%Y%m%d')}.parquet\").is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`.get_live_data()` returns a `NumerFrame` directly with data for a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27e1ee72bd5945ae8b8c248ed5e129cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": " WARNING: No data found for ticker: \u001B[31m'NOTATICKER'\u001B[0m. \n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> WARNING: No data found for ticker: <span style=\"color: #800000; text-decoration-color: #800000\">'NOTATICKER'</span>. \n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"dataf = pdr.get_live_data()\";\n                var nbb_formatted_code = \"dataf = pdr.get_live_data()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = pdr.get_live_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        date        High         Low        Open       Close      Volume  \\\n0 2022-04-11  169.029999  165.500000  168.710007  165.750000  72246700.0   \n1 2022-04-12  169.869995  166.639999  168.020004  167.660004  79265200.0   \n\n    Adj Close ticker  \n0  165.506821   AAPL  \n1  167.414032   AAPL  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Adj Close</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-04-11</td>\n      <td>169.029999</td>\n      <td>165.500000</td>\n      <td>168.710007</td>\n      <td>165.750000</td>\n      <td>72246700.0</td>\n      <td>165.506821</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-04-12</td>\n      <td>169.869995</td>\n      <td>166.639999</td>\n      <td>168.020004</td>\n      <td>167.660004</td>\n      <td>79265200.0</td>\n      <td>167.414032</td>\n      <td>AAPL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"print(dataf.shape)\\ndataf.head(2)\";\n                var nbb_formatted_code = \"print(dataf.shape)\\ndataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataf.shape)\n",
    "dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date        High         Low        Open      Close      Volume  \\\n20 2022-05-10  273.750000  265.070007  271.690002  269.50000  39292300.0   \n21 2022-05-11  271.359985  263.779999  265.679993  265.23999  16032857.0   \n\n    Adj Close ticker  \n20  269.50000   MSFT  \n21  265.23999   MSFT  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Adj Close</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>2022-05-10</td>\n      <td>273.750000</td>\n      <td>265.070007</td>\n      <td>271.690002</td>\n      <td>269.50000</td>\n      <td>39292300.0</td>\n      <td>269.50000</td>\n      <td>MSFT</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2022-05-11</td>\n      <td>271.359985</td>\n      <td>263.779999</td>\n      <td>265.679993</td>\n      <td>265.23999</td>\n      <td>16032857.0</td>\n      <td>265.23999</td>\n      <td>MSFT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"dataf.tail(2)\";\n                var nbb_formatted_code = \"dataf.tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"dataf[dataf['ticker']==\\\"AAPL\\\"].set_index(\\\"date\\\")['Adj Close'].plot()\\ndataf[dataf['ticker']==\\\"MSFT\\\"].set_index(\\\"date\\\")['Adj Close'].plot()\\nplt.legend(['AAPL', 'MSFT']);\";\n                var nbb_formatted_code = \"dataf[dataf[\\\"ticker\\\"] == \\\"AAPL\\\"].set_index(\\\"date\\\")[\\\"Adj Close\\\"].plot()\\ndataf[dataf[\\\"ticker\\\"] == \\\"MSFT\\\"].set_index(\\\"date\\\")[\\\"Adj Close\\\"].plot()\\nplt.legend([\\\"AAPL\\\", \\\"MSFT\\\"])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf[dataf['ticker']==\"AAPL\"].set_index(\"date\")['Adj Close'].plot()\n",
    "dataf[dataf['ticker']==\"MSFT\"].set_index(\"date\")['Adj Close'].plot()\n",
    "plt.legend(['AAPL', 'MSFT']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": " \u001B[31mDeleting directory for \u001B[0m\u001B[31m'PandasDataReader\u001B[0m\u001B[32m'\u001B[0m \nPath: \n\u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/pandas_datareader_test'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'PandasDataReader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> \nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/pandas_datareader_test'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"pdr.remove_base_directory()\";\n                var nbb_formatted_code = \"pdr.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdr.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. FinnhubDownloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"# export\\nclass FinnhubDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    Download financial data from Finnhub.\\n\\n    :param directory_path: Base folder to download files to. \\\\n\\n    :param key: Valid Finnhub client key. \\\\n\\n    :param frequency: Choose from [1, 5, 15, 30, 60, D, W, M]. \\\\n\\n    Daily data by default.\\n    \\\"\\\"\\\"\\n    def __init__(self,\\n                 directory_path: str,\\n                 key: str,\\n                 tickers: list,\\n                 frequency: str = \\\"D\\\"):\\n        super().__init__(directory_path=directory_path)\\n        self.key = key\\n        self.tickers = tickers\\n        self.client = finnhub.Client(api_key=self.key)\\n        self.frequency = frequency\\n        self.current_time = dt.now()\\n        self.end_timestamp = int(self.current_time.timestamp())\\n\\n    def download_inference_data(self):\\n        \\\"\\\"\\\" Download one year of data for defined tickers. \\\"\\\"\\\"\\n        start = self.current_time - relativedelta(years=1)\\n        dataf = self.generate_full_dataf(start=start)\\n        dataf.to_parquet(self.__format_default_save_path(start=start))\\n\\n    def download_training_data(self):\\n        \\\"\\\"\\\" Download full date length available. \\\"\\\"\\\"\\n        start = int(pd.to_datetime(0).timestamp())\\n        dataf = self.generate_full_dataf(start=start)\\n        dataf.to_parquet(self.__format_default_save_path(start=start))\\n\\n    def generate_full_dataf(self, start: int) -> pd.DataFrame:\\n        \\\"\\\"\\\" Collect all price data for list of Finnhub ticker symbols (without US). \\\"\\\"\\\"\\n        price_datafs = []\\n        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\\n            tasks = [executor.submit(self.generate_stock_dataf, ticker, start) for ticker in self.tickers]\\n            for task in tqdm(concurrent.futures.as_completed(tasks),\\n                             total=len(self.tickers),\\n                             desc=\\\"Finnhub price data extraction\\\"):\\n                price_datafs.append(task.result())\\n        return pd.concat(price_datafs)\\n\\n    def generate_stock_dataf(self, ticker: str, start: dt) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Generate Price DataFrame for a single ticker.\\n        ticker: Finnhub ticker symbol (without US).\\n        start: Datetime object denoting starting time.\\n        \\\"\\\"\\\"\\n        candles = self.client.stock_candles(ticker,\\n                                            self.frequency,\\n                                            int(start.timestamp()),\\n                                            self.end_timestamp)\\n        try:\\n            stock_df = pd.DataFrame(candles)\\n        except:\\n            return pd.DataFrame()\\n        stock_df['ticker'] = ticker\\n        stock_df['date'] = pd.to_datetime(stock_df['t'], unit='s', origin='unix').map(lambda x: x.strftime('%Y-%m-%d'))\\n        stock_df = stock_df.drop(['s', 't'], axis=1)\\n        return stock_df\\n\\n    def __format_default_save_path(self, start: dt):\\n        return f\\\"{self.dir}/finnhub_{start.strftime('%Y%m%d')}_{self.current_time.strftime('%Y%m%d')}.parquet\\\"\";\n                var nbb_formatted_code = \"# export\\nclass FinnhubDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    Download financial data from Finnhub.\\n\\n    :param directory_path: Base folder to download files to. \\\\n\\n    :param key: Valid Finnhub client key. \\\\n\\n    :param frequency: Choose from [1, 5, 15, 30, 60, D, W, M]. \\\\n\\n    Daily data by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self, directory_path: str, key: str, tickers: list, frequency: str = \\\"D\\\"\\n    ):\\n        super().__init__(directory_path=directory_path)\\n        self.key = key\\n        self.tickers = tickers\\n        self.client = finnhub.Client(api_key=self.key)\\n        self.frequency = frequency\\n        self.current_time = dt.now()\\n        self.end_timestamp = int(self.current_time.timestamp())\\n\\n    def download_inference_data(self):\\n        \\\"\\\"\\\"Download one year of data for defined tickers.\\\"\\\"\\\"\\n        start = self.current_time - relativedelta(years=1)\\n        dataf = self.generate_full_dataf(start=start)\\n        dataf.to_parquet(self.__format_default_save_path(start=start))\\n\\n    def download_training_data(self):\\n        \\\"\\\"\\\"Download full date length available.\\\"\\\"\\\"\\n        start = int(pd.to_datetime(0).timestamp())\\n        dataf = self.generate_full_dataf(start=start)\\n        dataf.to_parquet(self.__format_default_save_path(start=start))\\n\\n    def generate_full_dataf(self, start: int) -> pd.DataFrame:\\n        \\\"\\\"\\\"Collect all price data for list of Finnhub ticker symbols (without US).\\\"\\\"\\\"\\n        price_datafs = []\\n        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\\n            tasks = [\\n                executor.submit(self.generate_stock_dataf, ticker, start)\\n                for ticker in self.tickers\\n            ]\\n            for task in tqdm(\\n                concurrent.futures.as_completed(tasks),\\n                total=len(self.tickers),\\n                desc=\\\"Finnhub price data extraction\\\",\\n            ):\\n                price_datafs.append(task.result())\\n        return pd.concat(price_datafs)\\n\\n    def generate_stock_dataf(self, ticker: str, start: dt) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Generate Price DataFrame for a single ticker.\\n        ticker: Finnhub ticker symbol (without US).\\n        start: Datetime object denoting starting time.\\n        \\\"\\\"\\\"\\n        candles = self.client.stock_candles(\\n            ticker, self.frequency, int(start.timestamp()), self.end_timestamp\\n        )\\n        try:\\n            stock_df = pd.DataFrame(candles)\\n        except:\\n            return pd.DataFrame()\\n        stock_df[\\\"ticker\\\"] = ticker\\n        stock_df[\\\"date\\\"] = pd.to_datetime(stock_df[\\\"t\\\"], unit=\\\"s\\\", origin=\\\"unix\\\").map(\\n            lambda x: x.strftime(\\\"%Y-%m-%d\\\")\\n        )\\n        stock_df = stock_df.drop([\\\"s\\\", \\\"t\\\"], axis=1)\\n        return stock_df\\n\\n    def __format_default_save_path(self, start: dt):\\n        return f\\\"{self.dir}/finnhub_{start.strftime('%Y%m%d')}_{self.current_time.strftime('%Y%m%d')}.parquet\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class FinnhubDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    Download financial data from Finnhub.\n",
    "\n",
    "    :param directory_path: Base folder to download files to. \\n\n",
    "    :param key: Valid Finnhub client key. \\n\n",
    "    :param frequency: Choose from [1, 5, 15, 30, 60, D, W, M]. \\n\n",
    "    Daily data by default.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 directory_path: str,\n",
    "                 key: str,\n",
    "                 tickers: list,\n",
    "                 frequency: str = \"D\"):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "        self.key = key\n",
    "        self.tickers = tickers\n",
    "        self.client = finnhub.Client(api_key=self.key)\n",
    "        self.frequency = frequency\n",
    "        self.current_time = dt.now()\n",
    "        self.end_timestamp = int(self.current_time.timestamp())\n",
    "\n",
    "    def download_inference_data(self):\n",
    "        \"\"\" Download one year of data for defined tickers. \"\"\"\n",
    "        start = self.current_time - relativedelta(years=1)\n",
    "        dataf = self.generate_full_dataf(start=start)\n",
    "        dataf.to_parquet(self.__format_default_save_path(start=start))\n",
    "\n",
    "    def download_training_data(self):\n",
    "        \"\"\" Download full date length available. \"\"\"\n",
    "        start = int(pd.to_datetime(0).timestamp())\n",
    "        dataf = self.generate_full_dataf(start=start)\n",
    "        dataf.to_parquet(self.__format_default_save_path(start=start))\n",
    "\n",
    "    def generate_full_dataf(self, start: int) -> pd.DataFrame:\n",
    "        \"\"\" Collect all price data for list of Finnhub ticker symbols (without US). \"\"\"\n",
    "        price_datafs = []\n",
    "        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "            tasks = [executor.submit(self.generate_stock_dataf, ticker, start) for ticker in self.tickers]\n",
    "            for task in tqdm(concurrent.futures.as_completed(tasks),\n",
    "                             total=len(self.tickers),\n",
    "                             desc=\"Finnhub price data extraction\"):\n",
    "                price_datafs.append(task.result())\n",
    "        return pd.concat(price_datafs)\n",
    "\n",
    "    def generate_stock_dataf(self, ticker: str, start: dt) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate Price DataFrame for a single ticker.\n",
    "        ticker: Finnhub ticker symbol (without US).\n",
    "        start: Datetime object denoting starting time.\n",
    "        \"\"\"\n",
    "        candles = self.client.stock_candles(ticker,\n",
    "                                            self.frequency,\n",
    "                                            int(start.timestamp()),\n",
    "                                            self.end_timestamp)\n",
    "        try:\n",
    "            stock_df = pd.DataFrame(candles)\n",
    "        except:\n",
    "            return pd.DataFrame()\n",
    "        stock_df['ticker'] = ticker\n",
    "        stock_df['date'] = pd.to_datetime(stock_df['t'], unit='s', origin='unix', format='%Y-%m-%d')\n",
    "        stock_df = stock_df.drop(['s', 't'], axis=1)\n",
    "        return stock_df\n",
    "\n",
    "    def __format_default_save_path(self, start: dt):\n",
    "        return f\"{self.dir}/finnhub_{start.strftime('%Y%m%d')}_{self.current_time.strftime('%Y%m%d')}.parquet\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We invite the Numerai Community to implement new downloaders for this project using interesting APIs.\n",
    "\n",
    "These are especially important for creating innovative Numerai Signals models.\n",
    "\n",
    "A new Downloader can be created by inheriting from `BaseDownloader`. You should implement methods for `.download_inference_data` and `.download_training_data` so every downloader has a common interface. Below you will find a template for a new downloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"# export\\nclass AwesomeCustomDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    TEMPLATE -\\n    Download awesome financial data from who knows where.\\n\\n    :param directory_path: Base folder to download files to.\\n    \\\"\\\"\\\"\\n    def __init__(self, directory_path: str):\\n        super().__init__(directory_path=directory_path)\\n\\n    def download_inference_data(self, *args, **kwargs):\\n        \\\"\\\"\\\" (minimal) weekly inference downloading here. \\\"\\\"\\\"\\n        ...\\n\\n    def download_training_data(self, *args, **kwargs):\\n        \\\"\\\"\\\" Training + validation dataset downloading here. \\\"\\\"\\\"\\n        ...\";\n                var nbb_formatted_code = \"# export\\nclass AwesomeCustomDownloader(BaseDownloader):\\n    \\\"\\\"\\\"\\n    TEMPLATE -\\n    Download awesome financial data from who knows where.\\n\\n    :param directory_path: Base folder to download files to.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, directory_path: str):\\n        super().__init__(directory_path=directory_path)\\n\\n    def download_inference_data(self, *args, **kwargs):\\n        \\\"\\\"\\\"(minimal) weekly inference downloading here.\\\"\\\"\\\"\\n        ...\\n\\n    def download_training_data(self, *args, **kwargs):\\n        \\\"\\\"\\\"Training + validation dataset downloading here.\\\"\\\"\\\"\\n        ...\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class AwesomeCustomDownloader(BaseDownloader):\n",
    "    \"\"\"\n",
    "    TEMPLATE -\n",
    "    Download awesome financial data from who knows where.\n",
    "\n",
    "    :param directory_path: Base folder to download files to.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory_path: str):\n",
    "        super().__init__(directory_path=directory_path)\n",
    "\n",
    "    def download_inference_data(self, *args, **kwargs):\n",
    "        \"\"\" (minimal) weekly inference downloading here. \"\"\"\n",
    "        ...\n",
    "\n",
    "    def download_training_data(self, *args, **kwargs):\n",
    "        \"\"\" Training + validation dataset downloading here. \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_misc.ipynb.\n",
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}